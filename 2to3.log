--- ./ez/__init__.py	(original)
+++ ./ez/__init__.py	(refactored)
@@ -1,16 +1,16 @@
-from pipetools import pipe
-from easyshell import *
-from easyshell import __doc__ as doc1
-from pyg import Mail, mail, AddEvent, addevent, Sheet
-from pyg import Mail2, mail2, AddEvent2, addevent2, Sheet2
-from pyg import __doc__ as doc2
-from version import __version__
-from xpinyin import pinyin
+from .pipetools import pipe
+from .easyshell import *
+from .easyshell import __doc__ as doc1
+from .pyg import Mail, mail, AddEvent, addevent, Sheet
+from .pyg import Mail2, mail2, AddEvent2, addevent2, Sheet2
+from .pyg import __doc__ as doc2
+from .version import __version__
+from .xpinyin import pinyin
 try:
-    from pyperclip import copy as SetClip
-    from pyperclip import copy as setclip
-    from pyperclip import paste as GetClip
-    from pyperclip import paste as getclip
+    from .pyperclip import copy as SetClip
+    from .pyperclip import copy as setclip
+    from .pyperclip import paste as GetClip
+    from .pyperclip import paste as getclip
 except:
     pass    
 __doc__ = doc1 + '\n\n\n\n' + doc2
--- ./ez/easyshell.py	(original)
+++ ./ez/easyshell.py	(refactored)
@@ -133,7 +133,7 @@
 """
 
 # reference: abspath for ../ ./, expanduser for ~, glob to resolve wildcards, fnmatch.translate wildcards to re
-import os, sys, platform, string, random, shutil, re, subprocess, glob, ConfigParser, fnmatch
+import os, sys, platform, string, random, shutil, re, subprocess, glob, configparser, fnmatch
 from os.path import abspath, basename, dirname, splitext, isfile, isdir, realpath, expanduser
 
 _DEBUG_MODE = 0
@@ -475,13 +475,13 @@
     """cd(path), Changes to a new directory."""
     path = fullpath(path)
     os.chdir(path)
-    print "Start working in " + os.getcwd()
+    print("Start working in " + os.getcwd())
 
 def ce():
     """cd(csd()), Changes to csd."""
     path = csd()
     os.chdir(path)
-    print "Start working in " + path
+    print("Start working in " + path)
 cf = ce
 
 def ls(path="./", regex=".*", full=True, dotfile=False, sort=True, case=True):
@@ -492,7 +492,7 @@
     def _FilterList(list, pattern_regex):
         # match_pattern = re.compile(pattern_regex, re.IGNORECASE).search
         match_pattern = re.compile(pattern_regex).search
-        return filter(match_pattern, list)
+        return list(filter(match_pattern, list))
     def _ListingParse(path="./", pattern_regex=".*"):
         # ls() or ls('homebrew'), ls("homebrew", "\.py$")
         if os.path.isdir(path):
@@ -529,7 +529,7 @@
     def _FilterList(list, pattern_regex):
         # match_pattern = re.compile(pattern_regex, re.IGNORECASE).search
         match_pattern = re.compile(pattern_regex).search
-        return filter(match_pattern, list)
+        return list(filter(match_pattern, list))
     def _ListingParse(path="./", pattern_regex=".*"):
         # ls() or ls('homebrew'), ls("homebrew", "\.py$")
         if os.path.isdir(path):
@@ -572,7 +572,7 @@
     def _FilterList(list, pattern_regex):
         # match_pattern = re.compile(pattern_regex, re.IGNORECASE).search
         match_pattern = re.compile(pattern_regex).search
-        return filter(match_pattern, list)
+        return list(filter(match_pattern, list))
     def _ListingParse(path="./", pattern_regex=".*"):
         # ls() or ls('homebrew'), ls("homebrew", "\.py$")
         if os.path.isdir(path):
@@ -619,7 +619,7 @@
     path = fullpath(path)
     if not os.path.exists(path):
         os.makedirs(path)
-        print "Created: " + path
+        print("Created: " + path)
 
 def exists(path):
     """Returns the existence of path (0 or 1, supports wildcards such as "../homebrew/*.pyc" but not regular expression)."""
@@ -863,7 +863,7 @@
     destination = fullpath(destination)
 
     os.symlink(source, destination)
-    print "Symbolic link: " + "->".join([source, destination])
+    print("Symbolic link: " + "->".join([source, destination]))
 
 def execute2(cmd, verbose=3, save=None, saveMode='a', redirect=None, redirectMode='a', shell='bash', debugMode=False, *args, **kwargs):
     """Executes a bash command. can capture output
@@ -923,7 +923,7 @@
                 with open(save, 'a') as tmp:
                     tmp.write('#!/bin/'+('tcsh -xef' if shell in ['tcsh'] else shell)+'\n\n'+cmd.replace('"','\"').replace("'","\'")+'\n\n')
             subprocess.call('chmod +x '+save, shell=True)
-            print('\nCommand saved at '+save+'\n')
+            print(('\nCommand saved at '+save+'\n'))
 
         # https://stackoverflow.com/a/40139101/2292993
         def _execute_cmd(cmd):
@@ -973,7 +973,7 @@
             err = p.stderr.read()
             if p.returncode != 0:
                 # responsible for logging STDERR 
-                if verbose in [2,3]: print "Error: " + str(err)
+                if verbose in [2,3]: print("Error: " + str(err))
                 yield None
             # delete temp file
             os.remove(tmpPath)
@@ -983,7 +983,7 @@
             # error did not occur earlier
             if line is not None:
                 # trailing comma to avoid a newline (by print itself) being printed
-                if verbose in [2,3]: print line,
+                if verbose in [2,3]: print(line, end=' ')
                 out.append(line.strip())
             else:
                 # error occured earlier
@@ -995,7 +995,7 @@
         else:
             # https://stackoverflow.com/a/3845453/2292993
             # filter() check if one or all empty string
-            if len(out)==0 or len(filter(None,out))==0:
+            if len(out)==0 or len([_f for _f in out if _f])==0:
                 return []
             else:
                 return out
@@ -1010,7 +1010,7 @@
                 with open(save, 'a') as tmp:
                     tmp.write('#!/bin/'+('tcsh -xef' if shell in ['tcsh'] else shell)+'\n\n'+cmd.replace('"','\"').replace("'","\'")+'\n\n')
             subprocess.call('chmod +x '+save, shell=True)
-            print('\nCommand saved at '+save+'\n')
+            print(('\nCommand saved at '+save+'\n'))
         return None
 
 def execute1(cmd, verbose=3, save=None, saveMode='a', redirect=None, redirectMode='a', shell='bash', debugMode=False, *args, **kwargs):
@@ -1174,7 +1174,7 @@
             else:
                 with open(save, 'a') as tmp:
                     tmp.write('#!/bin/Rscript \n\n'+cmd.replace('"','\"').replace("'","\'")+'\n\n')
-            print('\nCommand saved at '+save+'\n')
+            print(('\nCommand saved at '+save+'\n'))
         
         import tempfile
         # create temp file with specified suffix
@@ -1199,7 +1199,7 @@
             else:
                 with open(save, 'a') as tmp:
                     tmp.write('#!/bin/Rscript \n\n'+cmd.replace('"','\"').replace("'","\'")+'\n\n')
-            print('\nCommand saved at '+save+'\n')
+            print(('\nCommand saved at '+save+'\n'))
         return None
 
 def espR1(cmdString, verbose=3, save=None, saveMode='a', redirect=None, redirectMode='a', skipdollar=1, debugMode=False, *args, **kwargs):
@@ -1290,7 +1290,7 @@
                 with open(save, 'a') as tmp:
                     tmp.write('#!/bin/'+('tcsh -xef' if shell in ['tcsh'] else shell)+'\n\n'+cmd.replace('"','\"').replace("'","\'")+'\n\n')
             subprocess.call('chmod +x '+save, shell=True)
-            print('\nCommand saved at '+save+'\n')
+            print(('\nCommand saved at '+save+'\n'))
 
         if os.name == 'nt' or platform.system() == 'Windows':
             if output:
@@ -1318,7 +1318,7 @@
                     subprocess.call('/bin/'+('tcsh -xef' if shell in ['tcsh'] else shell)+' "'+tmpPath+'"'+cmdSuffix, shell=True, executable="/bin/bash", stdout=open(os.devnull, "w"), stderr=subprocess.STDOUT)
                 finally:
                     os.remove(tmpPath)
-        print ""
+        print("")
 
     else:
         pprint("Simulation! Execute command: " + cmd + "\n< < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < ", 'yellow')
@@ -1331,7 +1331,7 @@
                 with open(save, 'a') as tmp:
                     tmp.write('#!/bin/'+('tcsh -xef' if shell in ['tcsh'] else shell)+'\n\n'+cmd.replace('"','\"').replace("'","\'")+'\n\n')
             subprocess.call('chmod +x '+save, shell=True)
-            print('\nCommand saved at '+save+'\n')
+            print(('\nCommand saved at '+save+'\n'))
 
 def esp(cmdString, verbose=3, save=None, saveMode='a', redirect=None, redirectMode='a', shell='bash', skipdollar=0, debugMode=False, *args, **kwargs):
     """
@@ -1422,7 +1422,7 @@
             else:
                 with open(save, 'a') as tmp:
                     tmp.write('#!/bin/Rscript \n\n'+cmd.replace('"','\"').replace("'","\'")+'\n\n')
-            print('\nCommand saved at '+save+'\n')
+            print(('\nCommand saved at '+save+'\n'))
 
         import tempfile
         # create temp file with specified suffix
@@ -1446,7 +1446,7 @@
             else:
                 with open(save, 'a') as tmp:
                     tmp.write('#!/bin/Rscript \n\n'+cmd.replace('"','\"').replace("'","\'")+'\n\n')
-            print('\nCommand saved at '+save+'\n')
+            print(('\nCommand saved at '+save+'\n'))
         return None
 
 def espA(cmdString, verbose=0, save=None, saveMode='a', redirect=None, redirectMode='a', shell='bash', skipdollar=1, debugMode=False, *args, **kwargs):
@@ -1528,7 +1528,7 @@
             else:
                 with open(save, 'a') as tmp:
                     tmp.write(cmd.replace('"','\"').replace("'","\'")+'\n\n')
-            print('\nCommand saved at '+save+'\n')
+            print(('\nCommand saved at '+save+'\n'))
 
         import tempfile
         # create temp file with specified suffix
@@ -1552,7 +1552,7 @@
             else:
                 with open(save, 'a') as tmp:
                     tmp.write(cmd.replace('"','\"').replace("'","\'")+'\n\n')
-            print('\nCommand saved at '+save+'\n')
+            print(('\nCommand saved at '+save+'\n'))
         return None
 
 def condorize(executables=[], submit=True, luggage=None, email=None, memory=None, disk=None, getenv=True, universe='vanilla', log='condor.log', submitfile='condor.sub',showstats=True):
@@ -1645,7 +1645,7 @@
 
     with open(submitfile, 'w') as tmp:
         tmp.write(condor.replace('"','\"').replace("'","\'")+'\n\n')
-    print('Condor submit file saved at '+submitfile)
+    print(('Condor submit file saved at '+submitfile))
 
     if email:
         # awk print should be single quoted (not double!)
@@ -1672,7 +1672,7 @@
     myqueue = 'Queue (mine):\t\t' + execute2('condor_q',0)[-1]
     
     pprint("\nSome condor commands...",'blue')
-    print """watch -n 2 condor_q
+    print("""watch -n 2 condor_q
 condor_q: See my current condor jobs
 condor_q -better-analyze <job_id>
 condor_status: cores being used
@@ -1702,13 +1702,13 @@
 2>&1 | tee -a: bash redirect file and screen (-a append)
 |& tee -a: tcsh redirect file and screen
 /path/\{file1.zip,file2.zip\}: multiple matches
-"""
+""")
 
     # pprint("Some users' reports...",'blue')
     # execute('condor_userprio -most',2)
     
     pprint("\nSome condor stats...",'blue')
-    print unclaimed + '\n' + allqueue + '\n' + myqueue + '\n'
+    print(unclaimed + '\n' + allqueue + '\n' + myqueue + '\n')
 
 from contextlib import contextmanager
 @contextmanager
@@ -1770,18 +1770,18 @@
     name_no_prefix = name.split('.')[-1]
     if name_no_prefix == 'python':
         from distutils.sysconfig import get_python_lib
-        print get_python_lib()
-        print (sys.version)
+        print(get_python_lib())
+        print((sys.version))
     else:
         try:
-            print sys.modules[name_no_prefix]
+            print(sys.modules[name_no_prefix])
         except:
-            for module in sys.modules.keys():
+            for module in list(sys.modules.keys()):
                 try:
                     import inspect
                     caller = inspect.currentframe().f_back
                     if name_no_prefix in eval('dir('+ module + ')', caller.f_locals):
-                        print 'function ' + name_no_prefix + '() in ' + module
+                        print('function ' + name_no_prefix + '() in ' + module)
                         # print sys.modules[module]
                         # print ''
                 except:
@@ -1801,21 +1801,21 @@
     """
     import inspect
     caller = inspect.currentframe().f_back
-    print eval(package_prefixed_name + '.__doc__', caller.f_locals)
+    print(eval(package_prefixed_name + '.__doc__', caller.f_locals))
 help = doc
 
 def ver(package_name='python'):
     """
     ver(package_name) version(package_name), see a package's version.  package_name could be 'python'
     """
-    print package_name + ' version installed:'
+    print(package_name + ' version installed:')
     if package_name == 'python':
-        print (sys.version)
+        print((sys.version))
     else:
         # https://docs.python.org/2.7/reference/simple_stmts.html#exec
         theNameSpace = {}
         exec('import ' + package_name, theNameSpace)
-        print theNameSpace[package_name].__version__
+        print(theNameSpace[package_name].__version__)
 version = ver
 
 def evaluate(exp):
@@ -1842,13 +1842,13 @@
     theList = eval('dir('+ name + ')', caller.f_locals)
     theList = sorted(theList)
     theNameSpace = name if name != '' else 'Current'
-    print theNameSpace + ' namespace has the following existing functions/modules:\n'
+    print(theNameSpace + ' namespace has the following existing functions/modules:\n')
     # http://stackoverflow.com/questions/19863388/modify-print-function-for-multiple-columns-python
     def pretty_print(theList, ncols):
         columns = len(theList)//200+ncols
         lines = ("".join(s.ljust(20) for s in theList[i:i+columns-1])+theList[i:i+columns][-1] for i in range(0, len(theList), columns))
         return "\n".join(lines)
-    print pretty_print(theList,4)
+    print(pretty_print(theList,4))
 whos = who
 
 # def sedawk(path, regex=".*", search=None, replace=None, recursion=True):
@@ -1888,7 +1888,7 @@
         def __init__(self, file):
             self.file = file
             sys.stdout = sys.__stdout__
-            print "log on with " + fullpath(self.file)
+            print("log on with " + fullpath(self.file))
             self.terminal = sys.stdout
             self.log = open(file, mode)
             if timestamp:
@@ -1914,7 +1914,7 @@
             self.log.flush()
             self.log.close()
             sys.stdout = sys.__stdout__
-            print "log off with " + fullpath(self.file)
+            print("log off with " + fullpath(self.file))
 
     if status:
         # restore first if it has been changed
@@ -1980,7 +1980,7 @@
         if PRINT_FILES and files:
             file_prefix = prefix + ('|' if dirs else ' ') + '   '
             for name in files:
-                print(file_prefix + name)
+                print((file_prefix + name))
             print(file_prefix)
         dir_prefix, walk_prefix = prefix + '+---', prefix + '|   '
         for pos, neg, name in enumerate2(dirs):
@@ -1989,9 +1989,9 @@
             path = os.path.join(root, name)
             try:
                 dirs, files = listdir(path)[:2]
-                print(dir_prefix + name + '\t(' + str(len(files)) +  ' files)')
+                print((dir_prefix + name + '\t(' + str(len(files)) +  ' files)'))
             except:
-                print(dir_prefix + name)
+                print((dir_prefix + name))
             else:
                 walk(path, dirs, files, walk_prefix)
 
@@ -2332,7 +2332,7 @@
                     if kwargs['skipdollar']!=1: kwargs.pop('skipdollar')
                 except:
                     pass
-                if 'skipdollar' not in kwargs.keys():
+                if 'skipdollar' not in list(kwargs.keys()):
                     # \w is [a-zA-Z0-9_], but I do not want pure number
                     # so [a-zA-Z_]+\w*? for valid variable naming
                     # ${number}, ${language}_ to {number}, {language}_
@@ -2388,7 +2388,7 @@
     remove a module from sys.modules so it cannot be searched.
     when recursive=True, remove the module and its submodules"""
     if recursive:
-        for mod in sys.modules.keys():
+        for mod in list(sys.modules.keys()):
             if mod.startswith(module):
                 del(sys.modules[mod])
     else:
@@ -2471,7 +2471,7 @@
     # a = [1,5,2,3,2,1,5,6,5,5,5]
     # duplicate(a) # yields [2, 1, 5]
     """
-    from orderedset import OrderedSet
+    from .orderedset import OrderedSet
     return list(OrderedSet(seq))
 
 def union(seq1,seq2):
@@ -2493,7 +2493,7 @@
     # a = [1,5,2,3,2,1,5,6,5,5,5]
     # duplicate(a) # yields [2, 1, 5]
     """
-    from orderedset import OrderedSet
+    from .orderedset import OrderedSet
     return list(OrderedSet(seq1) | OrderedSet(seq2))
 
 def intersect(seq1,seq2):
@@ -2515,7 +2515,7 @@
     # a = [1,5,2,3,2,1,5,6,5,5,5]
     # duplicate(a) # yields [2, 1, 5]
     """
-    from orderedset import OrderedSet
+    from .orderedset import OrderedSet
     return list(OrderedSet(seq1) & OrderedSet(seq2))
 
 def setdiff(seq1,seq2):
@@ -2537,7 +2537,7 @@
     # a = [1,5,2,3,2,1,5,6,5,5,5]
     # duplicate(a) # yields [2, 1, 5]
     """
-    from orderedset import OrderedSet
+    from .orderedset import OrderedSet
     return list(OrderedSet(seq1) - OrderedSet(seq2))
 
 def duplicate(seq):
@@ -2559,7 +2559,7 @@
     # a = [1,5,2,3,2,1,5,6,5,5,5]
     # duplicate(a) # yields [2, 1, 5]
     """
-    from orderedset import OrderedSet
+    from .orderedset import OrderedSet
     seen = OrderedSet()
     seen_add = seen.add
     # adds all elements it doesn't know yet to seen and all other to seen_twice
@@ -2615,9 +2615,9 @@
         # prev for recursive call
         if prev == None: prev = self
 
-        for (newKey,newVal) in theDict.items():
+        for (newKey,newVal) in list(theDict.items()):
             # if no newKey, this is easy, simply initialize
-            if not prev.has_key(newKey):
+            if newKey not in prev:
                 prev[newKey] = newVal
             else:
             # key exisiting
@@ -2636,7 +2636,7 @@
     def sort(self, reverse=False):
         # self = JDict(sorted(self.items(),reverse=reverse)) will not work, see
         # http://stackoverflow.com/questions/1216356/
-        return JDict(sorted(self.items(),reverse=reverse))
+        return JDict(sorted(list(self.items()),reverse=reverse))
 
 class Moment(object):
     """A datetime like class, but with convenient attributes and methods
@@ -2879,15 +2879,15 @@
         try:
             file_count += 1
             c = read_line_count(file)
-            print "%s : %d" % (os.path.basename(file), c)
+            print("%s : %d" % (os.path.basename(file), c))
             line_count += c
         except:
             pass
 
-    print '-----------------------------'
-    print 'File counted: %d' % file_count
-    print 'Line counted: %d' % line_count
-    print 'Done!'
+    print('-----------------------------')
+    print('File counted: %d' % file_count)
+    print('Line counted: %d' % line_count)
+    print('Done!')
 
 def keygen(length=8, complexity=3):
     """generate a random key
@@ -2934,16 +2934,16 @@
             sha1.update(chunk)
     if reference:
         if reference.lower() == md5.hexdigest().lower():
-            print 'md5 32: ' + md5.hexdigest() + ' (matched)!'
-        else:
-            print 'md5 32: ' + md5.hexdigest() + ' (NOT MATCHED)!'
+            print('md5 32: ' + md5.hexdigest() + ' (matched)!')
+        else:
+            print('md5 32: ' + md5.hexdigest() + ' (NOT MATCHED)!')
         if reference.lower() == sha1.hexdigest().lower():
-            print 'sha1 32: ' + sha1.hexdigest() + ' (matched)!'
-        else:
-            print 'sha1 32: ' + sha1.hexdigest() + ' (NOT MATCHED)!'
-    else:
-        print 'md5 32: ' + md5.hexdigest()
-        print 'sha1 32: ' + sha1.hexdigest()
+            print('sha1 32: ' + sha1.hexdigest() + ' (matched)!')
+        else:
+            print('sha1 32: ' + sha1.hexdigest() + ' (NOT MATCHED)!')
+    else:
+        print('md5 32: ' + md5.hexdigest())
+        print('sha1 32: ' + sha1.hexdigest())
 
 def readx(path, sheet=0, r=[1,], c=None, *args, **kwargs):
     """
@@ -2975,24 +2975,24 @@
     sheetobj = wbobj.sheet_by_name(sheet)
 
     if r == None:
-        r = range(0,sheetobj.nrows)     # all rows
+        r = list(range(0,sheetobj.nrows))     # all rows
     elif type(r) in [int]:
         r = [r]     # a single row
     elif type(r) in [list]:
         if len(r) == 1:
-            r = range(r[0],sheetobj.nrows)  # from r to end
+            r = list(range(r[0],sheetobj.nrows))  # from r to end
         else:
             r = r   # multiple rows
     else:
         raise Exception('Invalid row number(s)')
 
     if c == None:
-        c = range(0,sheetobj.ncols)     # all cols
+        c = list(range(0,sheetobj.ncols))     # all cols
     elif type(c) in [int]:
         c = [c]    # a single col
     elif type(c) in [list]:
         if len(c) == 1:
-            c = range(c[0],sheetobj.ncols)  # from c to end
+            c = list(range(c[0],sheetobj.ncols))  # from c to end
         else:
             c = c   # multiple cols
     else:
@@ -3111,19 +3111,19 @@
     count = {}  
     for line in codecs.open(filename, 'r', encoding):  
         for chr in line:  
-            if u'\u4E00' <= chr <= u'\u9FA5' or  u'\uF900' <= chr <= u'\uFA2D':  
+            if '\u4E00' <= chr <= '\u9FA5' or  '\uF900' <= chr <= '\uFA2D':  
                 count[chr] = 1 + count.get(chr, 0)
 
-    hanzifreq = sorted(count.iteritems(), key=itemgetter(1), reverse=True)
+    hanzifreq = sorted(iter(count.items()), key=itemgetter(1), reverse=True)
     result = hanzifreq  # for return
     if size: hanzifreq = hanzifreq[:size]
 
-    print '\n'.join([u'%s\t%s' % (chr, times) for chr, times in hanzifreq]) 
+    print('\n'.join(['%s\t%s' % (chr, times) for chr, times in hanzifreq])) 
     if outfile:
         with codecs.open(outfile, mode='w', encoding='utf-8') as outFile:
-            outFile.write('\n'.join([u'%s,%s' % (chr, times) for chr, times in hanzifreq]))
+            outFile.write('\n'.join(['%s,%s' % (chr, times) for chr, times in hanzifreq]))
     
-    print 'Done! Elapsed %s seconds.' % (time()-begin)
+    print('Done! Elapsed %s seconds.' % (time()-begin))
     return result
 
 def chunk(xs, n):
@@ -3244,10 +3244,10 @@
         source_encoding = chardet.detect(content)['encoding']
 
     if source_encoding is None:
-        print "I cannot guess source encoding (try GB2312 for MS-Windows?)", file_path
+        print("I cannot guess source encoding (try GB2312 for MS-Windows?)", file_path)
         return None
     else:
-        print source_encoding, file_path
+        print(source_encoding, file_path)
 
     target_encoding = 'utf-8'
     if source_encoding != target_encoding:
--- ./ez/orderedset.py	(original)
+++ ./ez/orderedset.py	(refactored)
@@ -62,6 +62,6 @@
 if __name__ == '__main__':
     s = OrderedSet('abracadaba')
     t = OrderedSet('simsalabim')
-    print(s | t)
-    print(s & t)
-    print(s - t)
+    print((s | t))
+    print((s & t))
+    print((s - t))
--- ./ez/prepublish.py	(original)
+++ ./ez/prepublish.py	(refactored)
@@ -8,12 +8,12 @@
 here = path.abspath(path.dirname(__file__))
 
 # readme
-from __init__ import __doc__ as doc
+from .__init__ import __doc__ as doc
 with open(path.join(os.path.dirname(here), 'README.rst'), encoding='utf-8', mode='w') as f:
     f.write(doc)
 
 # version
-from version import __version__ as ver
+from .version import __version__ as ver
 ver = ver.replace('.','')
 ver=int(ver)
 ver += 1
--- ./ez/pyg.py	(original)
+++ ./ez/pyg.py	(refactored)
@@ -4,12 +4,12 @@
 
 # __doc__ at the bottom
 
-import atom
-import atom.data    #essential to pygcal
-import gdata
-import pygcal
-import pygmail
-import pygsheet
+from . import atom
+from . import atom.data    #essential to pygcal
+from . import gdata
+from . import pygcal
+from . import pygmail
+from . import pygsheet
 
 try:
     # EMAIL = "someone@gmail.com", PASSWORD = "abcdefghijkl"
--- ./ez/pygcal.py	(original)
+++ ./ez/pygcal.py	(refactored)
@@ -1,6 +1,6 @@
-import gdata.calendar.data
-import gdata.calendar.client
-import atom
+from . import gdata.calendar.data
+from . import gdata.calendar.client
+from . import atom
 
 
 class GoogleCalendar:
--- ./ez/pygmail.py	(original)
+++ ./ez/pygmail.py	(refactored)
@@ -17,7 +17,7 @@
     msg.set_charset('utf8')
 
     msg['From'] = "Memory Lab"
-    if type(to) not in [str, unicode]: to = ', '.join(to)
+    if type(to) not in [str, str]: to = ', '.join(to)
     msg['To'] = to
     msg['Subject'] = Header(subject.encode('utf-8'), 'UTF-8').encode()
     #This solve the problem with the encode on the subject.
@@ -25,7 +25,7 @@
     to = [to]
     if cc:
         # cc gets added to the text header as well as list of recipients
-        if type(cc) in [str, unicode]:
+        if type(cc) in [str, str]:
             msg.add_header('Cc', cc)
             cc = [cc]
         else:
@@ -33,7 +33,7 @@
         to += cc
     if bcc:
         # bcc does not get added to the headers, but is a recipient
-        if type(bcc) in [str, unicode]:
+        if type(bcc) in [str, str]:
             bcc = [bcc]
         to += bcc
     if reply_to:
@@ -47,7 +47,7 @@
         msg.attach(MIMEText(body.encode('utf-8'), 'plain', 'UTF-8'))
 
     if attachment:
-        if type(attachment) in [str, unicode]: attachment = [attachment]
+        if type(attachment) in [str, str]: attachment = [attachment]
         for att in attachment:
             mimetype, encoding = guess_type(att)
             if mimetype is None or encoding is not None:
@@ -82,11 +82,11 @@
     mailServer.ehlo()
     mailServer.starttls()
     mailServer.ehlo()
-    print 'logging into email account...'
+    print('logging into email account...')
     mailServer.login(EMAIL, PASSWORD)
-    print 'sending...'
+    print('sending...')
     mailServer.sendmail(EMAIL, to, msg.as_string())
     # Should be mailServer.quit(), but that crashes...
-    print 'finishing...'
+    print('finishing...')
     mailServer.close()
-    print 'done!'
+    print('done!')
--- ./ez/pygsheet.py	(original)
+++ ./ez/pygsheet.py	(refactored)
@@ -16,7 +16,7 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-import gdata.spreadsheet.service
+from . import gdata.spreadsheet.service
 
 
 ID_FIELD = '__rowid__'
@@ -63,8 +63,7 @@
             A list with information about the spreadsheets available
         """
         sheets = self._get_client().GetSpreadsheetsFeed()
-        return map(lambda e: (e.title.text, e.id.text.rsplit('/', 1)[1]),
-            sheets.entry)
+        return [(e.title.text, e.id.text.rsplit('/', 1)[1]) for e in sheets.entry]
 
     def list_worksheets(self, spreadsheet_key):
         """List Spreadsheets.
@@ -74,8 +73,7 @@
         """
         wks = self._get_client().GetWorksheetsFeed(
             key=spreadsheet_key)
-        return map(lambda e: (e.title.text, e.id.text.rsplit('/', 1)[1]),
-            wks.entry)
+        return [(e.title.text, e.id.text.rsplit('/', 1)[1]) for e in wks.entry]
 
     def get_worksheet(self, spreadsheet_key, worksheet_key):
         """Get Worksheet.
@@ -210,7 +208,7 @@
         rows = [self._row_to_dict(row)
             for row in self._get_row_entries(query=self.query)]
         if filter_func:
-            rows = filter(filter_func, rows)
+            rows = list(filter(filter_func, rows))
         return rows
 
     def update_row(self, row_data):
--- ./ez/xpinyin.py	(original)
+++ ./ez/xpinyin.py	(refactored)
@@ -1,16 +1,16 @@
 # -*- coding: utf-8 -*-
 
-from __future__ import unicode_literals
+
 
 import os.path
 import re
 
 PinyinToneMark = {
-    0: u"aoeiuv\u00fc",
-    1: u"\u0101\u014d\u0113\u012b\u016b\u01d6\u01d6",
-    2: u"\u00e1\u00f3\u00e9\u00ed\u00fa\u01d8\u01d8",
-    3: u"\u01ce\u01d2\u011b\u01d0\u01d4\u01da\u01da",
-    4: u"\u00e0\u00f2\u00e8\u00ec\u00f9\u01dc\u01dc",
+    0: "aoeiuv\u00fc",
+    1: "\u0101\u014d\u0113\u012b\u016b\u01d6\u01d6",
+    2: "\u00e1\u00f3\u00e9\u00ed\u00fa\u01d8\u01d8",
+    3: "\u01ce\u01d2\u011b\u01d0\u01d4\u01da\u01da",
+    4: "\u00e0\u00f2\u00e8\u00ec\u00f9\u01dc\u01dc",
 }
 
 
@@ -106,7 +106,7 @@
         if convert == 'upper':
             return word.upper()
 
--- ./ez/atom/__init__.py	(original)
+++ ./ez/atom/__init__.py	(refactored)
@@ -94,7 +94,7 @@
     # Preserve the original name to avoid masking all decorated functions as
     # 'deprecated_function'
     try:
-      optional_warn_function.func_name = f.func_name
+      optional_warn_function.__name__ = f.__name__
     except TypeError:
       pass # In Python2.3 we can't set the func_name
     return optional_warn_function
@@ -122,7 +122,7 @@
     match those of the target class.
   """
   encoding = string_encoding or XML_STRING_ENCODING
-  if encoding and isinstance(xml_string, unicode):
+  if encoding and isinstance(xml_string, str):
     xml_string = xml_string.encode(encoding)
   tree = ElementTree.fromstring(xml_string)
   return _CreateClassFromElementTree(target_class, tree)
@@ -184,11 +184,11 @@
     # Fill in the instance members from the contents of the XML tree.
     for child in tree:
       self._ConvertElementTreeToMember(child)
-    for attribute, value in tree.attrib.iteritems():
+    for attribute, value in tree.attrib.items():
       self._ConvertElementAttributeToMember(attribute, value)
     # Encode the text string according to the desired encoding type. (UTF-8)
     if tree.text:
-      if MEMBER_STRING_ENCODING is unicode:
+      if MEMBER_STRING_ENCODING is str:
         self.text = tree.text
       else:
         self.text = tree.text.encode(MEMBER_STRING_ENCODING)
@@ -200,7 +200,7 @@
   def _ConvertElementAttributeToMember(self, attribute, value):
     # Encode the attribute value's string with the desired type Default UTF-8
     if value:
-      if MEMBER_STRING_ENCODING is unicode:
+      if MEMBER_STRING_ENCODING is str:
         self.extension_attributes[attribute] = value
       else:
         self.extension_attributes[attribute] = value.encode(
@@ -210,15 +210,15 @@
   def _AddMembersToElementTree(self, tree):
     for child in self.extension_elements:
       child._BecomeChildElement(tree)
-    for attribute, value in self.extension_attributes.iteritems():
+    for attribute, value in self.extension_attributes.items():
       if value:
-        if isinstance(value, unicode) or MEMBER_STRING_ENCODING is unicode:
+        if isinstance(value, str) or MEMBER_STRING_ENCODING is str:
           tree.attrib[attribute] = value
         else:
           # Decode the value from the desired encoding (default UTF-8).
           tree.attrib[attribute] = value.decode(MEMBER_STRING_ENCODING)
     if self.text:
-      if isinstance(self.text, unicode) or MEMBER_STRING_ENCODING is unicode:
+      if isinstance(self.text, str) or MEMBER_STRING_ENCODING is str:
         tree.text = self.text
       else:
         tree.text = self.text.decode(MEMBER_STRING_ENCODING)
@@ -279,7 +279,7 @@
 
   def _ConvertElementTreeToMember(self, child_tree):
     # Find the element's tag in this class's list of child members
-    if self.__class__._children.has_key(child_tree.tag):
+    if child_tree.tag in self.__class__._children:
       member_name = self.__class__._children[child_tree.tag][0]
       member_class = self.__class__._children[child_tree.tag][1]
       # If the class member is supposed to contain a list, make sure the
@@ -298,13 +298,13 @@
 
   def _ConvertElementAttributeToMember(self, attribute, value):
     # Find the attribute in this class's list of attributes.
-    if self.__class__._attributes.has_key(attribute):
+    if attribute in self.__class__._attributes:
       # Find the member of this class which corresponds to the XML attribute
       # (lookup in current_class._attributes) and set this member to the
       # desired value (using self.__dict__).
       if value:
         # Encode the string to capture non-ascii characters (default UTF-8)
-        if MEMBER_STRING_ENCODING is unicode:
+        if MEMBER_STRING_ENCODING is str:
           setattr(self, self.__class__._attributes[attribute], value)
         else:
           setattr(self, self.__class__._attributes[attribute],
@@ -319,7 +319,7 @@
     # This uses the class's _children dictionary to find the members which
     # should become XML child nodes.
     member_node_names = [values[0] for tag, values in
-                                       self.__class__._children.iteritems()]
+                                       self.__class__._children.items()]
     for member_name in member_node_names:
       member = getattr(self, member_name)
       if member is None:
@@ -330,10 +330,10 @@
       else:
         member._BecomeChildElement(tree)
     # Convert the members of this class which are XML attributes.
-    for xml_attribute, member_name in self.__class__._attributes.iteritems():
+    for xml_attribute, member_name in self.__class__._attributes.items():
       member = getattr(self, member_name)
       if member is not None:
-        if isinstance(member, unicode) or MEMBER_STRING_ENCODING is unicode:
+        if isinstance(member, str) or MEMBER_STRING_ENCODING is str:
           tree.attrib[xml_attribute] = member
         else:
           tree.attrib[xml_attribute] = member.decode(MEMBER_STRING_ENCODING)
@@ -1375,7 +1375,7 @@
     else:
       element_tree.tag = self.tag
 
-    for key, value in self.attributes.iteritems():
+    for key, value in self.attributes.items():
       element_tree.attrib[key] = value
 
     for child in self.children:
@@ -1452,7 +1452,7 @@
     namespace = None
     tag = element_tag
   extension = ExtensionElement(namespace=namespace, tag=tag)
-  for key, value in element_tree.attrib.iteritems():
+  for key, value in element_tree.attrib.items():
     extension.attributes[key] = value
   for child in element_tree:
     extension.children.append(_ExtensionElementFromElementTree(child))
@@ -1476,7 +1476,7 @@
     # Preserve the original name to avoid masking all decorated functions as
     # 'deprecated_function'
     try:
-      deprecated_function.func_name = f.func_name
+      deprecated_function.__name__ = f.__name__
     except TypeError:
       # Setting the func_name is not allowed in Python2.3.
       pass
--- ./ez/atom/client.py	(original)
+++ ./ez/atom/client.py	(refactored)
@@ -85,15 +85,15 @@
     # Modify the request based on the AtomPubClient settings and parameters
     # passed in to the request.
     http_request = self.modify_request(http_request)
-    if isinstance(uri, (str, unicode)):
+    if isinstance(uri, str):
       uri = atom.http_core.Uri.parse_uri(uri)
     if uri is not None:
       uri.modify_request(http_request)
-    if isinstance(method, (str, unicode)):
+    if isinstance(method, str):
       http_request.method = method
     # Any unrecognized arguments are assumed to be capable of modifying the
     # HTTP request.
-    for name, value in kwargs.iteritems():
+    for name, value in kwargs.items():
       if value is not None:
         if hasattr(value, 'modify_request'):
           value.modify_request(http_request)
@@ -218,7 +218,7 @@
       An atom.http_core.HttpRequest() with the added custom headers.
     """
 
-    for name, value in self.headers.iteritems():
+    for name, value in self.headers.items():
       if value is not None:
         http_request.headers[name] = value
     return http_request
--- ./ez/atom/core.py	(original)
+++ ./ez/atom/core.py	(refactored)
@@ -93,7 +93,7 @@
       if not pair[0].startswith('_') and pair[0] != 'text':
         member_type = pair[1]
         if (isinstance(member_type, tuple) or isinstance(member_type, list)
-            or isinstance(member_type, (str, unicode))
+            or isinstance(member_type, str)
             or (inspect.isclass(member_type)
                 and issubclass(member_type, XmlElement))):
           members.append(pair)
@@ -173,7 +173,7 @@
             attributes[target[version-1]] = member_name
           else:
             attributes[target[-1]] = member_name
-        elif isinstance(target, (str, unicode)):
+        elif isinstance(target, str):
           # This member points to an XML attribute.
           attributes[target] = member_name
         elif issubclass(target, XmlElement):
@@ -207,7 +207,7 @@
     matches = []
     ignored1, elements, ignored2 = self.__class__._get_rules(version)
     if elements:
-      for qname, element_def in elements.iteritems():
+      for qname, element_def in elements.items():
         member = getattr(self, element_def[0])
         if member:
           if _qname_matches(tag, namespace, qname):
@@ -253,7 +253,7 @@
     matches = []
     ignored1, ignored2, attributes = self.__class__._get_rules(version)
     if attributes:
-      for qname, attribute_def in attributes.iteritems():
+      for qname, attribute_def in attributes.items():
         if isinstance(attribute_def, (list, tuple)):
           attribute_def = attribute_def[0]
         member = getattr(self, attribute_def)
@@ -262,7 +262,7 @@
         if member:
           if _qname_matches(tag, namespace, qname):
             matches.append(XmlAttribute(qname, member))
-    for qname, value in self._other_attributes.iteritems():
+    for qname, value in self._other_attributes.items():
       if _qname_matches(tag, namespace, qname):
         matches.append(XmlAttribute(qname, value))
     return matches
@@ -288,7 +288,7 @@
       else:
         self._other_elements.append(_xml_element_from_tree(element, XmlElement,
                                                            version))
-    for attrib, value in tree.attrib.iteritems():
+    for attrib, value in tree.attrib.items():
       if attributes and attrib in attributes:
         setattr(self, attributes[attrib], value)
       else:
@@ -318,7 +318,7 @@
     encoding = encoding or STRING_ENCODING
     # Add the expected elements and attributes to the tree.
     if elements:
-      for tag, element_def in elements.iteritems():
+      for tag, element_def in elements.items():
         member = getattr(self, element_def[0])
         # If this is a repeating element and there are members in the list.
         if member and element_def[2]:
@@ -327,21 +327,21 @@
         elif member:
           member._become_child(tree, version)
     if attributes:
-      for attribute_tag, member_name in attributes.iteritems():
+      for attribute_tag, member_name in attributes.items():
         value = getattr(self, member_name)
         if value:
           tree.attrib[attribute_tag] = value
     # Add the unexpected (other) elements and attributes to the tree.
     for element in self._other_elements:
       element._become_child(tree, version)
-    for key, value in self._other_attributes.iteritems():
+    for key, value in self._other_attributes.items():
       # I'm not sure if unicode can be used in the attribute name, so for now
       # we assume the encoding is correct for the attribute name.
-      if not isinstance(value, unicode):
+      if not isinstance(value, str):
         value = value.decode(encoding)
       tree.attrib[key] = value
     if self.text:
-      if isinstance(self.text, unicode):
+      if isinstance(self.text, str):
         tree.text = self.text
       else:
         tree.text = self.text.decode(encoding)
@@ -512,7 +512,7 @@
   """
   if target_class is None:
     target_class = XmlElement
-  if isinstance(xml_string, unicode):
+  if isinstance(xml_string, str):
     if encoding is None:
       xml_string = xml_string.encode(STRING_ENCODING)
     else:
--- ./ez/atom/http.py	(original)
+++ ./ez/atom/http.py	(refactored)
@@ -37,7 +37,7 @@
 
 import types
 import os
-import httplib
+import http.client
 import atom.url
 import atom.http_interface
 import socket
@@ -103,7 +103,7 @@
     # If the list of headers does not include a Content-Length, attempt to
     # calculate it based on the data object.
     if data and 'Content-Length' not in all_headers:
-      if isinstance(data, types.StringTypes):
+      if isinstance(data, (str,)):
         all_headers['Content-Length'] = str(len(data))
       else:
         raise atom.http_interface.ContentLengthRequired('Unable to calculate '
@@ -123,7 +123,7 @@
       return self.v2_http_client.request(http_request=http_request)
 
     if not isinstance(url, atom.url.Url):
-      if isinstance(url, types.StringTypes):
+      if isinstance(url, (str,)):
         url = atom.url.parse_url(url)
       else:
         raise atom.http_interface.UnparsableUrlObject('Unable to parse url '
@@ -175,19 +175,19 @@
     
   def _prepare_connection(self, url, headers):
     if not isinstance(url, atom.url.Url):
-      if isinstance(url, types.StringTypes):
+      if isinstance(url, (str,)):
         url = atom.url.parse_url(url)
       else:
         raise atom.http_interface.UnparsableUrlObject('Unable to parse url '
             'parameter because it was not a string or atom.url.Url')
     if url.protocol == 'https':
       if not url.port:
-        return httplib.HTTPSConnection(url.host)
-      return httplib.HTTPSConnection(url.host, int(url.port))
+        return http.client.HTTPSConnection(url.host)
+      return http.client.HTTPSConnection(url.host, int(url.port))
     else:
       if not url.port:
-        return httplib.HTTPConnection(url.host)
-      return httplib.HTTPConnection(url.host, int(url.port))
+        return http.client.HTTPConnection(url.host)
+      return http.client.HTTPConnection(url.host, int(url.port))
 
   def _get_access_url(self, url):
     return url.to_string()
@@ -259,10 +259,10 @@
           sslobj = ssl.wrap_socket(p_sock, None, None)
         else:
           sock_ssl = socket.ssl(p_sock, None, None)
-          sslobj = httplib.FakeSocket(p_sock, sock_ssl)
+          sslobj = http.client.FakeSocket(p_sock, sock_ssl)
  
         # Initalize httplib and replace with the proxy socket.
-        connection = httplib.HTTPConnection(proxy_url.host)
+        connection = http.client.HTTPConnection(proxy_url.host)
         connection.sock = sslobj
         return connection
       else:
@@ -275,7 +275,7 @@
         if proxy_auth:
           headers['Proxy-Authorization'] = proxy_auth.strip()
 
-        return httplib.HTTPConnection(proxy_url.host, int(proxy_url.port))
+        return http.client.HTTPConnection(proxy_url.host, int(proxy_url.port))
 
   def _get_access_url(self, url):
     return url.to_string()
@@ -343,7 +343,7 @@
 
 
 def _send_data_part(data, connection):
-  if isinstance(data, types.StringTypes):
+  if isinstance(data, (str,)):
     connection.send(data)
     return
   # Check to see if data is a file-like object that has a read method.
--- ./ez/atom/http_core.py	(original)
+++ ./ez/atom/http_core.py	(refactored)
@@ -23,10 +23,10 @@
 
 
 import os
-import StringIO
-import urlparse
-import urllib
-import httplib
+import io
+import urllib.parse
+import urllib.request, urllib.parse, urllib.error
+import http.client
 ssl = None
 try:
   import ssl
@@ -97,7 +97,7 @@
     self._body_parts = []
     if method is not None:
       self.method = method
-    if isinstance(uri, (str, unicode)):
+    if isinstance(uri, str):
       uri = Uri.parse_uri(uri)
     self.uri = uri or Uri()
 
@@ -184,7 +184,7 @@
       mime_type: str The MIME type of the form data being sent. Defaults
                  to 'application/x-www-form-urlencoded'.
     """
-    body = urllib.urlencode(form_data)
+    body = urllib.parse.urlencode(form_data)
     self.add_body_part(body, mime_type)
 
   AddFormInputs = add_form_inputs
@@ -206,12 +206,12 @@
     """
     output =  'HTTP Request\n  method: %s\n  url: %s\n  headers:\n' % (
         self.method, str(self.uri))
-    for header, value in self.headers.iteritems():
+    for header, value in self.headers.items():
       output += '    %s: %s\n' % (header, value)
     output += '  body sections:\n'
     i = 0
     for part in self._body_parts:
-      if isinstance(part, (str, unicode)):
+      if isinstance(part, str):
         output += '    %s: %s\n' % (i, part)
       else:
         output += '    %s: <file like object>\n' % i
@@ -260,12 +260,12 @@
 
   def _get_query_string(self):
     param_pairs = []
-    for key, value in self.query.iteritems():
-      quoted_key = urllib.quote_plus(str(key))
+    for key, value in self.query.items():
+      quoted_key = urllib.parse.quote_plus(str(key))
       if value is None:
         param_pairs.append(quoted_key)
       else:
-        quoted_value = urllib.quote_plus(str(value))
+        quoted_value = urllib.parse.quote_plus(str(value))
         param_pairs.append('%s=%s' % (quoted_key, quoted_value))
     return '&'.join(param_pairs)
 
@@ -329,7 +329,7 @@
     This method can accept partial URIs, but it will leave missing
     members of the Uri unset.
     """
-    parts = urlparse.urlparse(uri_string)
+    parts = urllib.parse.urlparse(uri_string)
     uri = Uri()
     if parts[0]:
       uri.scheme = parts[0]
@@ -346,10 +346,10 @@
       for pair in param_pairs:
         pair_parts = pair.split('=')
         if len(pair_parts) > 1:
-          uri.query[urllib.unquote_plus(pair_parts[0])] = (
-              urllib.unquote_plus(pair_parts[1]))
+          uri.query[urllib.parse.unquote_plus(pair_parts[0])] = (
+              urllib.parse.unquote_plus(pair_parts[1]))
         elif len(pair_parts) == 1:
-          uri.query[urllib.unquote_plus(pair_parts[0])] = None
+          uri.query[urllib.parse.unquote_plus(pair_parts[0])] = None
     return uri
 
   parse_uri = staticmethod(parse_uri)
@@ -378,7 +378,7 @@
       if hasattr(body, 'read'):
         self._body = body
       else:
-        self._body = StringIO.StringIO(body)
+        self._body = io.StringIO(body)
 
   def getheader(self, name, default=None):
     if name in self._headers:
@@ -407,7 +407,7 @@
       http_response.status, http_response.reason)
   headers = get_headers(http_response)
   if isinstance(headers, dict):
-    for header, value in headers.iteritems():
+    for header, value in headers.items():
       output += '    %s: %s\n' % (header, value)
   else:
     for pair in headers:
@@ -436,14 +436,14 @@
     connection = None
     if uri.scheme == 'https':
       if not uri.port:
-        connection = httplib.HTTPSConnection(uri.host)
+        connection = http.client.HTTPSConnection(uri.host)
       else:
-        connection = httplib.HTTPSConnection(uri.host, int(uri.port))
+        connection = http.client.HTTPSConnection(uri.host, int(uri.port))
     else:
       if not uri.port:
-        connection = httplib.HTTPConnection(uri.host)
+        connection = http.client.HTTPConnection(uri.host)
       else:
-        connection = httplib.HTTPConnection(uri.host, int(uri.port))
+        connection = http.client.HTTPConnection(uri.host, int(uri.port))
     return connection
 
   def _http_request(self, method, uri, headers=None, body_parts=None):
@@ -458,7 +458,7 @@
                   which can be converted to strings using str. Each of these
                   will be sent in order as the body of the HTTP request.
     """
-    if isinstance(uri, (str, unicode)):
+    if isinstance(uri, str):
       uri = Uri.parse_uri(uri)
 
     connection = self._get_connection(uri, headers=headers)
@@ -488,12 +488,12 @@
         pass
 
     # Send the HTTP headers.
-    for header_name, value in headers.iteritems():
+    for header_name, value in headers.items():
       connection.putheader(header_name, value)
     connection.endheaders()
 
     # If there is data, send it in the request.
-    if body_parts and filter(lambda x: x != '', body_parts):
+    if body_parts and [x for x in body_parts if x != '']:
       for part in body_parts:
         _send_data_part(part, connection)
 
@@ -502,7 +502,7 @@
 
 
 def _send_data_part(data, connection):
-  if isinstance(data, (str, unicode)):
+  if isinstance(data, str):
     # I might want to just allow str, not unicode.
     connection.send(data)
     return
@@ -570,9 +570,9 @@
         sslobj = ssl.wrap_socket(p_sock, None, None)
       else:
         sock_ssl = socket.ssl(p_sock, None, Nonesock_)
-        sslobj = httplib.FakeSocket(p_sock, sock_ssl)
+        sslobj = http.client.FakeSocket(p_sock, sock_ssl)
       # Initalize httplib and replace with the proxy socket.
-      connection = httplib.HTTPConnection(proxy_uri.host)
+      connection = http.client.HTTPConnection(proxy_uri.host)
       connection.sock = sslobj
       return connection
     elif uri.scheme == 'http':
@@ -581,7 +581,7 @@
         proxy_uri.port = '80'
       if proxy_auth:
         headers['Proxy-Authorization'] = proxy_auth.strip()
-      return httplib.HTTPConnection(proxy_uri.host, int(proxy_uri.port))
+      return http.client.HTTPConnection(proxy_uri.host, int(proxy_uri.port))
     return None
 
 
--- ./ez/atom/http_interface.py	(original)
+++ ./ez/atom/http_interface.py	(refactored)
@@ -33,7 +33,7 @@
 __author__ = 'api.jscudder (Jeff Scudder)'
 
 
-import StringIO
+import io
 
 
 USER_AGENT = '%s GData-Python/2.0.18'
@@ -74,7 +74,7 @@
       if hasattr(body, 'read'):
         self._body = body
       else:
-        self._body = StringIO.StringIO(body)
+        self._body = io.StringIO(body)
     else:
       self._body = None
     if status is not None:
--- ./ez/atom/mock_http.py	(original)
+++ ./ez/atom/mock_http.py	(refactored)
@@ -35,7 +35,7 @@
   """
   def __init__(self, operation, url, data=None, headers=None):
     self.operation = operation
-    if isinstance(url, (str, unicode)):
+    if isinstance(url, str):
       url = atom.url.parse_url(url)
     self.url = url
     self.data = data
@@ -112,7 +112,7 @@
     If there is no match, a NoRecordingFound error will be raised.
     """
     if self.real_client is None:
-      if isinstance(url, (str, unicode)):
+      if isinstance(url, str):
         url = atom.url.parse_url(url)
       for recording in self.recordings:
         if recording[0].operation == operation and recording[0].url == url:
--- ./ez/atom/mock_http_core.py	(original)
+++ ./ez/atom/mock_http_core.py	(refactored)
@@ -21,7 +21,7 @@
 __author__ = 'j.s@google.com (Jeff Scudder)'
 
 
-import StringIO
+import io
 import pickle
 import os.path
 import tempfile
@@ -250,7 +250,7 @@
                               http_request.headers, http_request._body_parts)
 
   def _http_request(self, uri, method, headers=None, body_parts=None):
-    body = StringIO.StringIO()
+    body = io.StringIO()
     response = atom.http_core.HttpResponse(status=200, reason='OK', body=body)
     if headers is None:
       response._headers = {}
@@ -258,7 +258,7 @@
       # Copy headers from the request to the response but convert values to
       # strings. Server response headers always come in as strings, so an int
       # should be converted to a corresponding string when echoing.
-      for header, value in headers.iteritems():
+      for header, value in headers.items():
         response._headers[header] = str(value)
     response._headers['Echo-Host'] = '%s:%s' % (uri.host, str(uri.port))
     response._headers['Echo-Uri'] = uri._get_relative_path()
--- ./ez/atom/mock_service.py	(original)
+++ ./ez/atom/mock_service.py	(refactored)
@@ -168,7 +168,7 @@
 
   def ConcealSecrets(self, conceal_func):
     """Conceal secret data in this request."""
-    if self.extra_headers.has_key('Authorization'):
+    if 'Authorization' in self.extra_headers:
       self.extra_headers['Authorization'] = conceal_func(
         self.extra_headers['Authorization'])
 
--- ./ez/atom/service.py	(original)
+++ ./ez/atom/service.py	(refactored)
@@ -36,8 +36,8 @@
 import atom.token_store
 
 import os
-import httplib
-import urllib
+import http.client
+import urllib.request, urllib.parse, urllib.error
 import re
 import base64
 import socket
@@ -151,7 +151,7 @@
   #@atom.v1_deprecated('Please use atom.client.AtomPubClient for requests.')
   def request(self, operation, url, data=None, headers=None, 
       url_params=None):
-    if isinstance(url, (str, unicode)):
+    if isinstance(url, str):
       if url.startswith('http:') and self.ssl:
         # Force all requests to be https if self.ssl is True.
         url = atom.url.parse_url('https:' + url[5:])
@@ -163,7 +163,7 @@
         url = atom.url.parse_url(url)
 
     if url_params:
-      for name, value in url_params.iteritems():
+      for name, value in url_params.items():
         url.params[name] = value
 
     all_headers = self.additional_headers.copy()
@@ -347,12 +347,12 @@
   def valid_for_scope(self, url):
     """Tells the caller if the token authorizes access to the desired URL.
     """
-    if isinstance(url, (str, unicode)):
+    if isinstance(url, str):
       url = atom.url.parse_url(url)
     for scope in self.scopes:
       if scope == atom.token_store.SCOPE_ALL:
         return True
-      if isinstance(scope, (str, unicode)):
+      if isinstance(scope, str):
         scope = atom.url.parse_url(scope)
       if scope == url:
         return True
@@ -430,15 +430,15 @@
 
       # Trivial setup for ssl socket.
       ssl = socket.ssl(p_sock, None, None)
-      fake_sock = httplib.FakeSocket(p_sock, ssl)
+      fake_sock = http.client.FakeSocket(p_sock, ssl)
 
       # Initalize httplib and replace with the proxy socket.
-      connection = httplib.HTTPConnection(server)
+      connection = http.client.HTTPConnection(server)
       connection.sock=fake_sock
       full_uri = partial_uri
 
     else:
-      connection = httplib.HTTPSConnection(server, port)
+      connection = http.client.HTTPSConnection(server, port)
       full_uri = partial_uri
 
   else:
@@ -454,14 +454,14 @@
         proxy_password = os.environ.get('proxy_password')
       if proxy_username:
         UseBasicAuth(service, proxy_username, proxy_password, True)
-      connection = httplib.HTTPConnection(p_server, p_port)
+      connection = http.client.HTTPConnection(p_server, p_port)
       if not full_uri.startswith("http://"):
         if full_uri.startswith("/"):
           full_uri = "http://%s%s" % (service.server, full_uri)
         else:
           full_uri = "http://%s/%s" % (service.server, full_uri)
     else:
-      connection = httplib.HTTPConnection(server, port)
+      connection = http.client.HTTPConnection(server, port)
       full_uri = partial_uri
 
   return (connection, full_uri)
@@ -544,11 +544,11 @@
   """
   # Choose which function to use when modifying the query and parameters.
   # Use quote_plus when escape_params is true.
-  transform_op = [str, urllib.quote_plus][bool(escape_params)]
+  transform_op = [str, urllib.parse.quote_plus][bool(escape_params)]
   # Create a list of tuples containing the escaped version of the
   # parameter-value pairs.
   parameter_tuples = [(transform_op(param), transform_op(value))
-                     for param, value in (url_parameters or {}).items()]
+                     for param, value in list((url_parameters or {}).items())]
   # Turn parameter-value tuples into a list of strings in the form
   # 'PARAMETER=VALUE'.
   return ['='.join(x) for x in parameter_tuples]
@@ -658,8 +658,8 @@
 
   # If the list of headers does not include a Content-Length, attempt to 
   # calculate it based on the data object.
-  if (data and not service.additional_headers.has_key('Content-Length') and 
-      not extra_headers.has_key('Content-Length')):
+  if (data and 'Content-Length' not in service.additional_headers and 
+      'Content-Length' not in extra_headers):
     content_length = CalculateDataLength(data)
     if content_length:
       extra_headers['Content-Length'] = str(content_length)
--- ./ez/atom/token_store.py	(original)
+++ ./ez/atom/token_store.py	(refactored)
@@ -78,7 +78,7 @@
     """
     if url is None:
       return None
-    if isinstance(url, (str, unicode)):
+    if isinstance(url, str):
       url = atom.url.parse_url(url)
     if url in self._tokens:
       token = self._tokens[url]
@@ -86,7 +86,7 @@
         return token
       else:
         del self._tokens[url]
-    for scope, token in self._tokens.iteritems():
+    for scope, token in self._tokens.items():
       if token.valid_for_scope(url):
         return token
     return atom.http_interface.GenericToken()
@@ -105,7 +105,7 @@
     """
     token_found = False
     scopes_to_delete = []
-    for scope, stored_token in self._tokens.iteritems():
+    for scope, stored_token in self._tokens.items():
       if stored_token == token:
         scopes_to_delete.append(scope)
         token_found = True
--- ./ez/atom/url.py	(original)
+++ ./ez/atom/url.py	(refactored)
@@ -18,8 +18,8 @@
 __author__ = 'api.jscudder (Jeff Scudder)'
 
 
-import urlparse
-import urllib
+import urllib.parse
+import urllib.request, urllib.parse, urllib.error
 
 
 DEFAULT_PROTOCOL = 'http'
@@ -32,7 +32,7 @@
   This method can accept partial URLs, but it will leave missing
   members of the Url unset.
   """
-  parts = urlparse.urlparse(url_string)
+  parts = urllib.parse.urlparse(url_string)
   url = Url()
   if parts[0]:
     url.protocol = parts[0]
@@ -49,10 +49,10 @@
     for pair in param_pairs:
       pair_parts = pair.split('=')
       if len(pair_parts) > 1:
-        url.params[urllib.unquote_plus(pair_parts[0])] = (
-            urllib.unquote_plus(pair_parts[1]))
+        url.params[urllib.parse.unquote_plus(pair_parts[0])] = (
+            urllib.parse.unquote_plus(pair_parts[1]))
       elif len(pair_parts) == 1:
-        url.params[urllib.unquote_plus(pair_parts[0])] = None
+        url.params[urllib.parse.unquote_plus(pair_parts[0])] = None
   return url
    
 class Url(object):
@@ -84,13 +84,13 @@
       url_parts[2] = self.path
     if self.params:
       url_parts[4] = self.get_param_string()
-    return urlparse.urlunparse(url_parts)
+    return urllib.parse.urlunparse(url_parts)
 
   def get_param_string(self):
     param_pairs = []
-    for key, value in self.params.iteritems():
-      param_pairs.append('='.join((urllib.quote_plus(key), 
-          urllib.quote_plus(str(value)))))
+    for key, value in self.params.items():
+      param_pairs.append('='.join((urllib.parse.quote_plus(key), 
+          urllib.parse.quote_plus(str(value)))))
     return '&'.join(param_pairs)
 
   def get_request_uri(self):
--- ./ez/gdata/auth.py	(original)
+++ ./ez/gdata/auth.py	(refactored)
@@ -21,7 +21,7 @@
 import re
 import time
 import types
-import urllib
+import urllib.request, urllib.parse, urllib.error
 import atom.http_interface
 import atom.token_store
 import atom.url
@@ -30,11 +30,11 @@
 try:
   import gdata.tlslite.utils.keyfactory as keyfactory
 except ImportError:
-  from tlslite.tlslite.utils import keyfactory
+  from .tlslite.tlslite.utils import keyfactory
 try:
   import gdata.tlslite.utils.cryptomath as cryptomath
 except ImportError:
-  from tlslite.tlslite.utils import cryptomath
+  from .tlslite.tlslite.utils import cryptomath
 
 import gdata.gauth
 
@@ -263,7 +263,7 @@
       callback_url += '&'
     else:
       callback_url += '?'
-    callback_url += urllib.urlencode({scopes_param_prefix:scopes})  
+    callback_url += urllib.parse.urlencode({scopes_param_prefix:scopes})  
   oauth_token = oauth.OAuthToken(request_token.key, request_token.secret)
   oauth_request = oauth.OAuthRequest.from_token_and_callback(
       token=oauth_token, callback=callback_url,
@@ -342,7 +342,7 @@
   else:
     session = 0
 
-  request_params = urllib.urlencode({'next': next, 'scope': scope,
+  request_params = urllib.parse.urlencode({'next': next, 'scope': scope,
                                      'secure': secure, 'session': session, 
                                      'hd': domain})
   if request_url.find('?') == -1:
@@ -391,12 +391,12 @@
     An atom.url.Url which the user's browser should be directed to in order
     to authorize this application to access their information.
   """
-  if isinstance(next, (str, unicode)):
+  if isinstance(next, str):
     next = atom.url.parse_url(next)
   scopes_string = ' '.join([str(scope) for scope in scopes])
   next.params[scopes_param_prefix] = scopes_string
 
-  if isinstance(request_url, (str, unicode)):
+  if isinstance(request_url, str):
     request_url = atom.url.parse_url(request_url)
   request_url.params['next'] = str(next)
   request_url.params['scope'] = scopes_string
@@ -471,7 +471,7 @@
     the AuthSubToken defaults to being valid for no scopes. If there was no
     'token' parameter in the URL, this function returns None.
   """
-  if isinstance(url, (str, unicode)):
+  if isinstance(url, str):
     url = atom.url.parse_url(url)
   if 'token' not in url.params:
     return None
@@ -557,7 +557,7 @@
     the OAuthToken defaults to being valid for no scopes. If there was no
     'oauth_token' parameter in the URL, this function returns None.
   """
-  if isinstance(url, (str, unicode)):
+  if isinstance(url, str):
     url = atom.url.parse_url(url)
   if 'oauth_token' not in url.params:
     return None
@@ -740,12 +740,12 @@
   def valid_for_scope(self, url):
     """Tells the caller if the token authorizes access to the desired URL.
     """
-    if isinstance(url, (str, unicode)):
+    if isinstance(url, str):
       url = atom.url.parse_url(url)
     for scope in self.scopes:
       if scope == atom.token_store.SCOPE_ALL:
         return True
-      if isinstance(scope, (str, unicode)):
+      if isinstance(scope, str):
         scope = atom.url.parse_url(scope)
       if scope == url:
         return True
@@ -810,7 +810,7 @@
       oauth_token_secret=[1]. If both are absent, it returns None.
     """
     if self.key and self.secret:
-      return urllib.urlencode({'oauth_token': self.key,
+      return urllib.parse.urlencode({'oauth_token': self.key,
                                'oauth_token_secret': self.secret})
     elif self.key:
       return 'oauth_token=%s' % self.key
@@ -847,7 +847,7 @@
       dict Header to be sent with every subsequent request after
       authentication.
     """
-    if isinstance(http_url, types.StringTypes):
+    if isinstance(http_url, (str,)):
       http_url = atom.url.parse_url(http_url)
     header = None
     token = None
@@ -874,12 +874,12 @@
     return http_client.request(operation, url, data=data, headers=headers)
     
   def valid_for_scope(self, url):
-    if isinstance(url, (str, unicode)):
+    if isinstance(url, str):
       url = atom.url.parse_url(url)
     for scope in self.scopes:
       if scope == atom.token_store.SCOPE_ALL:
         return True
-      if isinstance(scope, (str, unicode)):
+      if isinstance(scope, str):
         scope = atom.url.parse_url(scope)
       if scope == url:
         return True
--- ./ez/gdata/client.py	(original)
+++ ./ez/gdata/client.py	(refactored)
@@ -240,7 +240,7 @@
       body will be converted to the class using
       atom.core.parse.
     """
-    if isinstance(uri, (str, unicode)):
+    if isinstance(uri, str):
       uri = atom.http_core.Uri.parse_uri(uri)
 
     # Add the gsession ID to the URL to prevent further redirects.
@@ -742,7 +742,7 @@
 
     # If the user passes in a URL, just delete directly, may not work as
     # the service might require an ETag.
-    if isinstance(entry_or_uri, (str, unicode, atom.http_core.Uri)):
+    if isinstance(entry_or_uri, (str, atom.http_core.Uri)):
       return self.request(method='DELETE', uri=entry_or_uri,
                           http_request=http_request, auth_token=auth_token,
                           **kwargs)
@@ -1037,7 +1037,7 @@
                                      http_request=http_request,
                                      desired_class=self.desired_class)
       return response
-    except RequestError, error:
+    except RequestError as error:
       if error.status == 308:
         return None
       else:
@@ -1183,7 +1183,7 @@
       else:
         raise error_from_response(
             '%s returned by server' % response.status, response, RequestError)
-    except RequestError, error:
+    except RequestError as error:
       if error.status == 308:
         for pair in error.headers:
           if pair[0].capitalize() == 'Range':
--- ./ez/gdata/core.py	(original)
+++ ./ez/gdata/core.py	(refactored)
@@ -51,7 +51,7 @@
     # Recursively transform all members of the dict.
     # When converting a dict, we do not convert _name items into private
     # Jsonc members.
-    for key, value in x.iteritems():
+    for key, value in x.items():
       jsonc_obj._dict[key] = _convert_to_jsonc(value)
     return jsonc_obj
   elif isinstance(x, list):
@@ -112,7 +112,7 @@
 
   if isinstance(jsonc_obj, Jsonc):
     plain = {}
-    for key, value in jsonc_obj._dict.iteritems():
+    for key, value in jsonc_obj._dict.items():
       plain[key] = _convert_to_object(value)
     return plain
   elif isinstance(jsonc_obj, list):
@@ -232,7 +232,7 @@
 
   def __init__(self, _dict=None, **kwargs):
     json = _dict or {}
-    for key, value in kwargs.iteritems():
+    for key, value in kwargs.items():
       if key.startswith('_'):
         object.__setattr__(self, key, value)
       else:
--- ./ez/gdata/gauth.py	(original)
+++ ./ez/gdata/gauth.py	(refactored)
@@ -49,8 +49,8 @@
 import datetime
 import time
 import random
-import urllib
-import urlparse
+import urllib.request, urllib.parse, urllib.error
+import urllib.parse
 import atom.http_core
 
 try:
@@ -66,7 +66,7 @@
     import json as simplejson
 
 try:
-    from urlparse import parse_qsl
+    from urllib.parse import parse_qsl
 except ImportError:
     from cgi import parse_qsl
 
@@ -216,7 +216,7 @@
     # user is responding to a captch challenge.
     request_fields['logintoken'] = captcha_token
     request_fields['logincaptcha'] = captcha_response
-  return urllib.urlencode(request_fields)
+  return urllib.parse.urlencode(request_fields)
 
 
 GenerateClientLoginRequestBody = generate_client_login_request_body
@@ -301,7 +301,7 @@
 
 # AuthSub functions and classes.
 def _to_uri(str_or_uri):
-  if isinstance(str_or_uri, (str, unicode)):
+  if isinstance(str_or_uri, str):
     return atom.http_core.Uri.parse_uri(str_or_uri)
   return str_or_uri
 
@@ -350,16 +350,16 @@
     An atom.http_core.Uri which the user's browser should be directed to in
     order to authorize this application to access their information.
   """
-  if isinstance(next, (str, unicode)):
+  if isinstance(next, str):
     next = atom.http_core.Uri.parse_uri(next)
   # If the user passed in a string instead of a list for scopes, convert to
   # a single item tuple.
-  if isinstance(scopes, (str, unicode, atom.http_core.Uri)):
+  if isinstance(scopes, (str, atom.http_core.Uri)):
     scopes = (scopes,)
   scopes_string = ' '.join([str(scope) for scope in scopes])
   next.query[scopes_param_prefix] = scopes_string
 
-  if isinstance(request_url, (str, unicode)):
+  if isinstance(request_url, str):
     request_url = atom.http_core.Uri.parse_uri(request_url)
   request_url.query['next'] = str(next)
   request_url.query['scope'] = scopes_string
@@ -400,7 +400,7 @@
     None. If there was no token param in the url, the tuple returned is
     (None, None)
   """
-  if isinstance(url, (str, unicode)):
+  if isinstance(url, str):
     url = atom.http_core.Uri.parse_uri(url)
   if 'token' not in url.query:
     return (None, None)
@@ -501,12 +501,12 @@
   """Signs the data string for a secure AuthSub request."""
   import base64
   try:
-    from tlslite.utils import keyfactory
+    from .tlslite.utils import keyfactory
   except ImportError:
     try:
       from gdata.tlslite.utils import keyfactory
     except ImportError:
-      from tlslite.tlslite.utils import keyfactory
+      from .tlslite.tlslite.utils import keyfactory
 
   private_key = keyfactory.parsePrivateKey(rsa_key)
   signed = private_key.hashAndSign(data)
@@ -557,7 +557,7 @@
           not be valid.
     """
     timestamp = str(int(time.time()))
-    nonce = ''.join([str(random.randint(0, 9)) for i in xrange(15)])
+    nonce = ''.join([str(random.randint(0, 9)) for i in range(15)])
     data = build_auth_sub_data(http_request, timestamp, nonce)
     signature = generate_signature(data, self.rsa_private_key)
     http_request.headers['Authorization'] = (
@@ -621,14 +621,14 @@
     sorted_keys = sorted(params.keys())
   # The sorted function is not available in Python2.3 and lower
   except NameError:
-    sorted_keys = params.keys()
+    sorted_keys = list(params.keys())
     sorted_keys.sort()
   pairs = []
   for key in sorted_keys:
-    pairs.append('%s=%s' % (urllib.quote(key, safe='~'),
-                            urllib.quote(params[key], safe='~')))
+    pairs.append('%s=%s' % (urllib.parse.quote(key, safe='~'),
+                            urllib.parse.quote(params[key], safe='~')))
   # We want to escape /'s too, so use safe='~'
-  all_parameters = urllib.quote('&'.join(pairs), safe='~')
+  all_parameters = urllib.parse.quote('&'.join(pairs), safe='~')
   normailzed_host = http_request.uri.host.lower()
   normalized_scheme = (http_request.uri.scheme or 'http').lower()
   non_default_port = None
@@ -643,12 +643,12 @@
   if non_default_port is not None:
     # Set the only safe char in url encoding to ~ since we want to escape /
     # as well.
-    request_path = urllib.quote('%s://%s:%s%s' % (
+    request_path = urllib.parse.quote('%s://%s:%s%s' % (
         normalized_scheme, normailzed_host, non_default_port, path), safe='~')
   else:
     # Set the only safe char in url encoding to ~ since we want to escape /
     # as well.
-    request_path = urllib.quote('%s://%s%s' % (
+    request_path = urllib.parse.quote('%s://%s%s' % (
         normalized_scheme, normailzed_host, path), safe='~')
   # TODO: ensure that token escaping logic is correct, not sure if the token
   # value should be double escaped instead of single.
@@ -669,10 +669,10 @@
   hash_key = None
   hashed = None
   if token_secret is not None:
-    hash_key = '%s&%s' % (urllib.quote(consumer_secret, safe='~'),
-                          urllib.quote(token_secret, safe='~'))
+    hash_key = '%s&%s' % (urllib.parse.quote(consumer_secret, safe='~'),
+                          urllib.parse.quote(token_secret, safe='~'))
   else:
-    hash_key = '%s&' % urllib.quote(consumer_secret, safe='~')
+    hash_key = '%s&' % urllib.parse.quote(consumer_secret, safe='~')
   try:
     import hashlib
     hashed = hmac.new(hash_key, base_string, hashlib.sha1)
@@ -691,12 +691,12 @@
                            token=None, token_secret=None, verifier=None):
   import base64
   try:
-    from tlslite.utils import keyfactory
+    from .tlslite.utils import keyfactory
   except ImportError:
     try:
       from gdata.tlslite.utils import keyfactory
     except ImportError:
-      from tlslite.tlslite.utils import keyfactory
+      from .tlslite.tlslite.utils import keyfactory
   base_string = build_oauth_base_string(
       http_request, consumer_key, nonce, RSA_SHA1, timestamp, version,
       next, token, verifier=verifier)
@@ -746,7 +746,7 @@
     params['oauth_verifier'] = verifier
   pairs = [
       '%s="%s"' % (
-          k, urllib.quote(v, safe='~')) for k, v in params.iteritems()]
+          k, urllib.parse.quote(v, safe='~')) for k, v in params.items()]
   return 'OAuth %s' % (', '.join(pairs))
 
 
@@ -789,7 +789,7 @@
     request.uri.query['scope'] = ' '.join(scopes)
 
   timestamp = str(int(time.time()))
-  nonce = ''.join([str(random.randint(0, 9)) for i in xrange(15)])
+  nonce = ''.join([str(random.randint(0, 9)) for i in range(15)])
   signature = None
   if signature_type == HMAC_SHA1:
     signature = generate_hmac_signature(
@@ -843,9 +843,9 @@
   token_secret = None
   for pair in http_body.split('&'):
     if pair.startswith('oauth_token='):
-      token = urllib.unquote(pair[len('oauth_token='):])
+      token = urllib.parse.unquote(pair[len('oauth_token='):])
     if pair.startswith('oauth_token_secret='):
-      token_secret = urllib.unquote(pair[len('oauth_token_secret='):])
+      token_secret = urllib.parse.unquote(pair[len('oauth_token_secret='):])
   return (token, token_secret)
 
 
@@ -914,14 +914,14 @@
     A tuple of strings containing the OAuth token and the OAuth verifier which
     need to sent when upgrading a request token to an access token.
   """
-  if isinstance(url, (str, unicode)):
+  if isinstance(url, str):
     url = atom.http_core.Uri.parse_uri(url)
   token = None
   verifier = None
   if 'oauth_token' in url.query:
-    token = urllib.unquote(url.query['oauth_token'])
+    token = urllib.parse.unquote(url.query['oauth_token'])
   if 'oauth_verifier' in url.query:
-    verifier = urllib.unquote(url.query['oauth_verifier'])
+    verifier = urllib.parse.unquote(url.query['oauth_verifier'])
   return (token, verifier)
 
 
@@ -1040,14 +1040,14 @@
       The same HTTP request object which was passed in.
     """
     timestamp = str(int(time.time()))
-    nonce = ''.join([str(random.randint(0, 9)) for i in xrange(15)])
+    nonce = ''.join([str(random.randint(0, 9)) for i in range(15)])
     signature = generate_hmac_signature(
         http_request, self.consumer_key, self.consumer_secret, timestamp,
-        nonce, version='1.0', next=self.next, token=self.token,
+        nonce, version='1.0', next=self.__next__, token=self.token,
         token_secret=self.token_secret, verifier=self.verifier)
     http_request.headers['Authorization'] = generate_auth_header(
         self.consumer_key, timestamp, nonce, HMAC_SHA1, signature,
-        version='1.0', next=self.next, token=self.token,
+        version='1.0', next=self.__next__, token=self.token,
         verifier=self.verifier)
     return http_request
 
@@ -1078,14 +1078,14 @@
       The same HTTP request object which was passed in.
     """
     timestamp = str(int(time.time()))
-    nonce = ''.join([str(random.randint(0, 9)) for i in xrange(15)])
+    nonce = ''.join([str(random.randint(0, 9)) for i in range(15)])
     signature = generate_rsa_signature(
         http_request, self.consumer_key, self.rsa_private_key, timestamp,
-        nonce, version='1.0', next=self.next, token=self.token,
+        nonce, version='1.0', next=self.__next__, token=self.token,
         token_secret=self.token_secret, verifier=self.verifier)
     http_request.headers['Authorization'] = generate_auth_header(
         self.consumer_key, timestamp, nonce, RSA_SHA1, signature,
-        version='1.0', next=self.next, token=self.token,
+        version='1.0', next=self.__next__, token=self.token,
         verifier=self.verifier)
     return http_request
 
@@ -1204,7 +1204,7 @@
       request: The atom.http_core.HttpRequest which contains all of the
           information needed to send a request to the remote server.
     """
-    body = urllib.urlencode({
+    body = urllib.parse.urlencode({
       'grant_type': 'refresh_token',
       'client_id': self.client_id,
       'client_secret': self.client_secret,
@@ -1273,10 +1273,10 @@
       'access_type': access_type
       }
     query.update(kwargs)
-    parts = list(urlparse.urlparse(self.auth_uri))
+    parts = list(urllib.parse.urlparse(self.auth_uri))
     query.update(dict(parse_qsl(parts[4]))) # 4 is the index of the query part
-    parts[4] = urllib.urlencode(query)
-    return urlparse.urlunparse(parts)
+    parts[4] = urllib.parse.urlencode(query)
+    return urllib.parse.urlunparse(parts)
 
   def get_access_token(self, code):
     """Exhanges a code for an access token.
@@ -1287,10 +1287,10 @@
         the code.
     """
 
-    if not (isinstance(code, str) or isinstance(code, unicode)):
+    if not (isinstance(code, str) or isinstance(code, str)):
       code = code['code']
 
-    body = urllib.urlencode({
+    body = urllib.parse.urlencode({
       'grant_type': 'authorization_code',
       'client_id': self.client_id,
       'client_secret': self.client_secret,
@@ -1496,7 +1496,7 @@
   Returns:
     A string in the form 1x|member1|member2|member3...
   """
-  return '|'.join([urllib.quote_plus(a or '') for a in args])
+  return '|'.join([urllib.parse.quote_plus(a or '') for a in args])
 
 
 def _split_token_parts(blob):
@@ -1514,7 +1514,7 @@
   Returns:
     A list of unescaped strings.
   """
-  return [urllib.unquote_plus(part) or None for part in blob.split('|')]
+  return [urllib.parse.unquote_plus(part) or None for part in blob.split('|')]
 
 
 def token_to_blob(token):
@@ -1557,12 +1557,12 @@
   elif isinstance(token, OAuthRsaToken):
     return _join_token_parts(
         '1r', token.consumer_key, token.rsa_private_key, token.token,
-        token.token_secret, str(token.auth_state), token.next,
+        token.token_secret, str(token.auth_state), token.__next__,
         token.verifier)
   elif isinstance(token, OAuthHmacToken):
     return _join_token_parts(
         '1h', token.consumer_key, token.consumer_secret, token.token,
-        token.token_secret, str(token.auth_state), token.next,
+        token.token_secret, str(token.auth_state), token.__next__,
         token.verifier)
   elif isinstance(token, OAuth2Token):
     return _join_token_parts(
@@ -1651,7 +1651,7 @@
   """
   result_scopes = []
   if service_names is None:
-    for service_name, scopes in AUTH_SCOPES.iteritems():
+    for service_name, scopes in AUTH_SCOPES.items():
       result_scopes.extend(scopes)
   else:
     for service_name in service_names:
--- ./ez/gdata/sample_util.py	(original)
+++ ./ez/gdata/sample_util.py	(refactored)
@@ -21,7 +21,7 @@
 
 import sys
 import getpass
-import urllib
+import urllib.request, urllib.parse, urllib.error
 import gdata.gauth
 
 __author__ = 'j.s@google.com (Jeff Scudder)'
@@ -52,7 +52,7 @@
      return self.prefs[name]
     # Second, check for a command line parameter.
     value = None
-    for i in xrange(len(sys.argv)):
+    for i in range(len(sys.argv)):
       if sys.argv[i].startswith('--%s=' % name):
         value = sys.argv[i].split('=')[1]
       elif sys.argv[i] == '--%s' % name:
@@ -64,7 +64,7 @@
       if secret:
         value = getpass.getpass(prompt)
       else:
-        value = raw_input(prompt)
+        value = input(prompt)
     # If we want to save the preference for reuse in future requests, add it
     # to this object's prefs.
     if value is not None and reuse:
@@ -94,7 +94,7 @@
             'between each URL.\n'
             'Example: http://www.google.com/calendar/feeds/,'
             'http://www.google.com/m8/feeds/\n', reuse=True).split(',')
-      elif isinstance(scopes, (str, unicode)):
+      elif isinstance(scopes, str):
         scopes = scopes.split(',')
 
     if auth_type == CLIENT_LOGIN:
@@ -129,7 +129,7 @@
           private_key = private_key_file.read()
           private_key_file.close()
         except IOError:
-          print 'Unable to read private key from file'
+          print('Unable to read private key from file')
 
       if private_key is not None:
         if client.auth_token is None:
@@ -149,7 +149,7 @@
 
         auth_url = gdata.gauth.generate_auth_sub_url(
             'http://gauthmachine.appspot.com/authsub', scopes, True)
-        print 'with a private key, get ready for this URL', auth_url
+        print('with a private key, get ready for this URL', auth_url)
 
       else:
         if client.auth_token is None:
@@ -170,12 +170,12 @@
           auth_url = gdata.gauth.generate_auth_sub_url(
               'http://gauthmachine.appspot.com/authsub', scopes)
 
-      print 'Visit the following URL in your browser to authorize this app:'
-      print str(auth_url)
-      print 'After agreeing to authorize the app, copy the token value from'
-      print ' the URL. Example: "www.google.com/?token=ab12" token value is'
-      print ' ab12'
-      token_value = raw_input('Please enter the token value: ')
+      print('Visit the following URL in your browser to authorize this app:')
+      print(str(auth_url))
+      print('After agreeing to authorize the app, copy the token value from')
+      print(' the URL. Example: "www.google.com/?token=ab12" token value is')
+      print(' ab12')
+      token_value = input('Please enter the token value: ')
       if private_key is not None:
         single_use_token = gdata.gauth.SecureAuthSubToken(
             token_value, private_key, scopes)
@@ -219,26 +219,26 @@
           private_key = private_key_file.read()
           private_key_file.close()
         except IOError:
-          print 'Unable to read private key from file'
+          print('Unable to read private key from file')
 
         request_token = client.get_oauth_token(
             scopes, 'http://gauthmachine.appspot.com/oauth', consumer_key,
             rsa_private_key=private_key)
       else:
-        print 'Invalid OAuth signature type'
+        print('Invalid OAuth signature type')
         return None
 
       # Authorize the request token in the browser.
-      print 'Visit the following URL in your browser to authorize this app:'
-      print str(request_token.generate_authorization_url())
-      print 'After agreeing to authorize the app, copy URL from the browser\'s'
-      print ' address bar.'
-      url = raw_input('Please enter the url: ')
+      print('Visit the following URL in your browser to authorize this app:')
+      print(str(request_token.generate_authorization_url()))
+      print('After agreeing to authorize the app, copy URL from the browser\'s')
+      print(' address bar.')
+      url = input('Please enter the url: ')
       gdata.gauth.authorize_request_token(request_token, url)
       # Exchange for an access token.
       client.auth_token = client.get_access_token(request_token)
     else:
-      print 'Invalid authorization type.'
+      print('Invalid authorization type.')
       return None
     if client.auth_token:
       self.prefs['client_auth_token'] = gdata.gauth.token_to_blob(
@@ -265,5 +265,5 @@
 def print_options():
   """Displays usage information, available command line params."""
   # TODO: fill in the usage description for authorizing the client.
-  print ''
-
+  print('')
+
--- ./ez/gdata/service.py	(original)
+++ ./ez/gdata/service.py	(refactored)
@@ -61,8 +61,8 @@
 __author__ = 'api.jscudder (Jeffrey Scudder)'
 
 import re
-import urllib
-import urlparse
+import urllib.request, urllib.parse, urllib.error
+import urllib.parse
 try:
   from xml.etree import cElementTree as ElementTree
 except ImportError:
@@ -786,22 +786,22 @@
       if captcha_parameters:
         self.__captcha_token = captcha_parameters['token']
         self.__captcha_url = captcha_parameters['url']
-        raise CaptchaRequired, 'Captcha Required'
+        raise CaptchaRequired('Captcha Required')
       elif response_body.splitlines()[0] == 'Error=BadAuthentication':
         self.__captcha_token = None
         self.__captcha_url = None
-        raise BadAuthentication, 'Incorrect username or password'
+        raise BadAuthentication('Incorrect username or password')
       else:
         self.__captcha_token = None
         self.__captcha_url = None
-        raise Error, 'Server responded with a 403 code'
+        raise Error('Server responded with a 403 code')
     elif auth_response.status == 302:
       self.__captcha_token = None
       self.__captcha_url = None
       # Google tries to redirect all bad URLs back to 
       # http://www.google.<locale>. If a redirect
       # attempt is made, assume the user has supplied an incorrect authentication URL
-      raise BadAuthenticationServiceURL, 'Server responded with a 302 code.'
+      raise BadAuthenticationServiceURL('Server responded with a 302 code.')
 
   def ClientLogin(self, username, password, account_type=None, service=None,
       auth_service_url=None, source=None, captcha_token=None, 
@@ -946,8 +946,8 @@
     if response.status == 200:
       return result_body
     else:
-      raise RequestError, {'status': response.status,
-          'body': result_body}
+      raise RequestError({'status': response.status,
+          'body': result_body})
 
   def GetWithRetries(self, uri, extra_headers=None, redirects_remaining=4, 
       encoding='UTF-8', converter=None, num_retries=DEFAULT_NUM_RETRIES,
@@ -997,13 +997,13 @@
       except SystemExit:
         # Allow this error
         raise
-      except RequestError, e:
+      except RequestError as e:
         # Error 500 is 'internal server error' and warrants a retry
         # Error 503 is 'service unavailable' and warrants a retry
         if e[0]['status'] not in [500, 503]:
           raise e
         # Else, fall through to the retry code...
-      except Exception, e:
+      except Exception as e:
         if logger:
           logger.debug(e)
         # Fall through to the retry code...
@@ -1096,16 +1096,16 @@
           return GDataService.Get(self, location, extra_headers, redirects_remaining - 1, 
               encoding=encoding, converter=converter)
         else:
-          raise RequestError, {'status': server_response.status,
+          raise RequestError({'status': server_response.status,
               'reason': '302 received without Location header',
-              'body': result_body}
+              'body': result_body})
       else:
-        raise RequestError, {'status': server_response.status,
+        raise RequestError({'status': server_response.status,
             'reason': 'Redirect received, but redirects_remaining <= 0',
-            'body': result_body}
-    else:
-      raise RequestError, {'status': server_response.status,
-          'reason': server_response.reason, 'body': result_body}
+            'body': result_body})
+    else:
+      raise RequestError({'status': server_response.status,
+          'reason': server_response.reason, 'body': result_body})
 
   def GetMedia(self, uri, extra_headers=None):
     """Returns a MediaSource containing media and its metadata from the given
@@ -1140,7 +1140,7 @@
     if isinstance(result, atom.Entry):
       return result
     else:
-      raise UnexpectedReturnType, 'Server did not send an entry' 
+      raise UnexpectedReturnType('Server did not send an entry') 
 
   def GetFeed(self, uri, extra_headers=None, 
               converter=gdata.GDataFeedFromString):
@@ -1165,7 +1165,7 @@
     if isinstance(result, atom.Feed):
       return result
     else:
-      raise UnexpectedReturnType, 'Server did not send a feed'  
+      raise UnexpectedReturnType('Server did not send a feed')  
 
   def GetNext(self, feed):
     """Requests the next 'page' of results in the feed.
@@ -1346,16 +1346,16 @@
               extra_headers, url_params, escape_params, 
               redirects_remaining - 1, media_source, converter=converter)
         else:
-          raise RequestError, {'status': server_response.status,
+          raise RequestError({'status': server_response.status,
               'reason': '302 received without Location header',
-              'body': result_body}
+              'body': result_body})
       else:
-        raise RequestError, {'status': server_response.status,
+        raise RequestError({'status': server_response.status,
             'reason': 'Redirect received, but redirects_remaining <= 0',
-            'body': result_body}
-    else:
-      raise RequestError, {'status': server_response.status,
-          'reason': server_response.reason, 'body': result_body}
+            'body': result_body})
+    else:
+      raise RequestError({'status': server_response.status,
+          'reason': server_response.reason, 'body': result_body})
 
   def Put(self, data, uri, extra_headers=None, url_params=None, 
           escape_params=True, redirects_remaining=3, media_source=None,
@@ -1443,16 +1443,16 @@
           return GDataService.Delete(self, location, extra_headers, 
               url_params, escape_params, redirects_remaining - 1)
         else:
-          raise RequestError, {'status': server_response.status,
+          raise RequestError({'status': server_response.status,
               'reason': '302 received without Location header',
-              'body': result_body}
+              'body': result_body})
       else:
-        raise RequestError, {'status': server_response.status,
+        raise RequestError({'status': server_response.status,
             'reason': 'Redirect received, but redirects_remaining <= 0',
-            'body': result_body}
-    else:
-      raise RequestError, {'status': server_response.status,
-          'reason': server_response.reason, 'body': result_body}
+            'body': result_body})
+    else:
+      raise RequestError({'status': server_response.status,
+          'reason': server_response.reason, 'body': result_body})
 
 
 def ExtractToken(url, scopes_included_in_next=True):
@@ -1475,13 +1475,13 @@
     this token should be valid. If the scope was not included in the URL, the
     tuple will contain (token, None).
   """
-  parsed = urlparse.urlparse(url)
+  parsed = urllib.parse.urlparse(url)
   token = gdata.auth.AuthSubTokenFromUrl(parsed[4])
   scopes = ''
   if scopes_included_in_next:
     for pair in parsed[4].split('&'):
       if pair.startswith('%s=' % SCOPE_URL_PARAM_NAME):
-        scopes = urllib.unquote_plus(pair.split('=')[1])
+        scopes = urllib.parse.unquote_plus(pair.split('=')[1])
   return (token, scopes.split(' '))
 
 
@@ -1528,9 +1528,9 @@
     scope = scopes
   if include_scopes_in_next:
     if next.find('?') > -1:
-      next += '&%s' % urllib.urlencode({SCOPE_URL_PARAM_NAME:scope})
-    else:
-      next += '?%s' % urllib.urlencode({SCOPE_URL_PARAM_NAME:scope})
+      next += '&%s' % urllib.parse.urlencode({SCOPE_URL_PARAM_NAME:scope})
+    else:
+      next += '?%s' % urllib.parse.urlencode({SCOPE_URL_PARAM_NAME:scope})
   return gdata.auth.GenerateAuthSubUrl(next=next, scope=scope, secure=secure,
       session=session, request_url=request_url, domain=hd)
 
@@ -1582,7 +1582,7 @@
         self.categories.append(category)
 
   def _GetTextQuery(self):
-    if 'q' in self.keys():
+    if 'q' in list(self.keys()):
       return self['q']
     else:
       return None
@@ -1594,7 +1594,7 @@
       doc="""The feed query's q parameter""")
 
   def _GetAuthor(self):
-    if 'author' in self.keys():
+    if 'author' in list(self.keys()):
       return self['author']
     else:
       return None
@@ -1606,7 +1606,7 @@
       doc="""The feed query's author parameter""")
 
   def _GetAlt(self):
-    if 'alt' in self.keys():
+    if 'alt' in list(self.keys()):
       return self['alt']
     else:
       return None
@@ -1618,7 +1618,7 @@
       doc="""The feed query's alt parameter""")
 
   def _GetUpdatedMin(self):
-    if 'updated-min' in self.keys():
+    if 'updated-min' in list(self.keys()):
       return self['updated-min']
     else:
       return None
@@ -1630,7 +1630,7 @@
       doc="""The feed query's updated-min parameter""")
 
   def _GetUpdatedMax(self):
-    if 'updated-max' in self.keys():
+    if 'updated-max' in list(self.keys()):
       return self['updated-max']
     else:
       return None
@@ -1642,7 +1642,7 @@
       doc="""The feed query's updated-max parameter""")
 
   def _GetPublishedMin(self):
-    if 'published-min' in self.keys():
+    if 'published-min' in list(self.keys()):
       return self['published-min']
     else:
       return None
@@ -1654,7 +1654,7 @@
       doc="""The feed query's published-min parameter""")
 
   def _GetPublishedMax(self):
-    if 'published-max' in self.keys():
+    if 'published-max' in list(self.keys()):
       return self['published-max']
     else:
       return None
@@ -1666,7 +1666,7 @@
       doc="""The feed query's published-max parameter""")
 
   def _GetStartIndex(self):
-    if 'start-index' in self.keys():
+    if 'start-index' in list(self.keys()):
       return self['start-index']
     else:
       return None
@@ -1680,7 +1680,7 @@
       doc="""The feed query's start-index parameter""")
 
   def _GetMaxResults(self):
-    if 'max-results' in self.keys():
+    if 'max-results' in list(self.keys()):
       return self['max-results']
     else:
       return None
@@ -1694,7 +1694,7 @@
       doc="""The feed query's max-results parameter""")
 
   def _GetOrderBy(self):
-    if 'orderby' in self.keys():
+    if 'orderby' in list(self.keys()):
       return self['orderby']
     else:
       return None
@@ -1708,7 +1708,7 @@
   def ToUri(self):
     q_feed = self.feed or ''
     category_string = '/'.join(
-        [urllib.quote_plus(c) for c in self.categories])
+        [urllib.parse.quote_plus(c) for c in self.categories])
     # Add categories to the feed if there are any.
     if len(self.categories) > 0:
       q_feed = q_feed + '/-/' + category_string
--- ./ez/gdata/test_config.py	(original)
+++ ./ez/gdata/test_config.py	(refactored)
@@ -63,7 +63,7 @@
   def get(self):
     value = self.default
     # Check for a command line parameter.
-    for i in xrange(len(sys.argv)):
+    for i in range(len(sys.argv)):
       if sys.argv[i].startswith('--%s=' % self.name):
         value = sys.argv[i].split('=')[1]
       elif sys.argv[i] == '--%s' % self.name:
@@ -77,8 +77,8 @@
       if self.secret:
         value = getpass.getpass(prompt)
       else:
-        print 'You can specify this on the command line using --%s' % self.name
-        value = raw_input(prompt)
+        print('You can specify this on the command line using --%s' % self.name)
+        value = input(prompt)
     return value
 
 
@@ -107,7 +107,7 @@
 
   def render_usage(self):
     message_parts = []
-    for opt_name, option in self.options.iteritems():
+    for opt_name, option in self.options.items():
       message_parts.append('--%s: %s' % (opt_name, option.description))
     return '\n'.join(message_parts)
 
@@ -395,7 +395,7 @@
 def check_data_classes(test, classes):
   import inspect
   for data_class in classes:
-    test.assert_(data_class.__doc__ is not None,
+    test.assertTrue(data_class.__doc__ is not None,
                  'The class %s should have a docstring' % data_class)
     if hasattr(data_class, '_qname'):
       qname_versions = None
@@ -404,13 +404,13 @@
       else:
         qname_versions = (data_class._qname,)
       for versioned_qname in qname_versions:
-        test.assert_(isinstance(versioned_qname, str),
+        test.assertTrue(isinstance(versioned_qname, str),
                      'The class %s has a non-string _qname' % data_class)
-        test.assert_(not versioned_qname.endswith('}'), 
+        test.assertTrue(not versioned_qname.endswith('}'), 
                      'The _qname for class %s is only a namespace' % (
                          data_class))
 
-    for attribute_name, value in data_class.__dict__.iteritems():
+    for attribute_name, value in data_class.__dict__.items():
       # Ignore all elements that start with _ (private members)
       if not attribute_name.startswith('_'):
         try:
@@ -433,9 +433,9 @@
 
 def check_clients_with_auth(test, classes):
   for client_class in classes:
-    test.assert_(hasattr(client_class, 'api_version'))
-    test.assert_(isinstance(client_class.auth_service, (str, unicode, int)))
-    test.assert_(hasattr(client_class, 'auth_service'))
-    test.assert_(isinstance(client_class.auth_service, (str, unicode)))
-    test.assert_(hasattr(client_class, 'auth_scopes'))
-    test.assert_(isinstance(client_class.auth_scopes, (list, tuple)))
+    test.assertTrue(hasattr(client_class, 'api_version'))
+    test.assertTrue(isinstance(client_class.auth_service, (str, int)))
+    test.assertTrue(hasattr(client_class, 'auth_service'))
+    test.assertTrue(isinstance(client_class.auth_service, str))
+    test.assertTrue(hasattr(client_class, 'auth_scopes'))
+    test.assertTrue(isinstance(client_class.auth_scopes, (list, tuple)))
--- ./ez/gdata/urlfetch.py	(original)
+++ ./ez/gdata/urlfetch.py	(refactored)
@@ -38,7 +38,7 @@
 __author__ = 'api.jscudder (Jeff Scudder)'
 
 
-import StringIO
+import io
 import atom.service
 import atom.http_interface
 from google.appengine.api import urlfetch
@@ -188,7 +188,7 @@
   if isinstance(service.additional_headers, dict):
     headers = service.additional_headers.copy()
   if isinstance(extra_headers, dict):
-    for header, value in extra_headers.iteritems():
+    for header, value in extra_headers.items():
       headers[header] = value
   # Add the content type header (we don't need to calculate content length,
   # since urlfetch.Fetch will calculate for us).
@@ -229,7 +229,7 @@
   """
 
   def __init__(self, urlfetch_response):
-    self.body = StringIO.StringIO(urlfetch_response.content)
+    self.body = io.StringIO(urlfetch_response.content)
     self.headers = urlfetch_response.headers
     self.status = urlfetch_response.status_code
     self.reason = ''
@@ -241,7 +241,7 @@
       return self.body.read(length)
 
   def getheader(self, name):
-    if not self.headers.has_key(name):
+    if name not in self.headers:
       return self.headers[name.lower()]
     return self.headers[name]
     
--- ./ez/gdata/Crypto/test.py	(original)
+++ ./ez/gdata/Crypto/test.py	(refactored)
@@ -22,15 +22,15 @@
 if quiet: args.remove('--quiet')
 
 if not quiet:
-    print '\nStream Ciphers:'
-    print '==============='
+    print('\nStream Ciphers:')
+    print('===============')
 
 if args: test.TestStreamModules(args, verbose= not quiet)
 else: test.TestStreamModules(verbose= not quiet)
 
 if not quiet:
-    print '\nBlock Ciphers:'
-    print '=============='
+    print('\nBlock Ciphers:')
+    print('==============')
 
 if args: test.TestBlockModules(args, verbose= not quiet)
 else: test.TestBlockModules(verbose= not quiet)
--- ./ez/gdata/Crypto/Hash/HMAC.py	(original)
+++ ./ez/gdata/Crypto/Hash/HMAC.py	(refactored)
@@ -33,7 +33,7 @@
         digestmod: A module supporting PEP 247. Defaults to the md5 module.
         """
         if digestmod == None:
-            import md5
+            from . import md5
             digestmod = md5
 
         self.digestmod = digestmod
--- ./ez/gdata/Crypto/Hash/MD5.py	(original)
+++ ./ez/gdata/Crypto/Hash/MD5.py	(refactored)
@@ -3,9 +3,9 @@
 
 __revision__ = "$Id: MD5.py,v 1.4 2002/07/11 14:31:19 akuchling Exp $"
 
-from md5 import *
+from .md5 import *
 
-import md5
+from . import md5
 if hasattr(md5, 'digestsize'):
     digest_size = digestsize
     del digestsize
--- ./ez/gdata/Crypto/Hash/SHA.py	(original)
+++ ./ez/gdata/Crypto/Hash/SHA.py	(refactored)
@@ -3,8 +3,8 @@
 
 __revision__ = "$Id: SHA.py,v 1.4 2002/07/11 14:31:19 akuchling Exp $"
 
-from sha import *
-import sha
+from .sha import *
+from . import sha
 if hasattr(sha, 'digestsize'):
     digest_size = digestsize
     del digestsize
--- ./ez/gdata/Crypto/Protocol/AllOrNothing.py	(original)
+++ ./ez/gdata/Crypto/Protocol/AllOrNothing.py	(refactored)
@@ -22,6 +22,7 @@
 import operator
 import string
 from Crypto.Util.number import bytes_to_long, long_to_bytes
+from functools import reduce
 
 
 
@@ -139,7 +140,7 @@
         # we convert the blocks to strings since in Python, byte sequences are
         # always represented as strings.  This is more consistent with the
         # model that encryption and hash algorithms always operate on strings.
-        return map(long_to_bytes, blocks)
+        return list(map(long_to_bytes, blocks))
 
 
     def undigest(self, blocks):
@@ -154,11 +155,11 @@
         # better have at least 2 blocks, for the padbytes package and the hash
         # block accumulator
         if len(blocks) < 2:
-            raise ValueError, "List must be at least length 2."
+            raise ValueError("List must be at least length 2.")
 
         # blocks is a list of strings.  We need to deal with them as long
         # integers
-        blocks = map(bytes_to_long, blocks)
+        blocks = list(map(bytes_to_long, blocks))
 
         # Calculate the well-known key, to which the hash blocks are
         # encrypted, and create the hash cipher.
@@ -193,7 +194,7 @@
         # of the cipher's block_size.  This number should be small enough that
         # the conversion from long integer to integer should never overflow
         padbytes = int(parts[-1])
-        text = string.join(map(long_to_bytes, parts[:-1]), '')
+        text = string.join(list(map(long_to_bytes, parts[:-1])), '')
         return text[:-padbytes]
 
     def _inventkey(self, key_size):
@@ -247,15 +248,15 @@
 
     def usage(code, msg=None):
         if msg:
-            print msg
-        print usagemsg % {'program': sys.argv[0],
-                          'ciphermodule': ciphermodule}
+            print(msg)
+        print(usagemsg % {'program': sys.argv[0],
+                          'ciphermodule': ciphermodule})
         sys.exit(code)
 
     try:
         opts, args = getopt.getopt(sys.argv[1:],
                                    'c:l', ['cipher=', 'aslong'])
-    except getopt.error, msg:
+    except getopt.error as msg:
         usage(1, msg)
 
     if args:
@@ -273,23 +274,23 @@
     module = __import__('Crypto.Cipher.'+ciphermodule, None, None, ['new'])
 
     a = AllOrNothing(module)
-    print 'Original text:\n=========='
-    print __doc__
-    print '=========='
+    print('Original text:\n==========')
+    print(__doc__)
+    print('==========')
     msgblocks = a.digest(__doc__)
-    print 'message blocks:'
-    for i, blk in map(None, range(len(msgblocks)), msgblocks):
+    print('message blocks:')
+    for i, blk in map(None, list(range(len(msgblocks))), msgblocks):
         # base64 adds a trailing newline
-        print '    %3d' % i,
+        print('    %3d' % i, end=' ')
         if aslong:
-            print bytes_to_long(blk)
+            print(bytes_to_long(blk))
         else:
-            print base64.encodestring(blk)[:-1]
+            print(base64.encodestring(blk)[:-1])
     #
     # get a new undigest-only object so there's no leakage
     b = AllOrNothing(module)
     text = b.undigest(msgblocks)
     if text == __doc__:
-        print 'They match!'
+        print('They match!')
     else:
-        print 'They differ!'
+        print('They differ!')
--- ./ez/gdata/Crypto/Protocol/Chaffing.py	(original)
+++ ./ez/gdata/Crypto/Protocol/Chaffing.py	(refactored)
@@ -81,9 +81,9 @@
         """
 
         if not (0.0<=factor<=1.0):
-            raise ValueError, "'factor' must be between 0.0 and 1.0"
+            raise ValueError("'factor' must be between 0.0 and 1.0")
         if blocksper < 0:
-            raise ValueError, "'blocksper' must be zero or more"
+            raise ValueError("'blocksper' must be zero or more")
 
         self.__factor = factor
         self.__blocksper = blocksper
@@ -114,8 +114,8 @@
         # number of chaff blocks to add per message block that is being
         # chaffed.
         count = len(blocks) * self.__factor
-        blocksper = range(self.__blocksper)
-        for i, wheat in map(None, range(len(blocks)), blocks):
+        blocksper = list(range(self.__blocksper))
+        for i, wheat in map(None, list(range(len(blocks))), blocks):
             # it shouldn't matter which of the n blocks we add chaff to, so for
             # ease of implementation, we'll just add them to the first count
             # blocks
@@ -170,9 +170,9 @@
 principles and organizing its powers in such form, as to them shall seem most
 likely to effect their Safety and Happiness.
 """
-    print 'Original text:\n=========='
-    print text
-    print '=========='
+    print('Original text:\n==========')
+    print(text)
+    print('==========')
 
     # first transform the text into packets
     blocks = [] ; size = 40
@@ -180,7 +180,7 @@
         blocks.append( text[i:i+size] )
 
     # now get MACs for all the text blocks.  The key is obvious...
-    print 'Calculating MACs...'
+    print('Calculating MACs...')
     from Crypto.Hash import HMAC, SHA
     key = 'Jefferson'
     macs = [HMAC.new(key, block, digestmod=SHA).digest()
@@ -190,13 +190,13 @@
 
     # put these into a form acceptable as input to the chaffing procedure
     source = []
-    m = map(None, range(len(blocks)), blocks, macs)
-    print m
+    m = map(None, list(range(len(blocks))), blocks, macs)
+    print(m)
     for i, data, mac in m:
         source.append((i, data, mac))
 
     # now chaff these
-    print 'Adding chaff...'
+    print('Adding chaff...')
     c = Chaff(factor=0.5, blocksper=2)
     chaffed = c.chaff(source)
 
@@ -206,7 +206,7 @@
     # the chaff
 
     wheat = []
-    print 'chaffed message blocks:'
+    print('chaffed message blocks:')
     for i, data, mac in chaffed:
         # do the authentication
         h = HMAC.new(key, data, digestmod=SHA)
@@ -217,13 +217,13 @@
         else:
             tag = '   '
         # base64 adds a trailing newline
-        print tag, '%3d' % i, \
-              repr(data), encodestring(mac)[:-1]
+        print(tag, '%3d' % i, \
+              repr(data), encodestring(mac)[:-1])
 
     # now decode the message packets and check it against the original text
-    print 'Undigesting wheat...'
+    print('Undigesting wheat...')
     newtext = "".join(wheat)
     if newtext == text:
-        print 'They match!'
+        print('They match!')
     else:
-        print 'They differ!'
+        print('They differ!')
--- ./ez/gdata/Crypto/PublicKey/DSA.py	(original)
+++ ./ez/gdata/Crypto/PublicKey/DSA.py	(refactored)
@@ -40,9 +40,9 @@
         q=q*256+c
     while (not isPrime(q)):
         q=q+2
-    if pow(2,159L) < q < pow(2,160L):
+    if pow(2,159) < q < pow(2,160):
         return S, q
-    raise error, 'Bad q value generated'
+    raise error('Bad q value generated')
 
 def generate(bits, randfunc, progress_func=None):
     """generate(bits:int, randfunc:callable, progress_func:callable)
@@ -53,7 +53,7 @@
     """
 
     if bits<160:
-        raise error, 'Key length <160 bits'
+        raise error('Key length <160 bits')
     obj=DSAobj()
     # Generate string S and prime q
     if progress_func:
@@ -70,7 +70,7 @@
                 V[k]=bytes_to_long(SHA.new(S+str(N)+str(k)).digest())
             W=V[n] % powb
             for k in range(n-1, -1, -1):
-                W=(W<<160L)+V[k]
+                W=(W<<160)+V[k]
             X=W+powL1
             p=X-(X%(2*obj.q)-1)
             if powL1<=p and isPrime(p):
@@ -106,7 +106,7 @@
     """
     obj=DSAobj()
     if len(tuple) not in [4,5]:
-        raise error, 'argument for construct() wrong length'
+        raise error('argument for construct() wrong length')
     for i in range(len(tuple)):
         field = obj.keydata[i]
         setattr(obj, field, tuple[i])
@@ -116,14 +116,14 @@
     keydata=['y', 'g', 'p', 'q', 'x']
 
     def _encrypt(self, s, Kstr):
-        raise error, 'DSA algorithm cannot encrypt data'
+        raise error('DSA algorithm cannot encrypt data')
 
     def _decrypt(self, s):
-        raise error, 'DSA algorithm cannot decrypt data'
+        raise error('DSA algorithm cannot decrypt data')
 
     def _sign(self, M, K):
         if (K<2 or self.q<=K):
-            raise error, 'K is not between 2 and q'
+            raise error('K is not between 2 and q')
         r=pow(self.g, K, self.p) % self.q
         s=(inverse(K, self.q)*(M+self.x*r)) % self.q
         return (r,s)
@@ -181,10 +181,10 @@
         if attr in self.keydata:
             return getattr(self.key, attr)
         else:
-            if self.__dict__.has_key(attr):
+            if attr in self.__dict__:
                 self.__dict__[attr]
             else:
-                raise AttributeError, '%s instance has no attribute %s' % (self.__class__, attr)
+                raise AttributeError('%s instance has no attribute %s' % (self.__class__, attr))
 
     def __getstate__(self):
         d = {}
@@ -195,7 +195,7 @@
 
     def __setstate__(self, state):
         y,g,p,q = state['y'], state['g'], state['p'], state['q']
-        if not state.has_key('x'):
+        if 'x' not in state:
             self.key = _fastmath.dsa_construct(y,g,p,q)
         else:
             x = state['x']
@@ -204,7 +204,8 @@
     def _sign(self, M, K):
         return self.key._sign(M, K)
 
-    def _verify(self, M, (r, s)):
+    def _verify(self, M, xxx_todo_changeme):
+        (r, s) = xxx_todo_changeme
         return self.key._verify(M, r, s)
 
     def size(self):
@@ -228,7 +229,7 @@
     return construct_c((y,g,p,q,x))
 
 def construct_c(tuple):
-    key = apply(_fastmath.dsa_construct, tuple)
+    key = _fastmath.dsa_construct(*tuple)
     return DSAobj_c(key)
 
 if _fastmath:
--- ./ez/gdata/Crypto/PublicKey/ElGamal.py	(original)
+++ ./ez/gdata/Crypto/PublicKey/ElGamal.py	(refactored)
@@ -71,7 +71,7 @@
 
     obj=ElGamalobj()
     if len(tuple) not in [3,4]:
-        raise error, 'argument for construct() wrong length'
+        raise error('argument for construct() wrong length')
     for i in range(len(tuple)):
         field = obj.keydata[i]
         setattr(obj, field, tuple[i])
@@ -87,17 +87,17 @@
 
     def _decrypt(self, M):
         if (not hasattr(self, 'x')):
-            raise error, 'Private key not available in this object'
+            raise error('Private key not available in this object')
         ax=pow(M[0], self.x, self.p)
         plaintext=(M[1] * inverse(ax, self.p ) ) % self.p
         return plaintext
 
     def _sign(self, M, K):
         if (not hasattr(self, 'x')):
-            raise error, 'Private key not available in this object'
+            raise error('Private key not available in this object')
         p1=self.p-1
         if (GCD(K, p1)!=1):
-            raise error, 'Bad K value: GCD(K,p-1)!=1'
+            raise error('Bad K value: GCD(K,p-1)!=1')
         a=pow(self.g, K, self.p)
         t=(M-self.x*a) % p1
         while t<0: t=t+p1
--- ./ez/gdata/Crypto/PublicKey/RSA.py	(original)
+++ ./ez/gdata/Crypto/PublicKey/RSA.py	(refactored)
@@ -35,7 +35,7 @@
     # Generate the prime factors of n
     if progress_func:
         progress_func('p,q\n')
-    p = q = 1L
+    p = q = 1
     while number.size(p*q) < bits:
         p = pubkey.getPrime(bits/2, randfunc)
         q = pubkey.getPrime(bits/2, randfunc)
@@ -51,7 +51,7 @@
     obj.u = pubkey.inverse(obj.p, obj.q)
     obj.n = obj.p*obj.q
 
-    obj.e = 65537L
+    obj.e = 65537
     if progress_func:
         progress_func('d\n')
     obj.d=pubkey.inverse(obj.e, (obj.p-1)*(obj.q-1))
@@ -67,7 +67,7 @@
 
     obj=RSAobj()
     if len(tuple) not in [2,3,5,6]:
-        raise error, 'argument for construct() wrong length'
+        raise error('argument for construct() wrong length')
     for i in range(len(tuple)):
         field = obj.keydata[i]
         setattr(obj, field, tuple[i])
@@ -86,14 +86,14 @@
     keydata = ['n', 'e', 'd', 'p', 'q', 'u']
     def _encrypt(self, plaintext, K=''):
         if self.n<=plaintext:
-            raise error, 'Plaintext too large'
+            raise error('Plaintext too large')
         return (pow(plaintext, self.e, self.n),)
 
     def _decrypt(self, ciphertext):
         if (not hasattr(self, 'd')):
-            raise error, 'Private key not available in this object'
+            raise error('Private key not available in this object')
         if self.n<=ciphertext[0]:
-            raise error, 'Ciphertext too large'
+            raise error('Ciphertext too large')
         return pow(ciphertext[0], self.d, self.n)
 
     def _sign(self, M, K=''):
@@ -153,10 +153,10 @@
         if attr in self.keydata:
             return getattr(self.key, attr)
         else:
-            if self.__dict__.has_key(attr):
+            if attr in self.__dict__:
                 self.__dict__[attr]
             else:
-                raise AttributeError, '%s instance has no attribute %s' % (self.__class__, attr)
+                raise AttributeError('%s instance has no attribute %s' % (self.__class__, attr))
 
     def __getstate__(self):
         d = {}
@@ -167,11 +167,11 @@
 
     def __setstate__(self, state):
         n,e = state['n'], state['e']
-        if not state.has_key('d'):
+        if 'd' not in state:
             self.key = _fastmath.rsa_construct(n,e)
         else:
             d = state['d']
-            if not state.has_key('q'):
+            if 'q' not in state:
                 self.key = _fastmath.rsa_construct(n,e,d)
             else:
                 p, q, u = state['p'], state['q'], state['u']
@@ -212,7 +212,7 @@
     if progress_func:
         progress_func('p,q\n')
 
-    p = q = 1L
+    p = q = 1
     while number.size(p*q) < bits:
         p = pubkey.getPrime(bits/2, randfunc)
         q = pubkey.getPrime(bits/2, randfunc)
@@ -225,7 +225,7 @@
     u=pubkey.inverse(p, q)
     n=p*q
 
-    e = 65537L
+    e = 65537
     if progress_func:
         progress_func('d\n')
     d=pubkey.inverse(e, (p-1)*(q-1))
@@ -241,7 +241,7 @@
 
 
 def construct_c(tuple):
-    key = apply(_fastmath.rsa_construct, tuple)
+    key = _fastmath.rsa_construct(*tuple)
     return RSAobj_c(key)
 
 object = RSAobj
--- ./ez/gdata/Crypto/PublicKey/pubkey.py	(original)
+++ ./ez/gdata/Crypto/PublicKey/pubkey.py	(refactored)
@@ -27,7 +27,7 @@
         restoration."""
         d=self.__dict__
         for key in self.keydata:
-            if d.has_key(key): d[key]=long(d[key])
+            if key in d: d[key]=int(d[key])
         return d
 
     def __setstate__(self, d):
@@ -35,7 +35,7 @@
 number representation being used, whether that is Python long
 integers, MPZ objects, or whatever."""
         for key in self.keydata:
-            if d.has_key(key): self.__dict__[key]=bignum(d[key])
+            if key in d: self.__dict__[key]=bignum(d[key])
 
     def encrypt(self, plaintext, K):
         """encrypt(plaintext:string|long, K:string|long) : tuple
@@ -43,9 +43,9 @@
         parameter required by some algorithms.
         """
         wasString=0
-        if isinstance(plaintext, types.StringType):
+        if isinstance(plaintext, bytes):
             plaintext=bytes_to_long(plaintext) ; wasString=1
-        if isinstance(K, types.StringType):
+        if isinstance(K, bytes):
             K=bytes_to_long(K)
         ciphertext=self._encrypt(plaintext, K)
         if wasString: return tuple(map(long_to_bytes, ciphertext))
@@ -56,9 +56,9 @@
         Decrypt 'ciphertext' using this key.
         """
         wasString=0
-        if not isinstance(ciphertext, types.TupleType):
+        if not isinstance(ciphertext, tuple):
             ciphertext=(ciphertext,)
-        if isinstance(ciphertext[0], types.StringType):
+        if isinstance(ciphertext[0], bytes):
             ciphertext=tuple(map(bytes_to_long, ciphertext)) ; wasString=1
         plaintext=self._decrypt(ciphertext)
         if wasString: return long_to_bytes(plaintext)
@@ -70,9 +70,9 @@
         K is a random parameter required by some algorithms.
         """
         if (not self.has_private()):
-            raise error, 'Private key not available in this object'
-        if isinstance(M, types.StringType): M=bytes_to_long(M)
-        if isinstance(K, types.StringType): K=bytes_to_long(K)
+            raise error('Private key not available in this object')
+        if isinstance(M, bytes): M=bytes_to_long(M)
+        if isinstance(K, bytes): K=bytes_to_long(K)
         return self._sign(M, K)
 
     def verify (self, M, signature):
@@ -80,7 +80,7 @@
         Verify that the signature is valid for the message M;
         returns true if the signature checks out.
         """
-        if isinstance(M, types.StringType): M=bytes_to_long(M)
+        if isinstance(M, bytes): M=bytes_to_long(M)
         return self._verify(M, signature)
 
     # alias to compensate for the old validate() name
@@ -93,9 +93,9 @@
         Blind message M using blinding factor B.
         """
         wasString=0
-        if isinstance(M, types.StringType):
+        if isinstance(M, bytes):
             M=bytes_to_long(M) ; wasString=1
-        if isinstance(B, types.StringType): B=bytes_to_long(B)
+        if isinstance(B, bytes): B=bytes_to_long(B)
         blindedmessage=self._blind(M, B)
         if wasString: return long_to_bytes(blindedmessage)
         else: return blindedmessage
@@ -105,9 +105,9 @@
         Unblind message M using blinding factor B.
         """
         wasString=0
-        if isinstance(M, types.StringType):
+        if isinstance(M, bytes):
             M=bytes_to_long(M) ; wasString=1
-        if isinstance(B, types.StringType): B=bytes_to_long(B)
+        if isinstance(B, bytes): B=bytes_to_long(B)
         unblindedmessage=self._unblind(M, B)
         if wasString: return long_to_bytes(unblindedmessage)
         else: return unblindedmessage
--- ./ez/gdata/Crypto/PublicKey/qNEW.py	(original)
+++ ./ez/gdata/Crypto/PublicKey/qNEW.py	(refactored)
@@ -49,8 +49,8 @@
         C, N, V = 0, 2, {}
         # Compute b and n such that bits-1 = b + n*HASHBITS
         n= (bits-1) / HASHBITS
-        b= (bits-1) % HASHBITS ; powb=2L << b
-        powL1=pow(long(2), bits-1)
+        b= (bits-1) % HASHBITS ; powb=2 << b
+        powL1=pow(int(2), bits-1)
         while C<4096:
             # The V array will contain (bits-1) bits of random
             # data, that are assembled to produce a candidate
@@ -59,7 +59,7 @@
                 V[k]=bytes_to_long(SHA.new(S+str(N)+str(k)).digest())
             p = V[n] % powb
             for k in range(n-1, -1, -1):
-                p= (p << long(HASHBITS) )+V[k]
+                p= (p << int(HASHBITS) )+V[k]
             p = p+powL1         # Ensure the high bit is set
 
             # Ensure that p-1 is a multiple of q
@@ -110,7 +110,7 @@
     """
     obj=qNEWobj()
     if len(tuple) not in [4,5]:
-        raise error, 'argument for construct() wrong length'
+        raise error('argument for construct() wrong length')
     for i in range(len(tuple)):
         field = obj.keydata[i]
         setattr(obj, field, tuple[i])
@@ -121,11 +121,11 @@
 
     def _sign(self, M, K=''):
         if (self.q<=K):
-            raise error, 'K is greater than q'
+            raise error('K is greater than q')
         if M<0:
-            raise error, 'Illegal value of M (<0)'
-        if M>=pow(2,161L):
-            raise error, 'Illegal value of M (too large)'
+            raise error('Illegal value of M (<0)')
+        if M>=pow(2,161):
+            raise error('Illegal value of M (too large)')
         r=pow(self.g, K, self.p) % self.q
         s=(K- (r*M*self.x % self.q)) % self.q
         return (r,s)
@@ -134,8 +134,8 @@
         if r<=0 or r>=self.q or s<=0 or s>=self.q:
             return 0
         if M<0:
-            raise error, 'Illegal value of M (<0)'
-        if M<=0 or M>=pow(2,161L):
+            raise error('Illegal value of M (<0)')
+        if M<=0 or M>=pow(2,161):
             return 0
         v1 = pow(self.g, s, self.p)
         v2 = pow(self.y, M*r, self.p)
--- ./ez/gdata/Crypto/Util/RFC1751.py	(original)
+++ ./ez/gdata/Crypto/Util/RFC1751.py	(refactored)
@@ -7,6 +7,7 @@
 
 
 import string, binascii
+from functools import reduce
 
 binary={0:'0000', 1:'0001', 2:'0010', 3:'0011', 4:'0100', 5:'0101',
         6:'0110', 7:'0111', 8:'1000', 9:'1001', 10:'1010', 11:'1011',
@@ -14,8 +15,8 @@
 
 def _key2bin(s):
     "Convert a key into a string of binary digits"
-    kl=map(lambda x: ord(x), s)
-    kl=map(lambda x: binary[x/16]+binary[x&15], kl)
+    kl=[ord(x) for x in s]
+    kl=[binary[x/16]+binary[x&15] for x in kl]
     return ''.join(kl)
 
 def _extract(key, start, length):
@@ -73,7 +74,7 @@
         p=0
         for i in range(0, 64, 2): p=p+_extract(skbin, i, 2)
         if (p&3) != _extract(skbin, 64, 2):
-            raise ValueError, "Parity error in resulting key"
+            raise ValueError("Parity error in resulting key")
         key=key+subkey[0:8]
     return key
 
@@ -330,13 +331,13 @@
            ]
 
     for key, words in data:
-        print 'Trying key', key
+        print('Trying key', key)
         key=binascii.a2b_hex(key)
         w2=key_to_english(key)
         if w2!=words:
-            print 'key_to_english fails on key', repr(key), ', producing', str(w2)
+            print('key_to_english fails on key', repr(key), ', producing', str(w2))
         k2=english_to_key(words)
         if k2!=key:
-            print 'english_to_key fails on key', repr(key), ', producing', repr(k2)
-
-
+            print('english_to_key fails on key', repr(key), ', producing', repr(k2))
+
+
--- ./ez/gdata/Crypto/Util/number.py	(original)
+++ ./ez/gdata/Crypto/Util/number.py	(refactored)
@@ -12,7 +12,7 @@
 
 __revision__ = "$Id: number.py,v 1.13 2003/04/04 18:21:07 akuchling Exp $"
 
-bignum = long
+bignum = int
 try:
     from Crypto.PublicKey import _fastmath
 except ImportError:
@@ -35,7 +35,7 @@
     """size(N:long) : int
     Returns the size of the number N in bits.
     """
-    bits, power = 0,1L
+    bits, power = 0,1
     while N >= power:
         bits += 1
         power = power << 1
@@ -51,7 +51,7 @@
         char = ord(randfunc(1)) >> (8-odd_bits)
         S = chr(char) + S
     value = bytes_to_long(S)
-    value |= 2L ** (N-1)                # Ensure high bit is set
+    value |= 2 ** (N-1)                # Ensure high bit is set
     assert size(value) >= N
     return value
 
@@ -68,8 +68,8 @@
     """inverse(u:long, u:long):long
     Return the inverse of u mod v.
     """
-    u3, v3 = long(u), long(v)
-    u1, v1 = 1L, 0L
+    u3, v3 = int(u), int(v)
+    u1, v1 = 1, 0
     while v3 > 0:
         q=u3 / v3
         u1, v1 = v1, u1 - v1*q
@@ -108,25 +108,25 @@
         return _fastmath.isPrime(N)
 
     # Compute the highest bit that's set in N
-    N1 = N - 1L
-    n = 1L
+    N1 = N - 1
+    n = 1
     while (n<N):
-        n=n<<1L
-    n = n >> 1L
+        n=n<<1
+    n = n >> 1
 
     # Rabin-Miller test
     for c in sieve[:7]:
-        a=long(c) ; d=1L ; t=n
+        a=int(c) ; d=1 ; t=n
         while (t):  # Iterate over the bits in N1
             x=(d*d) % N
-            if x==1L and d!=1L and d!=N1:
+            if x==1 and d!=1 and d!=N1:
                 return 0  # Square root of 1 found
             if N1 & t:
                 d=(x*a) % N
             else:
                 d=x
-            t = t >> 1L
-        if d!=1L:
+            t = t >> 1
+        if d!=1:
             return 0
     return 1
 
@@ -154,10 +154,10 @@
     """
     # after much testing, this algorithm was deemed to be the fastest
     s = ''
-    n = long(n)
+    n = int(n)
     pack = struct.pack
     while n > 0:
-        s = pack('>I', n & 0xffffffffL) + s
+        s = pack('>I', n & 0xffffffff) + s
         n = n >> 32
     # strip off leading zeros
     for i in range(len(s)):
@@ -180,7 +180,7 @@
 
     This is (essentially) the inverse of long_to_bytes().
     """
-    acc = 0L
+    acc = 0
     unpack = struct.unpack
     length = len(s)
     if length % 4:
--- ./ez/gdata/Crypto/Util/randpool.py	(original)
+++ ./ez/gdata/Crypto/Util/randpool.py	(refactored)
@@ -62,7 +62,7 @@
         if cipher is not None:
             warnings.warn("'cipher' parameter is no longer used")
 
-        if isinstance(hash, types.StringType):
+        if isinstance(hash, bytes):
             # ugly hack to force __import__ to give us the end-path module
             hash = __import__('Crypto.Hash.'+hash,
                               None, None, ['new'])
@@ -116,8 +116,9 @@
                 f=open(devname)
                 data=f.read(nbytes)
                 f.close()
-            except IOError, (num, msg):
-                if num!=2: raise IOError, (num, msg)
+            except IOError as xxx_todo_changeme:
+                (num, msg) = xxx_todo_changeme.args
+                if num!=2: raise IOError(num, msg)
                 # If the file wasn't found, ignore the error
         if data:
             self._addBytes(data)
@@ -137,7 +138,7 @@
         """stir_n(N)
         stirs the random pool N times
         """
-        for i in xrange(N):
+        for i in range(N):
             self.stir()
 
     def stir (self, s = ''):
@@ -158,7 +159,7 @@
             h = self._hash.new(self._randpool)
             h.update(str(self.__counter) + str(i) + str(self._addPos) + s)
             self._addBytes( h.digest() )
-            self.__counter = (self.__counter + 1) & 0xFFFFffffL
+            self.__counter = (self.__counter + 1) & 0xFFFFffff
 
         self._addPos, self._getPos = 0, self._hash.digest_size
         self.add_event()
@@ -228,10 +229,10 @@
         t=time.time()
         delta = (t - self._lastcounter)/self._ticksize*1e6
         self._lastcounter = t
-        self._addBytes(long_to_bytes(long(1000*time.time())))
-        self._addBytes(long_to_bytes(long(1000*time.clock())))
-        self._addBytes(long_to_bytes(long(1000*time.time())))
-        self._addBytes(long_to_bytes(long(delta)))
+        self._addBytes(long_to_bytes(int(1000*time.time())))
+        self._addBytes(long_to_bytes(int(1000*time.clock())))
+        self._addBytes(long_to_bytes(int(1000*time.time())))
+        self._addBytes(long_to_bytes(int(delta)))
 
         # Reduce delta to a maximum of 8 bits so we don't add too much
         # entropy as a result of this call.
@@ -246,16 +247,16 @@
         # between measurements, and taking the median of the resulting
         # list.  (We also hash all the times and add them to the pool)
         interval = [None] * 100
-        h = self._hash.new(`(id(self),id(interval))`)
+        h = self._hash.new(repr((id(self),id(interval))))
 
         # Compute 100 differences
         t=time.time()
-        h.update(`t`)
+        h.update(repr(t))
         i = 0
         j = 0
         while i < 100:
             t2=time.time()
-            h.update(`(i,j,t2)`)
+            h.update(repr((i,j,t2)))
             j += 1
             delta=int((t2-t)*1e6)
             if delta:
@@ -266,7 +267,7 @@
         # Take the median of the array of intervals
         interval.sort()
         self._ticksize=interval[len(interval)/2]
-        h.update(`(interval,self._ticksize)`)
+        h.update(repr((interval,self._ticksize)))
         # mix in the measurement times and wash the random pool
         self.stir(h.digest())
 
@@ -311,7 +312,7 @@
 
     def save(self):
         if self.filename == "":
-            raise ValueError, "No filename set for this object"
+            raise ValueError("No filename set for this object")
         # wash the random pool before save, provides some forward secrecy for
         # old values of the pool.
         self.stir_n()
@@ -380,8 +381,8 @@
             bits = N*8
         if bits == 0:
             return
-        print bits,'bits of entropy are now required.  Please type on the keyboard'
-        print 'until enough randomness has been accumulated.'
+        print(bits,'bits of entropy are now required.  Please type on the keyboard')
+        print('until enough randomness has been accumulated.')
         kb = KeyboardEntry()
         s=''    # We'll save the characters typed and add them to the pool.
         hash = self._hash
@@ -396,26 +397,26 @@
             self.add_event(s+hash.new(s).digest() )
         finally:
             kb.close()
-        print '\n\007 Enough.  Please wait a moment.\n'
+        print('\n\007 Enough.  Please wait a moment.\n')
         self.stir_n()   # wash the random pool.
         kb.close(4)
 
 if __name__ == '__main__':
     pool = RandomPool()
-    print 'random pool entropy', pool.entropy, 'bits'
+    print('random pool entropy', pool.entropy, 'bits')
     pool.add_event('something')
-    print `pool.get_bytes(100)`
+    print(repr(pool.get_bytes(100)))
     import tempfile, os
     fname = tempfile.mktemp()
     pool = KeyboardRandomPool(filename=fname)
-    print 'keyboard random pool entropy', pool.entropy, 'bits'
+    print('keyboard random pool entropy', pool.entropy, 'bits')
     pool.randomize()
-    print 'keyboard random pool entropy', pool.entropy, 'bits'
+    print('keyboard random pool entropy', pool.entropy, 'bits')
     pool.randomize(128)
     pool.save()
     saved = open(fname, 'rb').read()
-    print 'saved', `saved`
-    print 'pool ', `pool._randpool.tostring()`
+    print('saved', repr(saved))
+    print('pool ', repr(pool._randpool.tostring()))
     newpool = PersistentRandomPool(fname)
-    print 'persistent random pool entropy', pool.entropy, 'bits'
+    print('persistent random pool entropy', pool.entropy, 'bits')
     os.remove(fname)
--- ./ez/gdata/Crypto/Util/test.py	(original)
+++ ./ez/gdata/Crypto/Util/test.py	(refactored)
@@ -20,32 +20,32 @@
 
 def die(string):
     import sys
-    print '***ERROR: ', string
+    print('***ERROR: ', string)
 #    sys.exit(0)   # Will default to continuing onward...
 
 def print_timing (size, delta, verbose):
     if verbose:
         if delta == 0:
-            print 'Unable to measure time -- elapsed time too small'
+            print('Unable to measure time -- elapsed time too small')
         else:
-            print '%.2f K/sec' % (size/delta)
+            print('%.2f K/sec' % (size/delta))
             
 def exerciseBlockCipher(cipher, verbose):
     import string, time
     try:
         ciph = eval(cipher)
     except NameError:
-        print cipher, 'module not available'
+        print(cipher, 'module not available')
         return None
-    print cipher+ ':'
+    print(cipher+ ':')
     str='1'                             # Build 128K of test data
-    for i in xrange(0, 17):
+    for i in range(0, 17):
         str=str+str
     if ciph.key_size==0: ciph.key_size=16
     password = 'password12345678Extra text for password'[0:ciph.key_size]
     IV = 'Test IV Test IV Test IV Test'[0:ciph.block_size]
 
-    if verbose: print '  ECB mode:',
+    if verbose: print('  ECB mode:', end=' ')
     obj=ciph.new(password, ciph.MODE_ECB)
     if obj.block_size != ciph.block_size:
         die("Module and cipher object block_size don't match")
@@ -69,7 +69,7 @@
     print_timing(256, end-start, verbose)
     del obj
 
-    if verbose: print '  CFB mode:',
+    if verbose: print('  CFB mode:', end=' ')
     obj1=ciph.new(password, ciph.MODE_CFB, IV)
     obj2=ciph.new(password, ciph.MODE_CFB, IV)
     start=time.time()
@@ -81,7 +81,7 @@
     print_timing(64, end-start, verbose)
     del obj1, obj2
 
-    if verbose: print '  CBC mode:',
+    if verbose: print('  CBC mode:', end=' ')
     obj1=ciph.new(password, ciph.MODE_CBC, IV)
     obj2=ciph.new(password, ciph.MODE_CBC, IV)
     start=time.time()
@@ -93,7 +93,7 @@
     print_timing(256, end-start, verbose)
     del obj1, obj2
 
-    if verbose: print '  PGP mode:',
+    if verbose: print('  PGP mode:', end=' ')
     obj1=ciph.new(password, ciph.MODE_PGP, IV)
     obj2=ciph.new(password, ciph.MODE_PGP, IV)
     start=time.time()
@@ -105,7 +105,7 @@
     print_timing(256, end-start, verbose)
     del obj1, obj2
 
-    if verbose: print '  OFB mode:',
+    if verbose: print('  OFB mode:', end=' ')
     obj1=ciph.new(password, ciph.MODE_OFB, IV)
     obj2=ciph.new(password, ciph.MODE_OFB, IV)
     start=time.time()
@@ -120,7 +120,7 @@
     def counter(length=ciph.block_size):
         return length * 'a'
 
-    if verbose: print '  CTR mode:',
+    if verbose: print('  CTR mode:', end=' ')
     obj1=ciph.new(password, ciph.MODE_CTR, counter=counter)
     obj2=ciph.new(password, ciph.MODE_CTR, counter=counter)
     start=time.time()
@@ -133,7 +133,7 @@
     del obj1, obj2
 
     # Test the IV handling
-    if verbose: print '  Testing IV handling'
+    if verbose: print('  Testing IV handling')
     obj1=ciph.new(password, ciph.MODE_CBC, IV)
     plaintext='Test'*(ciph.block_size/4)*3
     ciphertext1=obj1.encrypt(plaintext)
@@ -155,11 +155,11 @@
     try:
         ciph = eval(cipher)
     except (NameError):
-        print cipher, 'module not available'
+        print(cipher, 'module not available')
         return None
-    print cipher + ':',
+    print(cipher + ':', end=' ')
     str='1'                             # Build 128K of test data
-    for i in xrange(0, 17):
+    for i in range(0, 17):
         str=str+str
     key_size = ciph.key_size or 16
     password = 'password12345678Extra text for password'[0:key_size]
@@ -192,7 +192,7 @@
 
 def TestStreamModules(args=['arc4', 'XOR'], verbose=1):
     import sys, string
-    args=map(string.lower, args)
+    args=list(map(string.lower, args))
 
     if 'arc4' in args:
         # Test ARC4 stream cipher
@@ -206,7 +206,7 @@
                     obj=arc4.new(key)
                     ciphertext=obj.encrypt(plain)
                     if (ciphertext!=cipher):
-                        die('ARC4 failed on entry '+`entry`)
+                        die('ARC4 failed on entry '+repr(entry))
 
     if 'xor' in args:
         # Test XOR stream cipher
@@ -220,18 +220,18 @@
                     obj=XOR.new(key)
                     ciphertext=obj.encrypt(plain)
                     if (ciphertext!=cipher):
-                        die('XOR failed on entry '+`entry`)
+                        die('XOR failed on entry '+repr(entry))
 
 
 def TestBlockModules(args=['aes', 'arc2', 'des', 'blowfish', 'cast', 'des3',
                            'idea', 'rc5'],
                      verbose=1):
     import string
-    args=map(string.lower, args)
+    args=list(map(string.lower, args))
     if 'aes' in args:
         ciph=exerciseBlockCipher('AES', verbose)        # AES
         if (ciph!=None):
-                if verbose: print '  Verifying against test suite...'
+                if verbose: print('  Verifying against test suite...')
                 for entry in testdata.aes:
                     key,plain,cipher=entry
                     key=binascii.a2b_hex(key)
@@ -240,10 +240,10 @@
                     obj=ciph.new(key, ciph.MODE_ECB)
                     ciphertext=obj.encrypt(plain)
                     if (ciphertext!=cipher):
-                        die('AES failed on entry '+`entry`)
-                        for i in ciphertext:
-                            if verbose: print hex(ord(i)),
-                        if verbose: print
+                        die('AES failed on entry '+repr(entry))
+                        for i in ciphertext:
+                            if verbose: print(hex(ord(i)), end=' ')
+                        if verbose: print()
 
                 for entry in testdata.aes_modes:
                     mode, key, plain, cipher, kw = entry
@@ -254,23 +254,23 @@
                     obj2=ciph.new(key, mode, **kw)
                     ciphertext=obj.encrypt(plain)
                     if (ciphertext!=cipher):
-                        die('AES encrypt failed on entry '+`entry`)
-                        for i in ciphertext:
-                            if verbose: print hex(ord(i)),
-                        if verbose: print
+                        die('AES encrypt failed on entry '+repr(entry))
+                        for i in ciphertext:
+                            if verbose: print(hex(ord(i)), end=' ')
+                        if verbose: print()
 
                     plain2=obj2.decrypt(ciphertext)
                     if plain2!=plain:
-                        die('AES decrypt failed on entry '+`entry`)
+                        die('AES decrypt failed on entry '+repr(entry))
                         for i in plain2:
-                            if verbose: print hex(ord(i)),
-                        if verbose: print
+                            if verbose: print(hex(ord(i)), end=' ')
+                        if verbose: print()
 
 
     if 'arc2' in args:
         ciph=exerciseBlockCipher('ARC2', verbose)           # Alleged RC2
         if (ciph!=None):
-                if verbose: print '  Verifying against test suite...'
+                if verbose: print('  Verifying against test suite...')
                 for entry in testdata.arc2:
                     key,plain,cipher=entry
                     key=binascii.a2b_hex(key)
@@ -279,15 +279,15 @@
                     obj=ciph.new(key, ciph.MODE_ECB)
                     ciphertext=obj.encrypt(plain)
                     if (ciphertext!=cipher):
-                        die('ARC2 failed on entry '+`entry`)
-                        for i in ciphertext:
-                            if verbose: print hex(ord(i)),
-                        print
+                        die('ARC2 failed on entry '+repr(entry))
+                        for i in ciphertext:
+                            if verbose: print(hex(ord(i)), end=' ')
+                        print()
 
     if 'blowfish' in args:
         ciph=exerciseBlockCipher('Blowfish',verbose)# Bruce Schneier's Blowfish cipher
         if (ciph!=None):
-                if verbose: print '  Verifying against test suite...'
+                if verbose: print('  Verifying against test suite...')
                 for entry in testdata.blowfish:
                     key,plain,cipher=entry
                     key=binascii.a2b_hex(key)
@@ -296,15 +296,15 @@
                     obj=ciph.new(key, ciph.MODE_ECB)
                     ciphertext=obj.encrypt(plain)
                     if (ciphertext!=cipher):
-                        die('Blowfish failed on entry '+`entry`)
-                        for i in ciphertext:
-                            if verbose: print hex(ord(i)),
-                        if verbose: print
+                        die('Blowfish failed on entry '+repr(entry))
+                        for i in ciphertext:
+                            if verbose: print(hex(ord(i)), end=' ')
+                        if verbose: print()
 
     if 'cast' in args:
         ciph=exerciseBlockCipher('CAST', verbose)        # CAST-128
         if (ciph!=None):
-                if verbose: print '  Verifying against test suite...'
+                if verbose: print('  Verifying against test suite...')
                 for entry in testdata.cast:
                     key,plain,cipher=entry
                     key=binascii.a2b_hex(key)
@@ -313,10 +313,10 @@
                     obj=ciph.new(key, ciph.MODE_ECB)
                     ciphertext=obj.encrypt(plain)
                     if (ciphertext!=cipher):
-                        die('CAST failed on entry '+`entry`)
-                        for i in ciphertext:
-                            if verbose: print hex(ord(i)),
-                        if verbose: print
+                        die('CAST failed on entry '+repr(entry))
+                        for i in ciphertext:
+                            if verbose: print(hex(ord(i)), end=' ')
+                        if verbose: print()
 
                 if 0:
                     # The full-maintenance test; it requires 4 million encryptions,
@@ -332,9 +332,9 @@
                         b = obj.encrypt(b[:8]) + obj.encrypt(b[-8:])
 
                     if a!="\xEE\xA9\xD0\xA2\x49\xFD\x3B\xA6\xB3\x43\x6F\xB8\x9D\x6D\xCA\x92":
-                        if verbose: print 'CAST test failed: value of "a" doesn\'t match'
+                        if verbose: print('CAST test failed: value of "a" doesn\'t match')
                     if b!="\xB2\xC9\x5E\xB0\x0C\x31\xAD\x71\x80\xAC\x05\xB8\xE8\x3D\x69\x6E":
-                        if verbose: print 'CAST test failed: value of "b" doesn\'t match'
+                        if verbose: print('CAST test failed: value of "b" doesn\'t match')
 
     if 'des' in args:
         # Test/benchmark DES block cipher
@@ -370,7 +370,7 @@
             if x!=binascii.a2b_hex('1B1A2DDB4C642438'):
                 die("DES fails Rivest's test")
 
-            if verbose: print '  Verifying against test suite...'
+            if verbose: print('  Verifying against test suite...')
             for entry in testdata.des:
                 key,plain,cipher=entry
                 key=binascii.a2b_hex(key)
@@ -379,7 +379,7 @@
                 obj=des.new(key, des.MODE_ECB)
                 ciphertext=obj.encrypt(plain)
                 if (ciphertext!=cipher):
-                    die('DES failed on entry '+`entry`)
+                    die('DES failed on entry '+repr(entry))
             for entry in testdata.des_cbc:
                 key, iv, plain, cipher=entry
                 key, iv, cipher=binascii.a2b_hex(key),binascii.a2b_hex(iv),binascii.a2b_hex(cipher)
@@ -387,12 +387,12 @@
                 obj2=des.new(key, des.MODE_CBC, iv)
                 ciphertext=obj1.encrypt(plain)
                 if (ciphertext!=cipher):
-                    die('DES CBC mode failed on entry '+`entry`)
+                    die('DES CBC mode failed on entry '+repr(entry))
 
     if 'des3' in args:
         ciph=exerciseBlockCipher('DES3', verbose)        # Triple DES
         if (ciph!=None):
-                if verbose: print '  Verifying against test suite...'
+                if verbose: print('  Verifying against test suite...')
                 for entry in testdata.des3:
                     key,plain,cipher=entry
                     key=binascii.a2b_hex(key)
@@ -401,10 +401,10 @@
                     obj=ciph.new(key, ciph.MODE_ECB)
                     ciphertext=obj.encrypt(plain)
                     if (ciphertext!=cipher):
-                        die('DES3 failed on entry '+`entry`)
-                        for i in ciphertext:
-                            if verbose: print hex(ord(i)),
-                        if verbose: print
+                        die('DES3 failed on entry '+repr(entry))
+                        for i in ciphertext:
+                            if verbose: print(hex(ord(i)), end=' ')
+                        if verbose: print()
                 for entry in testdata.des3_cbc:
                     key, iv, plain, cipher=entry
                     key, iv, cipher=binascii.a2b_hex(key),binascii.a2b_hex(iv),binascii.a2b_hex(cipher)
@@ -412,12 +412,12 @@
                     obj2=ciph.new(key, ciph.MODE_CBC, iv)
                     ciphertext=obj1.encrypt(plain)
                     if (ciphertext!=cipher):
-                        die('DES3 CBC mode failed on entry '+`entry`)
+                        die('DES3 CBC mode failed on entry '+repr(entry))
 
     if 'idea' in args:
         ciph=exerciseBlockCipher('IDEA', verbose)       # IDEA block cipher
         if (ciph!=None):
-                if verbose: print '  Verifying against test suite...'
+                if verbose: print('  Verifying against test suite...')
                 for entry in testdata.idea:
                     key,plain,cipher=entry
                     key=binascii.a2b_hex(key)
@@ -426,13 +426,13 @@
                     obj=ciph.new(key, ciph.MODE_ECB)
                     ciphertext=obj.encrypt(plain)
                     if (ciphertext!=cipher):
-                        die('IDEA failed on entry '+`entry`)
+                        die('IDEA failed on entry '+repr(entry))
 
     if 'rc5' in args:
         # Ronald Rivest's RC5 algorithm
         ciph=exerciseBlockCipher('RC5', verbose)
         if (ciph!=None):
-                if verbose: print '  Verifying against test suite...'
+                if verbose: print('  Verifying against test suite...')
                 for entry in testdata.rc5:
                     key,plain,cipher=entry
                     key=binascii.a2b_hex(key)
@@ -444,10 +444,10 @@
                                  rounds  =ord(key[2]) )
                     ciphertext=obj.encrypt(plain)
                     if (ciphertext!=cipher):
-                        die('RC5 failed on entry '+`entry`)
-                        for i in ciphertext:
-                            if verbose: print hex(ord(i)),
-                        if verbose: print
-
-
-
+                        die('RC5 failed on entry '+repr(entry))
+                        for i in ciphertext:
+                            if verbose: print(hex(ord(i)), end=' ')
+                        if verbose: print()
+
+
+
--- ./ez/gdata/alt/appengine.py	(original)
+++ ./ez/gdata/alt/appengine.py	(refactored)
@@ -32,7 +32,7 @@
 __author__ = 'api.jscudder (Jeff Scudder)'
 
 
-import StringIO
+import io
 import pickle
 import atom.http_interface
 import atom.token_store
@@ -173,7 +173,7 @@
   """
 
   def __init__(self, urlfetch_response):
-    self.body = StringIO.StringIO(urlfetch_response.content)
+    self.body = io.StringIO(urlfetch_response.content)
     self.headers = urlfetch_response.headers
     self.status = urlfetch_response.status_code
     self.reason = ''
@@ -185,7 +185,7 @@
       return self.body.read(length)
 
   def getheader(self, name):
-    if not self.headers.has_key(name):
+    if name not in self.headers:
       return self.headers[name.lower()]
     return self.headers[name]
 
@@ -234,7 +234,7 @@
     """
     if url is None:
       return None
-    if isinstance(url, (str, unicode)):
+    if isinstance(url, str):
       url = atom.url.parse_url(url)
     tokens = load_auth_tokens(self.user)
     if url in tokens:
@@ -244,7 +244,7 @@
       else:
         del tokens[url]
         save_auth_tokens(tokens, self.user)
-    for scope, token in tokens.iteritems():
+    for scope, token in tokens.items():
       if token.valid_for_scope(url):
         return token
     return atom.http_interface.GenericToken()
@@ -259,7 +259,7 @@
     token_found = False
     scopes_to_delete = []
     tokens = load_auth_tokens(self.user)
-    for scope, stored_token in tokens.iteritems():
+    for scope, stored_token in tokens.items():
       if stored_token == token:
         scopes_to_delete.append(scope)
         token_found = True
--- ./ez/gdata/analytics/service.py	(original)
+++ ./ez/gdata/analytics/service.py	(refactored)
@@ -31,7 +31,7 @@
 __author__ = 'api.suryasev (Sal Uryasev)'
 
 
-import urllib
+import urllib.request, urllib.parse, urllib.error
 import atom
 import gdata.service
 import gdata.analytics
@@ -275,8 +275,8 @@
     """
     old_feed = self.feed
     self.feed = '/'.join([old_feed]) + '?' + \
-                urllib.urlencode(dict([(key, value) for key, value in \
-                self.elements.iteritems() if value]))
+                urllib.parse.urlencode(dict([(key, value) for key, value in \
+                self.elements.items() if value]))
     new_feed = gdata.service.Query.ToUri(self)
     self.feed = old_feed
     return new_feed
--- ./ez/gdata/apps/service.py	(original)
+++ ./ez/gdata/apps/service.py	(refactored)
@@ -26,7 +26,7 @@
       from xml.etree import ElementTree
     except ImportError:
       from elementtree import ElementTree
-import urllib
+import urllib.request, urllib.parse, urllib.error
 import gdata
 import atom.service
 import gdata.service
@@ -128,7 +128,7 @@
     try:
       return gdata.apps.EmailListFeedFromString(str(self.GetWithRetries(
             uri, num_retries=num_retries, delay=delay, backoff=backoff)))
-    except gdata.service.RequestError, e:
+    except gdata.service.RequestError as e:
       raise AppsForYourDomainException(e.args[0])
     
   def GetGeneratorForAllEmailLists(
@@ -157,7 +157,7 @@
       self._baseURL(), API_VER, list_name)
     try:
       return self.Get(uri, converter=gdata.apps.EmailListEntryFromString)
-    except gdata.service.RequestError, e:
+    except gdata.service.RequestError as e:
       raise AppsForYourDomainException(e.args[0])
 
   def RetrieveEmailLists(self, recipient):
@@ -167,7 +167,7 @@
       self._baseURL(), API_VER, recipient)
     try:
       ret = gdata.apps.EmailListFeedFromString(str(self.Get(uri)))
-    except gdata.service.RequestError, e:
+    except gdata.service.RequestError as e:
       raise AppsForYourDomainException(e.args[0])
     
     # pagination
@@ -181,7 +181,7 @@
       self._baseURL(), API_VER, list_name, recipient)
     try:
       self.Delete(uri)
-    except gdata.service.RequestError, e:
+    except gdata.service.RequestError as e:
       raise AppsForYourDomainException(e.args[0])
 
   def RetrievePageOfRecipients(self, list_name, start_recipient=None,
@@ -199,7 +199,7 @@
       return gdata.apps.EmailListRecipientFeedFromString(str(
           self.GetWithRetries(
             uri, num_retries=num_retries, delay=delay, backoff=backoff)))
-    except gdata.service.RequestError, e:
+    except gdata.service.RequestError as e:
       raise AppsForYourDomainException(e.args[0])
 
   def GetGeneratorForAllRecipients(
@@ -233,7 +233,7 @@
     try:
       return gdata.apps.EmailListRecipientEntryFromString(
         str(self.Post(recipient_entry, uri)))
-    except gdata.service.RequestError, e:
+    except gdata.service.RequestError as e:
       raise AppsForYourDomainException(e.args[0])
 
   def DeleteEmailList(self, list_name):
@@ -242,7 +242,7 @@
     uri = "%s/emailList/%s/%s" % (self._baseURL(), API_VER, list_name)
     try:
       self.Delete(uri)
-    except gdata.service.RequestError, e:
+    except gdata.service.RequestError as e:
       raise AppsForYourDomainException(e.args[0])
 
   def CreateEmailList(self, list_name):
@@ -254,7 +254,7 @@
     try: 
       return gdata.apps.EmailListEntryFromString(
         str(self.Post(email_list_entry, uri)))
-    except gdata.service.RequestError, e:
+    except gdata.service.RequestError as e:
       raise AppsForYourDomainException(e.args[0])
 
   def DeleteNickname(self, nickname):
@@ -263,7 +263,7 @@
     uri = "%s/nickname/%s/%s" % (self._baseURL(), API_VER, nickname)
     try:
       self.Delete(uri)
-    except gdata.service.RequestError, e:
+    except gdata.service.RequestError as e:
       raise AppsForYourDomainException(e.args[0])
 
   def RetrievePageOfNicknames(self, start_nickname=None,
@@ -278,7 +278,7 @@
     try:
       return gdata.apps.NicknameFeedFromString(str(self.GetWithRetries(
             uri, num_retries=num_retries, delay=delay, backoff=backoff)))
-    except gdata.service.RequestError, e:
+    except gdata.service.RequestError as e:
       raise AppsForYourDomainException(e.args[0])
 
   def GetGeneratorForAllNicknames(
@@ -308,7 +308,7 @@
     try:
       first_page = gdata.apps.NicknameFeedFromString(str(self.GetWithRetries(
             uri, num_retries=num_retries, delay=delay, backoff=backoff)))
-    except gdata.service.RequestError, e:
+    except gdata.service.RequestError as e:
       raise AppsForYourDomainException(e.args[0])
     return self.GetGeneratorFromLinkFinder(
       first_page, gdata.apps.NicknameFeedFromString, num_retries=num_retries,
@@ -320,7 +320,7 @@
     uri = "%s/nickname/%s?username=%s" % (self._baseURL(), API_VER, user_name)
     try:
       ret = gdata.apps.NicknameFeedFromString(str(self.Get(uri)))
-    except gdata.service.RequestError, e:
+    except gdata.service.RequestError as e:
       raise AppsForYourDomainException(e.args[0])
 
     # pagination
@@ -340,7 +340,7 @@
     uri = "%s/nickname/%s/%s" % (self._baseURL(), API_VER, nickname)
     try:
       return gdata.apps.NicknameEntryFromString(str(self.Get(uri)))
-    except gdata.service.RequestError, e:
+    except gdata.service.RequestError as e:
       raise AppsForYourDomainException(e.args[0])
 
   def CreateNickname(self, user_name, nickname):
@@ -354,7 +354,7 @@
     try: 
       return gdata.apps.NicknameEntryFromString(
         str(self.Post(nickname_entry, uri)))
-    except gdata.service.RequestError, e:
+    except gdata.service.RequestError as e:
       raise AppsForYourDomainException(e.args[0])
 
   def DeleteUser(self, user_name):
@@ -363,7 +363,7 @@
     uri = "%s/user/%s/%s" % (self._baseURL(), API_VER, user_name)
     try:
       return self.Delete(uri)
-    except gdata.service.RequestError, e:
+    except gdata.service.RequestError as e:
       raise AppsForYourDomainException(e.args[0])
 
   def UpdateUser(self, user_name, user_entry):
@@ -372,7 +372,7 @@
     uri = "%s/user/%s/%s" % (self._baseURL(), API_VER, user_name)
     try: 
       return gdata.apps.UserEntryFromString(str(self.Put(user_entry, uri)))
-    except gdata.service.RequestError, e:
+    except gdata.service.RequestError as e:
       raise AppsForYourDomainException(e.args[0])
 
   def CreateUser(self, user_name, family_name, given_name, password,
@@ -394,7 +394,7 @@
 
     try: 
       return gdata.apps.UserEntryFromString(str(self.Post(user_entry, uri)))
-    except gdata.service.RequestError, e:
+    except gdata.service.RequestError as e:
       raise AppsForYourDomainException(e.args[0])
 
   def SuspendUser(self, user_name):
@@ -424,7 +424,7 @@
     uri = "%s/user/%s/%s" % (self._baseURL(), API_VER, user_name)
     try:
       return gdata.apps.UserEntryFromString(str(self.Get(uri)))
-    except gdata.service.RequestError, e:
+    except gdata.service.RequestError as e:
       raise AppsForYourDomainException(e.args[0])
 
   def RetrievePageOfUsers(self, start_username=None,
@@ -439,7 +439,7 @@
     try:
       return gdata.apps.UserFeedFromString(str(self.GetWithRetries(
           uri, num_retries=num_retries, delay=delay, backoff=backoff)))
-    except gdata.service.RequestError, e:
+    except gdata.service.RequestError as e:
       raise AppsForYourDomainException(e.args[0])
 
   def GetGeneratorForAllUsers(self,
@@ -488,7 +488,7 @@
   def _GetPropertyEntry(self, properties):
     property_entry = gdata.apps.PropertyEntry()
     property = []
-    for name, value in properties.iteritems():
+    for name, value in properties.items():
       if name is not None and value is not None:
         property.append(gdata.apps.Property(name=name, value=value))
     property_entry.property = property
@@ -503,7 +503,7 @@
   def _GetPropertyFeed(self, uri):
     try:
       return gdata.apps.PropertyFeedFromString(str(self.Get(uri)))
-    except gdata.service.RequestError, e:
+    except gdata.service.RequestError as e:
       raise gdata.apps.service.AppsForYourDomainException(e.args[0])
 
   def _GetPropertiesList(self, uri):
@@ -520,7 +520,7 @@
     try:
       return self._PropertyEntry2Dict(gdata.apps.PropertyEntryFromString(
         str(self.Get(uri))))
-    except gdata.service.RequestError, e:
+    except gdata.service.RequestError as e:
       raise gdata.apps.service.AppsForYourDomainException(e.args[0])
 
   def _PostProperties(self, uri, properties):
@@ -528,7 +528,7 @@
     try:
       return self._PropertyEntry2Dict(gdata.apps.PropertyEntryFromString(
         str(self.Post(property_entry, uri))))
-    except gdata.service.RequestError, e:
+    except gdata.service.RequestError as e:
       raise gdata.apps.service.AppsForYourDomainException(e.args[0])
 
   def _PutProperties(self, uri, properties):
@@ -536,13 +536,13 @@
     try:
       return self._PropertyEntry2Dict(gdata.apps.PropertyEntryFromString(
         str(self.Put(property_entry, uri))))
-    except gdata.service.RequestError, e:
+    except gdata.service.RequestError as e:
       raise gdata.apps.service.AppsForYourDomainException(e.args[0])
 
   def _DeleteProperties(self, uri):
     try:
       self.Delete(uri)
-    except gdata.service.RequestError, e:
+    except gdata.service.RequestError as e:
       raise gdata.apps.service.AppsForYourDomainException(e.args[0])
 
 
--- ./ez/gdata/apps/adminsettings/service.py	(original)
+++ ./ez/gdata/apps/adminsettings/service.py	(refactored)
@@ -48,7 +48,7 @@
     uri = self._serviceUrl(location)
     try:
       return self._GetProperties(uri)
-    except gdata.service.RequestError, e:
+    except gdata.service.RequestError as e:
       raise AppsForYourDomainException(e.args[0])
 
   def GetDefaultLanguage(self):
@@ -232,9 +232,9 @@
 
     Returns: binary image file"""
  
-    import urllib
+    import urllib.request, urllib.parse, urllib.error
     url = 'http://www.google.com/a/cpanel/'+self.domain+'/images/logo.gif'
-    response = urllib.urlopen(url)
+    response = urllib.request.urlopen(url)
     return response.read()
 
   def UpdateDomainLogo(self, logoImage):
@@ -414,7 +414,7 @@
     uri = self._serviceUrl('email/gateway')
     try:
       return self._GetProperties(uri)
-    except gdata.service.RequestError, e:
+    except gdata.service.RequestError as e:
       raise AppsForYourDomainException(e.args[0])
     except TypeError:
       #if no outbound gateway is set, we get a TypeError,
--- ./ez/gdata/apps/audit/service.py	(original)
+++ ./ez/gdata/apps/audit/service.py	(refactored)
@@ -131,7 +131,7 @@
     uri = self._serviceUrl('mail/monitor', user=source_user+'/'+destination_user)
     try:
       return self._DeleteProperties(uri)
-    except gdata.service.RequestError, e:
+    except gdata.service.RequestError as e:
       raise AppsForYourDomainException(e.args[0])
 
   def createAccountInformationRequest(self, user):
@@ -148,7 +148,7 @@
     #XML Body is left empty
     try:
       return self._PostProperties(uri, properties)
-    except gdata.service.RequestError, e:
+    except gdata.service.RequestError as e:
       raise AppsForYourDomainException(e.args[0])
 
   def getAccountInformationRequestStatus(self, user, request_id):
@@ -164,7 +164,7 @@
     uri = self._serviceUrl('account', user=user+'/'+request_id)
     try:
       return self._GetProperties(uri)
-    except gdata.service.RequestError, e:
+    except gdata.service.RequestError as e:
       raise AppsForYourDomainException(e.args[0])
 
   def getAllAccountInformationRequestsStatus(self):
@@ -195,7 +195,7 @@
     uri = self._serviceUrl('account', user=user+'/'+request_id)
     try:
       return self._DeleteProperties(uri)
-    except gdata.service.RequestError, e:
+    except gdata.service.RequestError as e:
       raise AppsForYourDomainException(e.args[0])
 
   def createMailboxExportRequest(self, user, begin_date=None, end_date=None, include_deleted=False, search_query=None, headers_only=False):
@@ -242,7 +242,7 @@
     uri = self._serviceUrl('mail/export', user=user+'/'+request_id)
     try:
       return self._GetProperties(uri)
-    except gdata.service.RequestError, e:
+    except gdata.service.RequestError as e:
       raise AppsForYourDomainException(e.args[0])
 
   def getAllMailboxExportRequestsStatus(self):
@@ -273,5 +273,5 @@
     uri = self._serviceUrl('mail/export', user=user+'/'+request_id)
     try:
       return self._DeleteProperties(uri)
-    except gdata.service.RequestError, e:
-      raise AppsForYourDomainException(e.args[0])
+    except gdata.service.RequestError as e:
+      raise AppsForYourDomainException(e.args[0])
--- ./ez/gdata/apps/emailsettings/client.py	(original)
+++ ./ez/gdata/apps/emailsettings/client.py	(refactored)
@@ -28,7 +28,7 @@
 __author__ = 'Claudio Cherubino <ccherubino@google.com>'
 
 
-import urllib
+import urllib.request, urllib.parse, urllib.error
 
 import gdata.apps.emailsettings.data
 import gdata.client
@@ -181,7 +181,7 @@
     """
     uri = self.MakeEmailSettingsUri(username=username,
                                     setting_id=SETTING_ID_LABEL)
-    uri = '/'.join([uri, urllib.quote_plus(label)])
+    uri = '/'.join([uri, urllib.parse.quote_plus(label)])
     return self.delete(uri, **kwargs)
   
   DeleteLabel = delete_label
--- ./ez/gdata/apps/emailsettings/service.py	(original)
+++ ./ez/gdata/apps/emailsettings/service.py	(refactored)
@@ -235,7 +235,7 @@
     return self._PutProperties(uri, properties)
 
   def UpdateGeneral(self, username, page_size=None, shortcuts=None, arrows=None,
-                    snippets=None, unicode=None):
+                    snippets=None, str=None):
     """Update general settings.
 
     Args:
@@ -259,6 +259,6 @@
       properties['arrows'] = gdata.apps.service._bool2str(arrows)
     if snippets != None:
       properties['snippets'] = gdata.apps.service._bool2str(snippets)
-    if unicode != None:
-      properties['unicode'] = gdata.apps.service._bool2str(unicode)
-    return self._PutProperties(uri, properties)
+    if str != None:
+      properties['unicode'] = gdata.apps.service._bool2str(str)
+    return self._PutProperties(uri, properties)
--- ./ez/gdata/apps/groups/client.py	(original)
+++ ./ez/gdata/apps/groups/client.py	(refactored)
@@ -25,7 +25,7 @@
 __author__ = 'Shraddha gupta <shraddhag@google.com>'
 
 
-import urllib
+import urllib.request, urllib.parse, urllib.error
 import gdata.apps.groups.data
 import gdata.client
 
@@ -95,7 +95,7 @@
     if member_id:
       uri += '/' + member_id
     if params:
-      uri += '?' + urllib.urlencode(params)
+      uri += '?' + urllib.parse.urlencode(params)
     return uri
 
   MakeGroupProvisioningUri = make_group_provisioning_uri
--- ./ez/gdata/apps/groups/service.py	(original)
+++ ./ez/gdata/apps/groups/service.py	(refactored)
@@ -22,7 +22,7 @@
 __author__ = 'google-apps-apis@googlegroups.com'
 
 
-import urllib
+import urllib.request, urllib.parse, urllib.error
 import gdata.apps
 import gdata.apps.service
 import gdata.service
@@ -59,16 +59,16 @@
         return GROUP_ID_URL % (domain, group_id)
       elif member_id != '':
         if direct_only:
-          return GROUP_MEMBER_DIRECT_URL % (domain, urllib.quote_plus(member_id),
+          return GROUP_MEMBER_DIRECT_URL % (domain, urllib.parse.quote_plus(member_id),
                                             self._Bool2Str(direct_only))
         else:
-          return GROUP_MEMBER_URL % (domain, urllib.quote_plus(member_id))
+          return GROUP_MEMBER_URL % (domain, urllib.parse.quote_plus(member_id))
       else:
         return BASE_URL % (domain)
 
     if service_type == 'member':
       if member_id != '' and is_existed:
-        return MEMBER_ID_URL % (domain, group_id, urllib.quote_plus(member_id))
+        return MEMBER_ID_URL % (domain, group_id, urllib.parse.quote_plus(member_id))
       elif suspended_users:
         return MEMBER_WITH_SUSPENDED_URL % (domain, group_id,
                                             self._Bool2Str(suspended_users))
@@ -77,7 +77,7 @@
 
     if service_type == 'owner':
       if owner_email != '' and is_existed:
-        return OWNER_ID_URL % (domain, group_id, urllib.quote_plus(owner_email))
+        return OWNER_ID_URL % (domain, group_id, urllib.parse.quote_plus(owner_email))
       elif suspended_users:
         return OWNER_WITH_SUSPENDED_URL % (domain, group_id,
                                            self._Bool2Str(suspended_users))
@@ -93,7 +93,7 @@
     try:
       self._GetProperties(uri)
       return True
-    except gdata.apps.service.AppsForYourDomainException, e:
+    except gdata.apps.service.AppsForYourDomainException as e:
       if e.error_code == gdata.apps.service.ENTITY_DOES_NOT_EXIST:
         return False
       else:
--- ./ez/gdata/apps/migration/service.py	(original)
+++ ./ez/gdata/apps/migration/service.py	(refactored)
@@ -76,14 +76,12 @@
     mail_entry.rfc822_msg = migration.Rfc822Msg(text=(base64.b64encode(
         mail_message)))
     mail_entry.rfc822_msg.encoding = 'base64'
-    mail_entry.mail_item_property = map(
-        lambda x: migration.MailItemProperty(value=x), mail_item_properties)
-    mail_entry.label = map(lambda x: migration.Label(label_name=x),
-                           mail_labels)
+    mail_entry.mail_item_property = [migration.MailItemProperty(value=x) for x in mail_item_properties]
+    mail_entry.label = [migration.Label(label_name=x) for x in mail_labels]
 
     try:
       return migration.MailEntryFromString(str(self.Post(mail_entry, uri)))
-    except gdata.service.RequestError, e:
+    except gdata.service.RequestError as e:
       # Store the number of failed imports when importing several at a time 
       self.exceptions += 1
       raise gdata.apps.service.AppsForYourDomainException(e.args[0])
@@ -107,10 +105,8 @@
     mail_entry.rfc822_msg = migration.Rfc822Msg(text=(base64.b64encode(
         mail_message)))
     mail_entry.rfc822_msg.encoding = 'base64'
-    mail_entry.mail_item_property = map(
-        lambda x: migration.MailItemProperty(value=x), mail_item_properties)
-    mail_entry.label = map(lambda x: migration.Label(label_name=x),
-                           mail_labels)
+    mail_entry.mail_item_property = [migration.MailItemProperty(value=x) for x in mail_item_properties]
+    mail_entry.label = [migration.Label(label_name=x) for x in mail_labels]
 
     self.mail_batch.AddBatchEntry(mail_entry)
 
@@ -136,7 +132,7 @@
     try:
       self.result = self.Post(self.mail_batch, uri,
                               converter=migration.BatchMailEventFeedFromString)
-    except gdata.service.RequestError, e:
+    except gdata.service.RequestError as e:
       raise gdata.apps.service.AppsForYourDomainException(e.args[0])
 
     self.mail_batch = migration.BatchMailEventFeed()
@@ -212,7 +208,7 @@
         batch_min = batch_max
 
       self.mail_entries = []
-    except Exception, e:
+    except Exception as e:
       raise Exception(e.args[0])
     else:
       return num_entries - self.exceptions
--- ./ez/gdata/apps/multidomain/client.py	(original)
+++ ./ez/gdata/apps/multidomain/client.py	(refactored)
@@ -26,7 +26,7 @@
 __author__ = 'Claudio Cherubino <ccherubino@google.com>'
 
 
-import urllib
+import urllib.request, urllib.parse, urllib.error
 import gdata.apps.multidomain.data
 import gdata.client
 
@@ -97,7 +97,7 @@
     if email:
       uri += '/' + email
     if params:
-      uri += '?' + urllib.urlencode(params)
+      uri += '?' + urllib.parse.urlencode(params)
     return uri
 
   MakeMultidomainProvisioningUri = make_multidomain_provisioning_uri
--- ./ez/gdata/apps/organization/client.py	(original)
+++ ./ez/gdata/apps/organization/client.py	(refactored)
@@ -27,7 +27,7 @@
 __author__ = 'Gunjan Sharma <gunjansharma@google.com>'
 
 
-import urllib
+import urllib.request, urllib.parse, urllib.error
 import gdata.apps.organization.data
 import gdata.client
 
@@ -99,7 +99,7 @@
     if org_unit_path_or_user_email:
       uri += '/' + org_unit_path_or_user_email
     if params:
-      uri += '?' + urllib.urlencode(params)
+      uri += '?' + urllib.parse.urlencode(params)
     return uri
 
   MakeOrganizationUnitProvisioningUri = make_organization_unit_provisioning_uri
--- ./ez/gdata/blogger/client.py	(original)
+++ ./ez/gdata/blogger/client.py	(refactored)
@@ -145,7 +145,7 @@
   Update = update
 
   def delete(self, entry_or_uri, auth_token=None, **kwargs):
-    if isinstance(entry_or_uri, (str, unicode, atom.http_core.Uri)):
+    if isinstance(entry_or_uri, (str, atom.http_core.Uri)):
       return gdata.client.GDClient.delete(self, entry_or_uri,
                                           auth_token=auth_token, **kwargs)
     # The Blogger API does not currently support ETags, so for now remove
--- ./ez/gdata/blogger/data.py	(original)
+++ ./ez/gdata/blogger/data.py	(refactored)
@@ -22,7 +22,7 @@
 
 
 import re
-import urlparse
+import urllib.parse
 import atom.core
 import gdata.data
 
@@ -75,7 +75,7 @@
     """
     for link in self.link:
       if link.rel == 'alternate':
-        return urlparse.urlparse(link.href)[1].split(".", 1)[0]
+        return urllib.parse.urlparse(link.href)[1].split(".", 1)[0]
     return None
 
   GetBlogName = get_blog_name
--- ./ez/gdata/books/service.py	(original)
+++ ./ez/gdata/books/service.py	(refactored)
@@ -124,7 +124,7 @@
                     upper bound is exclusive
         """
 
-        for k, v in kwargs.items():
+        for k, v in list(kwargs.items()):
             if not v:
                 continue
             k = k.lower()
--- ./ez/gdata/calendar/__init__.py	(original)
+++ ./ez/gdata/calendar/__init__.py	(refactored)
@@ -337,7 +337,7 @@
     self.extension_attributes = extension_attributes or {}
 
   def findKey(self, value):
-     res=[item[0] for item in self.enum_map.items() if item[1] == value]
+     res=[item[0] for item in list(self.enum_map.items()) if item[1] == value]
      if res is None or len(res) == 0:
        return None
      return res[0]
@@ -348,7 +348,7 @@
       self.value = self.enum_map[value]
       return
     # Find the attribute in this class's list of attributes.
-    if self.__class__._attributes.has_key(attribute):
+    if attribute in self.__class__._attributes:
       # Find the member of this class which corresponds to the XML attribute
       # (lookup in current_class._attributes) and set this member to the
       # desired value (using self.__dict__).
@@ -364,7 +364,7 @@
     # This uses the class's _children dictionary to find the members which
     # should become XML child nodes.
     member_node_names = [values[0] for tag, values in
-                                       self.__class__._children.iteritems()]
+                                       self.__class__._children.items()]
     for member_name in member_node_names:
       member = getattr(self, member_name)
       if member is None:
@@ -379,7 +379,7 @@
     if key is not None:
       tree.attrib[self.attrib_name]=key
     # Convert the members of this class which are XML attributes.
-    for xml_attribute, member_name in self.__class__._attributes.iteritems():
+    for xml_attribute, member_name in self.__class__._attributes.items():
       member = getattr(self, member_name)
       if member is not None:
         tree.attrib[xml_attribute] = member
@@ -940,7 +940,7 @@
                                                         child_tree))
       return
     # Find the element's tag in this class's list of child members
-    if self.__class__._children.has_key(child_tree.tag):
+    if child_tree.tag in self.__class__._children:
       member_name = self.__class__._children[child_tree.tag][0]
       member_class = self.__class__._children[child_tree.tag][1]
       # If the class member is supposed to contain a list, make sure the
--- ./ez/gdata/calendar/client.py	(original)
+++ ./ez/gdata/calendar/client.py	(refactored)
@@ -28,7 +28,7 @@
 __author__ = 'alainv (Alain Vongsouvanh)'
 
 
-import urllib
+import urllib.request, urllib.parse, urllib.error
 import gdata.client
 import gdata.calendar.data
 import atom.data
--- ./ez/gdata/calendar/service.py	(original)
+++ ./ez/gdata/calendar/service.py	(refactored)
@@ -28,7 +28,7 @@
 __author__ = 'api.vli (Vivian Li)'
 
 
-import urllib
+import urllib.request, urllib.parse, urllib.error
 import gdata
 import atom.service
 import gdata.service
@@ -452,13 +452,13 @@
                text_query=None, params=None, categories=None):
     gdata.service.Query.__init__(self, 
         feed='http://www.google.com/calendar/feeds/%s/%s/%s' % (
-            urllib.quote(user), 
-            urllib.quote(visibility), 
-            urllib.quote(projection)),
+            urllib.parse.quote(user), 
+            urllib.parse.quote(visibility), 
+            urllib.parse.quote(projection)),
         text_query=text_query, params=params, categories=categories)
     
   def _GetStartMin(self):
-    if 'start-min' in self.keys():
+    if 'start-min' in list(self.keys()):
       return self['start-min']
     else:
       return None
@@ -470,7 +470,7 @@
       doc="""The start-min query parameter""")
 
   def _GetStartMax(self):
-    if 'start-max' in self.keys():
+    if 'start-max' in list(self.keys()):
       return self['start-max']
     else:
       return None
@@ -482,21 +482,21 @@
       doc="""The start-max query parameter""")
 
   def _GetOrderBy(self):
-    if 'orderby' in self.keys():
+    if 'orderby' in list(self.keys()):
       return self['orderby']
     else:
       return None
 
   def _SetOrderBy(self, val):
     if val is not 'lastmodified' and val is not 'starttime':
-      raise Error, "Order By must be either 'lastmodified' or 'starttime'"
+      raise Error("Order By must be either 'lastmodified' or 'starttime'")
     self['orderby'] = val
 
   orderby = property(_GetOrderBy, _SetOrderBy, 
       doc="""The orderby query parameter""")
 
   def _GetSortOrder(self):
-    if 'sortorder' in self.keys():
+    if 'sortorder' in list(self.keys()):
       return self['sortorder']
     else:
       return None
@@ -505,15 +505,15 @@
     if (val is not 'ascending' and val is not 'descending' 
         and val is not 'a' and val is not 'd' and val is not 'ascend'
         and val is not 'descend'):
-      raise Error, "Sort order must be either ascending, ascend, " + (
-          "a or descending, descend, or d")
+      raise Error("Sort order must be either ascending, ascend, " + (
+          "a or descending, descend, or d"))
     self['sortorder'] = val
 
   sortorder = property(_GetSortOrder, _SetSortOrder, 
       doc="""The sortorder query parameter""")
 
   def _GetSingleEvents(self):
-    if 'singleevents' in self.keys():
+    if 'singleevents' in list(self.keys()):
       return self['singleevents']
     else:
       return None
@@ -525,7 +525,7 @@
       doc="""The singleevents query parameter""")
 
   def _GetFutureEvents(self):
-    if 'futureevents' in self.keys():
+    if 'futureevents' in list(self.keys()):
       return self['futureevents']
     else:
       return None
@@ -537,7 +537,7 @@
       doc="""The futureevents query parameter""")
 
   def _GetRecurrenceExpansionStart(self):
-    if 'recurrence-expansion-start' in self.keys():
+    if 'recurrence-expansion-start' in list(self.keys()):
       return self['recurrence-expansion-start']
     else:
       return None
@@ -550,7 +550,7 @@
       doc="""The recurrence-expansion-start query parameter""")
 
   def _GetRecurrenceExpansionEnd(self):
-    if 'recurrence-expansion-end' in self.keys():
+    if 'recurrence-expansion-end' in list(self.keys()):
       return self['recurrence-expansion-end']
     else:
       return None
@@ -566,7 +566,7 @@
     self['ctz'] = val
 
   def _GetTimezone(self):
-    if 'ctz' in self.keys():
+    if 'ctz' in list(self.keys()):
       return self['ctz']
     else:
       return None
--- ./ez/gdata/calendar_resource/client.py	(original)
+++ ./ez/gdata/calendar_resource/client.py	(refactored)
@@ -28,7 +28,7 @@
 
 import gdata.calendar_resource.data
 import gdata.client
-import urllib
+import urllib.request, urllib.parse, urllib.error
 
 
 # Feed URI template.  This must end with a /
@@ -86,7 +86,7 @@
     if resource_id:
       uri += resource_id
     if params:
-      uri += '?' + urllib.urlencode(params)
+      uri += '?' + urllib.parse.urlencode(params)
     return uri
 
   MakeResourceFeedUri = make_resource_feed_uri
--- ./ez/gdata/contacts/client.py	(original)
+++ ./ez/gdata/contacts/client.py	(refactored)
@@ -159,7 +159,7 @@
       for link in calendar_link:
         if not isinstance(link, gdata.contacts.data.CalendarLink):
           if type(link) is not DictionaryType:
-            raise TypeError, "calendar_link Requires dictionary not %s" % type(link)
+            raise TypeError("calendar_link Requires dictionary not %s" % type(link))
 
           link = gdata.contacts.data.CalendarLink(
                                                   rel=link.get("rel", None),
--- ./ez/gdata/contentforshopping/client.py	(original)
+++ ./ez/gdata/contentforshopping/client.py	(refactored)
@@ -21,7 +21,7 @@
 __author__ = 'afshar (Ali Afshar), dhermes (Daniel Hermes)'
 
 
-import urllib
+import urllib.request, urllib.parse, urllib.error
 
 import atom.data
 import gdata.client
@@ -78,7 +78,7 @@
     segments = [self.cfs_uri, self.cfs_api_version, account_id, resource]
     if use_projection:
       segments.append(CFS_PROJECTION)
-    segments.extend(urllib.quote(value) for value in path)
+    segments.extend(urllib.parse.quote(value) for value in path)
     result = '/'.join(segments)
 
     request_params = []
--- ./ez/gdata/docs/client.py	(original)
+++ ./ez/gdata/docs/client.py	(refactored)
@@ -21,7 +21,7 @@
 import copy
 import mimetypes
 import re
-import urllib
+import urllib.request, urllib.parse, urllib.error
 import atom.data
 import atom.http_core
 import gdata.client
@@ -60,7 +60,7 @@
       Result of super(DocsClient, self).request().
     """
     if self.xoauth_requestor_id is not None and uri is not None:
-      if isinstance(uri, (str, unicode)):
+      if isinstance(uri, str):
         uri = atom.http_core.Uri.parse_uri(uri)
       uri.path.replace('/default', '/%s' % self.xoauth_requestor_id)
     return super(DocsClient, self).request(method=method, uri=uri, **kwargs)
@@ -137,7 +137,7 @@
     if uri is None:
       uri = RESOURCE_FEED_URI
 
-    if isinstance(uri, basestring):
+    if isinstance(uri, str):
       uri = atom.http_core.Uri.parse_uri(uri)
 
     # Add max-results param if it wasn't included in the uri.
@@ -177,7 +177,7 @@
     if uri is None:
       uri = RESOURCE_FEED_URI
 
-    if isinstance(uri, basestring):
+    if isinstance(uri, str):
       uri = atom.http_core.Uri.parse_uri(uri)
 
     if show_root is not None:
@@ -238,7 +238,7 @@
     Returns:
       gdata.docs.data.Resource representing the retrieved resource.
     """
-    if isinstance(uri, basestring):
+    if isinstance(uri, str):
       uri = atom.http_core.Uri.parse_uri(uri)
     if show_root is not None:
       uri.query['showroot'] = str(show_root).lower()
@@ -398,13 +398,13 @@
     uri = base_uri.replace('&amp;', '&')
     if extra_params is not None:
       if 'exportFormat' in extra_params and '/Export?' not in uri:
-        raise gdata.client.Error, ('This entry type cannot be exported '
+        raise gdata.client.Error('This entry type cannot be exported '
                                    'as a different format.')
 
       if 'gid' in extra_params and uri.find('spreadsheets') == -1:
-        raise gdata.client.Error, 'gid param is not valid for this resource type.'
-
-      uri += '&' + urllib.urlencode(extra_params)
+        raise gdata.client.Error('gid param is not valid for this resource type.')
+
+      uri += '&' + urllib.parse.urlencode(extra_params)
     return uri
 
   def _get_content(self, uri, extra_params=None, auth_token=None, **kwargs):
@@ -445,9 +445,9 @@
     server_response = self.request(
         'GET', uri, auth_token=token, **kwargs)
     if server_response.status != 200:
-      raise gdata.client.RequestError, {'status': server_response.status,
+      raise gdata.client.RequestError({'status': server_response.status,
                                         'reason': server_response.reason,
-                                        'body': server_response.read()}
+                                        'body': server_response.read()})
     return server_response.read()
 
   def _download_file(self, uri, file_path, **kwargs):
@@ -466,7 +466,7 @@
     f = open(file_path, 'wb')
     try:
       f.write(self._get_content(uri, **kwargs))
-    except gdata.client.RequestError, e:
+    except gdata.client.RequestError as e:
       f.close()
       raise e
     f.flush()
@@ -518,7 +518,7 @@
       for current_collection in entry.InCollections():
         uri = '%s/contents/%s' % (
             current_collection.href,
-            urllib.quote(entry.resource_id.text))
+            urllib.parse.quote(entry.resource_id.text))
         self.delete(uri, force=True)
 
     if collection is not None:
--- ./ez/gdata/docs/data.py	(original)
+++ ./ez/gdata/docs/data.py	(refactored)
@@ -178,8 +178,8 @@
       atom.data.Category if found or None.
     """
     try:
-      return self.get_categories(scheme).next()
-    except StopIteration, e:
+      return next(self.get_categories(scheme))
+    except StopIteration as e:
       # The entry doesn't have the category
       return None
 
@@ -367,7 +367,7 @@
     entry = AclEntry()
 
     if role is not None:
-      if isinstance(role, basestring):
+      if isinstance(role, str):
         role = gdata.acl.data.AclRole(value=role)
 
       if key:
@@ -409,11 +409,11 @@
 
   def __init__(self, type=None, title=None, **kwargs):
     super(Resource, self).__init__(**kwargs)
-    if isinstance(type, basestring):
+    if isinstance(type, str):
       self.set_resource_type(type)
 
     if title is not None:
-      if isinstance(title, basestring):
+      if isinstance(title, str):
         self.title = atom.data.Title(text=title)
       else:
         self.title = title
--- ./ez/gdata/docs/service.py	(original)
+++ ./ez/gdata/docs/service.py	(refactored)
@@ -33,7 +33,7 @@
 import atom
 import gdata.service
 import gdata.docs
-import urllib
+import urllib.request, urllib.parse, urllib.error
 
 # XML Namespaces used in Google Documents entities.
 DATA_KIND_SCHEME = gdata.GDATA_NAMESPACE + '#kind'
@@ -123,7 +123,7 @@
     if label == SPREADSHEET_LABEL:
       return ('https://spreadsheets.google.com/feeds/download/spreadsheets/'
               'Export?key=%s' % doc_id)
-    raise ValueError, 'Invalid resource id: %s' % resource_id
+    raise ValueError('Invalid resource id: %s' % resource_id)
 
   def _UploadFile(self, media_source, title, category, folder_or_uri=None):
     """Uploads a file to the Document List feed.
@@ -180,9 +180,9 @@
       response_body = server_response.read()
       timeout -= 1
     if server_response.status != 200:
-      raise gdata.service.RequestError, {'status': server_response.status,
+      raise gdata.service.RequestError({'status': server_response.status,
                                          'reason': server_response.reason,
-                                         'body': response_body}
+                                         'body': response_body})
     f = open(file_path, 'wb')
     f.write(response_body)
     f.flush()
@@ -332,17 +332,17 @@
 
     if export_format is not None:
       if url.find('/Export?') == -1:
-        raise gdata.service.Error, ('This entry cannot be exported '
+        raise gdata.service.Error('This entry cannot be exported '
                                     'as a different format')
       url += '&exportFormat=%s' % export_format
 
     if gid is not None:
       if url.find('spreadsheets') == -1:
-        raise gdata.service.Error, 'grid id param is not valid for this entry'
+        raise gdata.service.Error('grid id param is not valid for this entry')
       url += '&gid=%s' % gid
 
     if extra_params:
-      url += '&' + urllib.urlencode(extra_params)
+      url += '&' + urllib.parse.urlencode(extra_params)
 
     self._DownloadFile(url, file_path)
 
--- ./ez/gdata/exif/__init__.py	(original)
+++ ./ez/gdata/exif/__init__.py	(refactored)
@@ -44,7 +44,7 @@
 """
 
 
--- ./ez/gdata/geo/__init__.py	(original)
+++ ./ez/gdata/geo/__init__.py	(refactored)
@@ -39,7 +39,7 @@
 #elements mentioned above, but this module will let you seamlessly convert 
 #between the different formats (TODO 2007-10-18 hg)
 
--- ./ez/gdata/marketplace/client.py	(original)
+++ ./ez/gdata/marketplace/client.py	(refactored)
@@ -26,7 +26,7 @@
 
 import gdata.marketplace.data
 import gdata.client
-import urllib
+import urllib.request, urllib.parse, urllib.error
 
 
 # Feed URI template.  This must end with a /
@@ -76,9 +76,9 @@
       Apps domain.
     """
     parameters = '[appid=%s][domain=%s]' % (app_id, self.domain)
-    uri = LICENSE_FEED_TEMPLATE + urllib.quote_plus(parameters)
+    uri = LICENSE_FEED_TEMPLATE + urllib.parse.quote_plus(parameters)
     if params:
-      uri += '&' + urllib.urlencode(params)
+      uri += '&' + urllib.parse.urlencode(params)
     return uri
 
   MakeLicenseFeedUri = make_license_feed_uri
@@ -108,9 +108,9 @@
       parameters += '[max-results=%s]' % max_results
     else:
       parameters += '[max-results=100]'
-    uri = LICENSE_NOTIFICATIONS_FEED_TEMPLATE + urllib.quote_plus(parameters)
+    uri = LICENSE_NOTIFICATIONS_FEED_TEMPLATE + urllib.parse.quote_plus(parameters)
     if params:
-      uri += '&' + urllib.urlencode(params)
+      uri += '&' + urllib.parse.urlencode(params)
     return uri
 
   MakeLicenseNotificationsFeedUri = make_license_notifications_feed_uri
--- ./ez/gdata/media/__init__.py	(original)
+++ ./ez/gdata/media/__init__.py	(refactored)
@@ -45,7 +45,7 @@
 media:title
 """
 
--- ./ez/gdata/oauth/__init__.py	(original)
+++ ./ez/gdata/oauth/__init__.py	(refactored)
@@ -1,8 +1,8 @@
 import cgi
-import urllib
+import urllib.request, urllib.parse, urllib.error
 import time
 import random
-import urlparse
+import urllib.parse
 import hmac
 import binascii
 
@@ -22,7 +22,7 @@
 # url escape
 def escape(s):
     # escape '/' too
-    return urllib.quote(s, safe='~')
+    return urllib.parse.quote(s, safe='~')
 
 # util function: current timestamp
 # seconds since epoch (UTC)
@@ -60,7 +60,7 @@
         self.secret = secret
 
     def to_string(self):
-        return urllib.urlencode({'oauth_token': self.key, 'oauth_token_secret': self.secret})
+        return urllib.parse.urlencode({'oauth_token': self.key, 'oauth_token_secret': self.secret})
 
     # return a token from something like:
     # oauth_token_secret=digg&oauth_token=digg
@@ -112,7 +112,7 @@
     # get any non-oauth parameters
     def get_nonoauth_parameters(self):
         parameters = {}
-        for k, v in self.parameters.iteritems():
+        for k, v in self.parameters.items():
             # ignore oauth parameters
             if k.find('oauth_') < 0:
                 parameters[k] = v
@@ -123,14 +123,14 @@
         auth_header = 'OAuth realm="%s"' % realm
         # add the oauth parameters
         if self.parameters:
-            for k, v in self.parameters.iteritems():
+            for k, v in self.parameters.items():
                 if k[:6] == 'oauth_':
                     auth_header += ', %s="%s"' % (k, escape(str(v)))
         return {'Authorization': auth_header}
 
     # serialize as post data for a POST request
     def to_postdata(self):
-        return '&'.join(['%s=%s' % (escape(str(k)), escape(str(v))) for k, v in self.parameters.iteritems()])
+        return '&'.join(['%s=%s' % (escape(str(k)), escape(str(v))) for k, v in self.parameters.items()])
 
     # serialize as a url for a GET request
     def to_url(self):
@@ -144,7 +144,7 @@
             del params['oauth_signature']
         except:
             pass
-        key_values = params.items()
+        key_values = list(params.items())
         # sort lexicographically, first after key, then after value
         key_values.sort()
         # combine key value pairs in string and escape
@@ -156,7 +156,7 @@
 
     # parses the url and rebuilds it to be scheme://host/path
     def get_normalized_http_url(self):
-        parts = urlparse.urlparse(self.http_url)
+        parts = urllib.parse.urlparse(self.http_url)
         host = parts[1].lower()
         if host.endswith(':80') or host.endswith(':443'):
             host = host.split(':')[0] 
@@ -197,7 +197,7 @@
             parameters.update(query_params)
 
         # URL parameters
-        param_str = urlparse.urlparse(http_url)[4] # query
+        param_str = urllib.parse.urlparse(http_url)[4] # query
         url_params = OAuthRequest._split_url_string(param_str)
         parameters.update(url_params)
 
@@ -252,7 +252,7 @@
             # split key-value
             param_parts = param.split('=', 1)
             # remove quotes and unescape the value
-            params[param_parts[0]] = urllib.unquote(param_parts[1].strip('\"'))
+            params[param_parts[0]] = urllib.parse.unquote(param_parts[1].strip('\"'))
         return params
     _split_header = staticmethod(_split_header)
     
@@ -260,8 +260,8 @@
     # even empty values should be included
     def _split_url_string(param_str):
         parameters = cgi.parse_qs(param_str, keep_blank_values=True)
-        for k, v in parameters.iteritems():
-            parameters[k] = urllib.unquote(v[0])
+        for k, v in parameters.items():
+            parameters[k] = urllib.parse.unquote(v[0])
         return parameters
     _split_url_string = staticmethod(_split_url_string)
 
@@ -355,7 +355,7 @@
             # get the signature method object
             signature_method = self.signature_methods[signature_method]
         except:
-            signature_method_names = ', '.join(self.signature_methods.keys())
+            signature_method_names = ', '.join(list(self.signature_methods.keys()))
             raise OAuthError('Signature method %s not supported try one of the following: %s' % (signature_method, signature_method_names))
 
         return signature_method
--- ./ez/gdata/photos/__init__.py	(original)
+++ ./ez/gdata/photos/__init__.py	(refactored)
@@ -33,7 +33,7 @@
 
   """
 
--- ./ez/gdata/photos/service.py	(original)
+++ ./ez/gdata/photos/service.py	(refactored)
@@ -75,12 +75,12 @@
 
 """
 
--- ./ez/gdata/sites/client.py	(original)
+++ ./ez/gdata/sites/client.py	(refactored)
@@ -102,9 +102,9 @@
     """
     server_response = self.request('GET', uri)
     if server_response.status != 200:
-      raise  gdata.client.RequestError, {'status': server_response.status,
+      raise  gdata.client.RequestError({'status': server_response.status,
                                          'reason': server_response.reason,
-                                         'body': server_response.read()}
+                                         'body': server_response.read()})
     return server_response.read()
 
   _GetFileContent = _get_file_content
@@ -471,7 +471,7 @@
     f = open(file_path, 'wb')
     try:
       f.write(self._get_file_content(uri))
-    except gdata.client.RequestError, e:
+    except gdata.client.RequestError as e:
       f.close()
       raise e
     f.flush()
--- ./ez/gdata/spreadsheet/__init__.py	(original)
+++ ./ez/gdata/spreadsheet/__init__.py	(refactored)
@@ -143,7 +143,7 @@
     # Fill in the instance members from the contents of the XML tree.
     for child in tree:
       self._ConvertElementTreeToMember(child)
-    for attribute, value in tree.attrib.iteritems():
+    for attribute, value in tree.attrib.items():
       self._ConvertElementAttributeToMember(attribute, value)
     self.text = tree.text
 
@@ -319,7 +319,7 @@
   # convert custom attributes to members
   def _ConvertElementTreeToMember(self, child_tree):
     # Find the element's tag in this class's list of child members
-    if self.__class__._children.has_key(child_tree.tag):
+    if child_tree.tag in self.__class__._children:
       member_name = self.__class__._children[child_tree.tag][0]
       member_class = self.__class__._children[child_tree.tag][1]
       # If the class member is supposed to contain a list, make sure the
@@ -349,7 +349,7 @@
     # This uses the class's _children dictionary to find the members which
     # should become XML child nodes.
     member_node_names = [values[0] for tag, values in 
-                                       self.__class__._children.iteritems()]
+                                       self.__class__._children.items()]
     for member_name in member_node_names:
       member = getattr(self, member_name)
       if member is None:
@@ -360,12 +360,12 @@
       else:
         member._BecomeChildElement(tree)
     # Convert the members of this class which are XML attributes.
-    for xml_attribute, member_name in self.__class__._attributes.iteritems():
+    for xml_attribute, member_name in self.__class__._attributes.items():
       member = getattr(self, member_name)
       if member is not None:
         tree.attrib[xml_attribute] = member
     # Convert all special custom item attributes to nodes
-    for name, custom in self.custom.iteritems():
+    for name, custom in self.custom.items():
       custom._BecomeChildElement(tree)
     # Lastly, call the ExtensionContainers's _AddMembersToElementTree to 
     # convert any extension attributes.
--- ./ez/gdata/spreadsheet/service.py	(original)
+++ ./ez/gdata/spreadsheet/service.py	(refactored)
@@ -327,7 +327,7 @@
       The inserted row
     """
     new_entry = gdata.spreadsheet.SpreadsheetsList()
-    for k, v in row_data.iteritems():
+    for k, v in row_data.items():
       new_custom = gdata.spreadsheet.Custom()
       new_custom.column = k
       new_custom.text = v
@@ -355,7 +355,7 @@
       The updated row
     """
     entry.custom = {}
-    for k, v in new_row_data.iteritems():
+    for k, v in new_row_data.items():
       new_custom = gdata.spreadsheet.Custom()
       new_custom.column = k
       new_custom.text = v
--- ./ez/gdata/spreadsheet/text_db.py	(original)
+++ ./ez/gdata/spreadsheet/text_db.py	(refactored)
@@ -15,7 +15,7 @@
 # limitations under the License.
 
 
-import StringIO
+import io
 import gdata
 import gdata.service
 import gdata.spreadsheet
@@ -141,7 +141,7 @@
     # Create a Google Spreadsheet to form the foundation of this database.
     # Spreadsheet is created by uploading a file to the Google Documents
     # List API.
-    virtual_csv_file = StringIO.StringIO(',,,')
+    virtual_csv_file = io.StringIO(',,,')
     virtual_media_source = gdata.MediaSource(file_handle=virtual_csv_file, content_type='text/csv', content_length=3)
     db_entry = self.__docs_client.UploadSpreadsheet(virtual_media_source, name)
     return Database(spreadsheet_entry=db_entry, database_client=self)
@@ -503,7 +503,7 @@
     self.content = {}
     if entry:
       self.row_id = entry.id.text.split('/')[-1]
-      for label, custom in entry.custom.iteritems():
+      for label, custom in entry.custom.items():
         self.content[label] = custom.text
 
   def Push(self):
--- ./ez/gdata/spreadsheets/client.py	(original)
+++ ./ez/gdata/spreadsheets/client.py	(refactored)
@@ -200,7 +200,7 @@
     data = gdata.spreadsheets.data.Data(
         insertion_mode=insertion_mode, num_rows=str(num_rows),
         start_row=str(start_row))
-    for index, name in column_headers.iteritems():
+    for index, name in column_headers.items():
       data.column.append(gdata.spreadsheets.data.Column(
           index=index, name=name))
     new_table = gdata.spreadsheets.data.Table(
@@ -265,7 +265,7 @@
     new_record = gdata.spreadsheets.data.Record()
     if title is not None:
       new_record.title = atom.data.Title(text=title)
-    for name, value in fields.iteritems():
+    for name, value in fields.items():
       new_record.field.append(gdata.spreadsheets.data.Field(
           name=name, text=value))
     return self.post(new_record, RECORDS_URL % (spreadsheet_key, table_id),
--- ./ez/gdata/spreadsheets/data.py	(original)
+++ ./ez/gdata/spreadsheets/data.py	(refactored)
@@ -306,7 +306,7 @@
     Old values which are already in the entry will not be removed unless
     they are overwritten with new values from the dict.
     """
-    for column, value in values.iteritems():
+    for column, value in values.items():
       self.set_value(column, value)
 
 
--- ./ez/gdata/tlslite/BaseDB.py	(original)
+++ ./ez/gdata/tlslite/BaseDB.py	(refactored)
@@ -1,7 +1,7 @@
 """Base class for SharedKeyDB and VerifierDB."""
 
-import anydbm
-import thread
+import dbm
+import _thread
 
 class BaseDB:
     def __init__(self, filename, type):
@@ -11,7 +11,7 @@
             self.db = None
         else:
             self.db = {}
-        self.lock = thread.allocate_lock()
+        self.lock = _thread.allocate_lock()
 
     def create(self):
         """Create a new on-disk database.
@@ -19,7 +19,7 @@
         @raise anydbm.error: If there's a problem creating the database.
         """
         if self.filename:
-            self.db = anydbm.open(self.filename, "n") #raises anydbm.error
+            self.db = dbm.open(self.filename, "n") #raises anydbm.error
             self.db["--Reserved--type"] = self.type
             self.db.sync()
         else:
@@ -33,7 +33,7 @@
         """
         if not self.filename:
             raise ValueError("Can only open on-disk databases")
-        self.db = anydbm.open(self.filename, "w") #raises anydbm.error
+        self.db = dbm.open(self.filename, "w") #raises anydbm.error
         try:
             if self.db["--Reserved--type"] != self.type:
                 raise ValueError("Not a %s database" % self.type)
@@ -94,7 +94,7 @@
 
         self.lock.acquire()
         try:
-            return self.db.has_key(username)
+            return username in self.db
         finally:
             self.lock.release()
 
@@ -113,7 +113,7 @@
 
         self.lock.acquire()
         try:
-            usernames = self.db.keys()
+            usernames = list(self.db.keys())
         finally:
             self.lock.release()
         usernames = [u for u in usernames if not u.startswith("--Reserved--")]
--- ./ez/gdata/tlslite/Checker.py	(original)
+++ ./ez/gdata/tlslite/Checker.py	(refactored)
@@ -1,9 +1,9 @@
 """Class for post-handshake certificate checking."""
 
-from utils.cryptomath import hashAndBase64
-from X509 import X509
-from X509CertChain import X509CertChain
-from errors import *
+from .utils.cryptomath import hashAndBase64
+from .X509 import X509
+from .X509CertChain import X509CertChain
+from .errors import *
 
 
 class Checker:
--- ./ez/gdata/tlslite/FileObject.py	(original)
+++ ./ez/gdata/tlslite/FileObject.py	(refactored)
@@ -70,7 +70,7 @@
     def writelines(self, list):
         # XXX We could do better here for very long lists
         # XXX Should really reject non-string non-buffers
-        self._wbuf.extend(filter(None, map(str, list)))
+        self._wbuf.extend([_f for _f in map(str, list) if _f])
         if (self._wbufsize <= 1 or
             self._get_wbuf_len() >= self._wbufsize):
             self.flush()
@@ -213,7 +213,7 @@
     def __iter__(self):
         return self
 
-    def next(self):
+    def __next__(self):
         line = self.readline()
         if not line:
             raise StopIteration
--- ./ez/gdata/tlslite/HandshakeSettings.py	(original)
+++ ./ez/gdata/tlslite/HandshakeSettings.py	(refactored)
@@ -1,8 +1,8 @@
 """Class for setting handshake parameters."""
 
-from constants import CertificateType
-from utils import cryptomath
-from utils import cipherfactory
+from .constants import CertificateType
+from .utils import cryptomath
+from .utils import cipherfactory
 
 class HandshakeSettings:
     """This class encapsulates various parameters that can be used with
--- ./ez/gdata/tlslite/Session.py	(original)
+++ ./ez/gdata/tlslite/Session.py	(refactored)
@@ -1,8 +1,8 @@
 """Class representing a TLS session."""
 
-from utils.compat import *
-from mathtls import *
-from constants import *
+from .utils.compat import *
+from .mathtls import *
+from .constants import *
 
 class Session:
     """
--- ./ez/gdata/tlslite/SessionCache.py	(original)
+++ ./ez/gdata/tlslite/SessionCache.py	(refactored)
@@ -1,6 +1,6 @@
 """Class for caching TLS sessions."""
 
-import thread
+import _thread
 import time
 
 class SessionCache:
@@ -31,7 +31,7 @@
         @param maxAge:  The number of seconds before a session expires
         from the cache.  The default is 14400 (i.e. 4 hours)."""
 
-        self.lock = thread.allocate_lock()
+        self.lock = _thread.allocate_lock()
 
         # Maps sessionIDs to sessions
         self.entriesDict = {}
--- ./ez/gdata/tlslite/SharedKeyDB.py	(original)
+++ ./ez/gdata/tlslite/SharedKeyDB.py	(refactored)
@@ -1,10 +1,10 @@
 """Class for storing shared keys."""
 
-from utils.cryptomath import *
-from utils.compat import *
-from mathtls import *
-from Session import Session
-from BaseDB import BaseDB
+from .utils.cryptomath import *
+from .utils.compat import *
+from .mathtls import *
+from .Session import Session
+from .BaseDB import BaseDB
 
 class SharedKeyDB(BaseDB):
     """This class represent an in-memory or on-disk database of shared
--- ./ez/gdata/tlslite/TLSConnection.py	(original)
+++ ./ez/gdata/tlslite/TLSConnection.py	(refactored)
@@ -1,18 +1,18 @@
 """
 MAIN CLASS FOR TLS LITE (START HERE!).
 """
-from __future__ import generators
+
 
 import socket
-from utils.compat import formatExceptionTrace
-from TLSRecordLayer import TLSRecordLayer
-from Session import Session
-from constants import *
-from utils.cryptomath import getRandomBytes
-from errors import *
-from messages import *
-from mathtls import *
-from HandshakeSettings import HandshakeSettings
+from .utils.compat import formatExceptionTrace
+from .TLSRecordLayer import TLSRecordLayer
+from .Session import Session
+from .constants import *
+from .utils.cryptomath import getRandomBytes
+from .errors import *
+from .messages import *
+from .mathtls import *
+from .HandshakeSettings import HandshakeSettings
 
 
 class TLSConnection(TLSRecordLayer):
@@ -1561,11 +1561,11 @@
                         for result in self._sendMsg(alert):
                             yield result
                         raise
-            except socket.error, e:
+            except socket.error as e:
                 raise TLSFaultError("socket error!")
-            except TLSAbruptCloseError, e:
+            except TLSAbruptCloseError as e:
                 raise TLSFaultError("abrupt close error!")
-            except TLSAlert, alert:
+            except TLSAlert as alert:
                 if alert.description not in Fault.faultAlerts[self.fault]:
                     raise TLSFaultError(str(alert))
                 else:
--- ./ez/gdata/tlslite/TLSRecordLayer.py	(original)
+++ ./ez/gdata/tlslite/TLSRecordLayer.py	(refactored)
@@ -1,17 +1,17 @@
 """Helper class for TLSConnection."""
-from __future__ import generators
-
-from utils.compat import *
-from utils.cryptomath import *
-from utils.cipherfactory import createAES, createRC4, createTripleDES
-from utils.codec import *
-from errors import *
-from messages import *
-from mathtls import *
-from constants import *
-from utils.cryptomath import getRandomBytes
-from utils import hmac
-from FileObject import FileObject
+
+
+from .utils.compat import *
+from .utils.cryptomath import *
+from .utils.cipherfactory import createAES, createRC4, createTripleDES
+from .utils.codec import *
+from .errors import *
+from .messages import *
+from .mathtls import *
+from .constants import *
+from .utils.cryptomath import getRandomBytes
+from .utils import hmac
+from .FileObject import FileObject
 import sha
 import md5
 import socket
@@ -203,7 +203,7 @@
                             yield result
                     applicationData = result
                     self._readBuffer += bytesToString(applicationData.write())
-                except TLSRemoteAlert, alert:
+                except TLSRemoteAlert as alert:
                     if alert.description != AlertDescription.close_notify:
                         raise
                 except TLSAbruptCloseError:
@@ -538,7 +538,7 @@
         while 1:
             try:
                 bytesSent = self.sock.send(s) #Might raise socket.error
-            except socket.error, why:
+            except socket.error as why:
                 if why[0] == errno.EWOULDBLOCK:
                     yield 1
                     continue
@@ -701,7 +701,7 @@
                     raise AssertionError()
 
         #If an exception was raised by a Parser or Message instance:
-        except SyntaxError, e:
+        except SyntaxError as e:
             for result in self._sendError(AlertDescription.decode_error,
                                          formatExceptionTrace(e)):
                 yield result
@@ -725,7 +725,7 @@
         while 1:
             try:
                 s = self.sock.recv(recordHeaderLength-len(bytes))
-            except socket.error, why:
+            except socket.error as why:
                 if why[0] == errno.EWOULDBLOCK:
                     yield 0
                     continue
@@ -765,7 +765,7 @@
         while 1:
             try:
                 s = self.sock.recv(r.length - len(bytes))
-            except socket.error, why:
+            except socket.error as why:
                 if why[0] == errno.EWOULDBLOCK:
                     yield 0
                     continue
--- ./ez/gdata/tlslite/VerifierDB.py	(original)
+++ ./ez/gdata/tlslite/VerifierDB.py	(refactored)
@@ -1,9 +1,9 @@
 """Class for storing SRP password verifiers."""
 
-from utils.cryptomath import *
-from utils.compat import *
-import mathtls
-from BaseDB import BaseDB
+from .utils.cryptomath import *
+from .utils.compat import *
+from . import mathtls
+from .BaseDB import BaseDB
 
 class VerifierDB(BaseDB):
     """This class represent an in-memory or on-disk database of SRP
--- ./ez/gdata/tlslite/X509.py	(original)
+++ ./ez/gdata/tlslite/X509.py	(refactored)
@@ -1,8 +1,8 @@
 """Class representing an X.509 certificate."""
 
-from utils.ASN1Parser import ASN1Parser
-from utils.cryptomath import *
-from utils.keyfactory import _createPublicRSAKey
+from .utils.ASN1Parser import ASN1Parser
+from .utils.cryptomath import *
+from .utils.keyfactory import _createPublicRSAKey
 
 
 class X509:
@@ -120,7 +120,7 @@
                 returnVal = array.array('B', [0] * length)
                 cryptlib_py.cryptGetAttributeString(c, name, returnVal)
                 returnVal = returnVal.tostring()
-            except cryptlib_py.CryptException, e:
+            except cryptlib_py.CryptException as e:
                 if e[0] == cryptlib_py.CRYPT_ERROR_NOTFOUND:
                     returnVal = None
             return returnVal
--- ./ez/gdata/tlslite/X509CertChain.py	(original)
+++ ./ez/gdata/tlslite/X509CertChain.py	(refactored)
@@ -1,6 +1,6 @@
 """Class representing an X.509 certificate chain."""
 
-from utils import cryptomath
+from .utils import cryptomath
 
 class X509CertChain:
     """This class represents a chain of X.509 certificates.
@@ -150,7 +150,7 @@
                 lastName = array.array('B', [0] * length)
                 cryptlib_py.cryptGetAttributeString(lastC, name, lastName)
                 lastName = lastName.tostring()
-            except cryptlib_py.CryptException, e:
+            except cryptlib_py.CryptException as e:
                 if e[0] == cryptlib_py.CRYPT_ERROR_NOTFOUND:
                     lastName = None
             try:
@@ -158,7 +158,7 @@
                 rootName = array.array('B', [0] * length)
                 cryptlib_py.cryptGetAttributeString(rootC, name, rootName)
                 rootName = rootName.tostring()
-            except cryptlib_py.CryptException, e:
+            except cryptlib_py.CryptException as e:
                 if e[0] == cryptlib_py.CRYPT_ERROR_NOTFOUND:
                     rootName = None
 
--- ./ez/gdata/tlslite/api.py	(original)
+++ ./ez/gdata/tlslite/api.py	(refactored)
@@ -43,33 +43,33 @@
                                  parseAsPublicKey, parsePrivateKey
 """
 
-from constants import AlertLevel, AlertDescription, Fault
-from errors import *
-from Checker import Checker
-from HandshakeSettings import HandshakeSettings
-from Session import Session
-from SessionCache import SessionCache
-from SharedKeyDB import SharedKeyDB
-from TLSConnection import TLSConnection
-from VerifierDB import VerifierDB
-from X509 import X509
-from X509CertChain import X509CertChain
+from .constants import AlertLevel, AlertDescription, Fault
+from .errors import *
+from .Checker import Checker
+from .HandshakeSettings import HandshakeSettings
+from .Session import Session
+from .SessionCache import SessionCache
+from .SharedKeyDB import SharedKeyDB
+from .TLSConnection import TLSConnection
+from .VerifierDB import VerifierDB
+from .X509 import X509
+from .X509CertChain import X509CertChain
 
-from integration.HTTPTLSConnection import HTTPTLSConnection
-from integration.TLSSocketServerMixIn import TLSSocketServerMixIn
-from integration.TLSAsyncDispatcherMixIn import TLSAsyncDispatcherMixIn
-from integration.POP3_TLS import POP3_TLS
-from integration.IMAP4_TLS import IMAP4_TLS
-from integration.SMTP_TLS import SMTP_TLS
-from integration.XMLRPCTransport import XMLRPCTransport
+from .integration.HTTPTLSConnection import HTTPTLSConnection
+from .integration.TLSSocketServerMixIn import TLSSocketServerMixIn
+from .integration.TLSAsyncDispatcherMixIn import TLSAsyncDispatcherMixIn
+from .integration.POP3_TLS import POP3_TLS
+from .integration.IMAP4_TLS import IMAP4_TLS
+from .integration.SMTP_TLS import SMTP_TLS
+from .integration.XMLRPCTransport import XMLRPCTransport
 try:
     import twisted
     del(twisted)
-    from integration.TLSTwistedProtocolWrapper import TLSTwistedProtocolWrapper
+    from .integration.TLSTwistedProtocolWrapper import TLSTwistedProtocolWrapper
 except ImportError:
     pass
 
-from utils.cryptomath import cryptlibpyLoaded, m2cryptoLoaded, gmpyLoaded, \
+from .utils.cryptomath import cryptlibpyLoaded, m2cryptoLoaded, gmpyLoaded, \
                              pycryptoLoaded, prngName
-from utils.keyfactory import generateRSAKey, parsePEMKey, parseXMLKey, \
+from .utils.keyfactory import generateRSAKey, parsePEMKey, parseXMLKey, \
                              parseAsPublicKey, parsePrivateKey
--- ./ez/gdata/tlslite/constants.py	(original)
+++ ./ez/gdata/tlslite/constants.py	(refactored)
@@ -174,26 +174,26 @@
     badUsername = 101
     badPassword = 102
     badA = 103
-    clientSrpFaults = range(101,104)
+    clientSrpFaults = list(range(101,104))
 
     badVerifyMessage = 601
-    clientCertFaults = range(601,602)
+    clientCertFaults = list(range(601,602))
 
     badPremasterPadding = 501
     shortPremasterSecret = 502
-    clientNoAuthFaults = range(501,503)
+    clientNoAuthFaults = list(range(501,503))
 
     badIdentifier = 401
     badSharedKey = 402
-    clientSharedKeyFaults = range(401,403)
+    clientSharedKeyFaults = list(range(401,403))
 
     badB = 201
-    serverFaults = range(201,202)
+    serverFaults = list(range(201,202))
 
     badFinished = 300
     badMAC = 301
     badPadding = 302
-    genericFaults = range(300,303)
+    genericFaults = list(range(300,303))
 
     faultAlerts = {\
         badUsername: (AlertDescription.unknown_srp_username, \
--- ./ez/gdata/tlslite/errors.py	(original)
+++ ./ez/gdata/tlslite/errors.py	(refactored)
@@ -4,7 +4,7 @@
 TLSFingerprintError, TLSAuthorizationError, TLSValidationError, TLSFaultError
 """
 
-from constants import AlertDescription, AlertLevel
+from .constants import AlertDescription, AlertLevel
 
 class TLSError(Exception):
     """Base class for all TLS Lite exceptions."""
--- ./ez/gdata/tlslite/mathtls.py	(original)
+++ ./ez/gdata/tlslite/mathtls.py	(refactored)
@@ -1,7 +1,7 @@
 """Miscellaneous helper functions."""
 
-from utils.compat import *
-from utils.cryptomath import *
+from .utils.compat import *
+from .utils.cryptomath import *
 
 import hmac
 import md5
--- ./ez/gdata/tlslite/messages.py	(original)
+++ ./ez/gdata/tlslite/messages.py	(refactored)
@@ -1,12 +1,12 @@
 """Classes representing TLS messages."""
 
-from utils.compat import *
-from utils.cryptomath import *
-from errors import *
-from utils.codec import *
-from constants import *
-from X509 import X509
-from X509CertChain import X509CertChain
+from .utils.compat import *
+from .utils.cryptomath import *
+from .errors import *
+from .utils.codec import *
+from .constants import *
+from .X509 import X509
+from .X509CertChain import X509CertChain
 
 import sha
 import md5
@@ -364,10 +364,10 @@
     def __init__(self, cipherSuite):
         self.cipherSuite = cipherSuite
         self.contentType = ContentType.handshake
-        self.srp_N = 0L
-        self.srp_g = 0L
+        self.srp_N = 0
+        self.srp_g = 0
         self.srp_s = createByteArraySequence([])
-        self.srp_B = 0L
+        self.srp_B = 0
         self.signature = createByteArraySequence([])
 
     def createSRP(self, srp_N, srp_g, srp_s, srp_B):
--- ./ez/gdata/tlslite/integration/AsyncStateMachine.py	(original)
+++ ./ez/gdata/tlslite/integration/AsyncStateMachine.py	(refactored)
@@ -154,7 +154,7 @@
 
     def _doHandshakeOp(self):
         try:
-            self.result = self.handshaker.next()
+            self.result = next(self.handshaker)
         except StopIteration:
             self.handshaker = None
             self.result = None
@@ -162,14 +162,14 @@
 
     def _doCloseOp(self):
         try:
-            self.result = self.closer.next()
+            self.result = next(self.closer)
         except StopIteration:
             self.closer = None
             self.result = None
             self.outCloseEvent()
 
     def _doReadOp(self):
-        self.result = self.reader.next()
+        self.result = next(self.reader)
         if not self.result in (0,1):
             readBuffer = self.result
             self.reader = None
@@ -178,7 +178,7 @@
 
     def _doWriteOp(self):
         try:
-            self.result = self.writer.next()
+            self.result = next(self.writer)
         except StopIteration:
             self.writer = None
             self.result = None
--- ./ez/gdata/tlslite/integration/HTTPTLSConnection.py	(original)
+++ ./ez/gdata/tlslite/integration/HTTPTLSConnection.py	(refactored)
@@ -1,12 +1,12 @@
 """TLS Lite + httplib."""
 
 import socket
-import httplib
+import http.client
 from gdata.tlslite.TLSConnection import TLSConnection
 from gdata.tlslite.integration.ClientHelper import ClientHelper
 
 
-class HTTPBaseTLSConnection(httplib.HTTPConnection):
+class HTTPBaseTLSConnection(http.client.HTTPConnection):
     """This abstract class provides a framework for adding TLS support
     to httplib."""
 
@@ -15,9 +15,9 @@
     def __init__(self, host, port=None, strict=None):
         if strict == None:
             #Python 2.2 doesn't support strict
-            httplib.HTTPConnection.__init__(self, host, port)
+            http.client.HTTPConnection.__init__(self, host, port)
         else:
-            httplib.HTTPConnection.__init__(self, host, port, strict)
+            http.client.HTTPConnection.__init__(self, host, port, strict)
 
     def connect(self):
         sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
--- ./ez/gdata/tlslite/integration/POP3_TLS.py	(original)
+++ ./ez/gdata/tlslite/integration/POP3_TLS.py	(refactored)
@@ -114,14 +114,14 @@
             try:
                 self.sock = socket.socket(af, socktype, proto)
                 self.sock.connect(sa)
-            except socket.error, msg:
+            except socket.error as msg:
                 if self.sock:
                     self.sock.close()
                 self.sock = None
                 continue
             break
         if not self.sock:
-            raise socket.error, msg
+            raise socket.error(msg)
 
         ### New code below (all else copied from poplib)
         ClientHelper.__init__(self,
--- ./ez/gdata/tlslite/integration/TLSAsyncDispatcherMixIn.py	(original)
+++ ./ez/gdata/tlslite/integration/TLSAsyncDispatcherMixIn.py	(refactored)
@@ -3,7 +3,7 @@
 
 import asyncore
 from gdata.tlslite.TLSConnection import TLSConnection
-from AsyncStateMachine import AsyncStateMachine
+from .AsyncStateMachine import AsyncStateMachine
 
 
 class TLSAsyncDispatcherMixIn(AsyncStateMachine):
--- ./ez/gdata/tlslite/integration/TLSTwistedProtocolWrapper.py	(original)
+++ ./ez/gdata/tlslite/integration/TLSTwistedProtocolWrapper.py	(refactored)
@@ -3,7 +3,7 @@
 from twisted.protocols.policies import ProtocolWrapper, WrappingFactory
 from twisted.python.failure import Failure
 
-from AsyncStateMachine import AsyncStateMachine
+from .AsyncStateMachine import AsyncStateMachine
 from gdata.tlslite.TLSConnection import TLSConnection
 from gdata.tlslite.errors import *
 
@@ -24,7 +24,7 @@
 
     def recv(self, numBytes):
         if self.data == "":
-            raise socket.error, (errno.EWOULDBLOCK, "")
+            raise socket.error(errno.EWOULDBLOCK, "")
         returnData = self.data[:numBytes]
         self.data = self.data[numBytes:]
         return returnData
@@ -134,7 +134,7 @@
     def connectionMade(self):
         try:
             ProtocolWrapper.connectionMade(self)
-        except TLSError, e:
+        except TLSError as e:
             self.connectionLost(Failure(e))
             ProtocolWrapper.loseConnection(self)
 
@@ -146,7 +146,7 @@
                 self.fakeSocket.data += data
                 while self.fakeSocket.data:
                     AsyncStateMachine.inReadEvent(self)
-        except TLSError, e:
+        except TLSError as e:
             self.connectionLost(Failure(e))
             ProtocolWrapper.loseConnection(self)
 
--- ./ez/gdata/tlslite/integration/XMLRPCTransport.py	(original)
+++ ./ez/gdata/tlslite/integration/XMLRPCTransport.py	(refactored)
@@ -1,12 +1,12 @@
 """TLS Lite + xmlrpclib."""
 
-import xmlrpclib
-import httplib
+import xmlrpc.client
+import http.client
 from gdata.tlslite.integration.HTTPTLSConnection import HTTPTLSConnection
 from gdata.tlslite.integration.ClientHelper import ClientHelper
 
 
-class XMLRPCTransport(xmlrpclib.Transport, ClientHelper):
+class XMLRPCTransport(xmlrpc.client.Transport, ClientHelper):
     """Handles an HTTPS transaction to an XML-RPC server."""
 
     def __init__(self,
@@ -132,6 +132,6 @@
                                  self.checker.x509TrustList,
                                  self.checker.x509CommonName,
                                  self.settings)
-        http2 = httplib.HTTP()
+        http2 = http.client.HTTP()
         http2._setup(http)
         return http2
--- ./ez/gdata/tlslite/utils/ASN1Parser.py	(original)
+++ ./ez/gdata/tlslite/utils/ASN1Parser.py	(refactored)
@@ -1,6 +1,6 @@
 """Class for parsing ASN.1"""
-from compat import *
-from codec import *
+from .compat import *
+from .codec import *
 
 #Takes a byte array which has a DER TLV field at its head
 class ASN1Parser:
--- ./ez/gdata/tlslite/utils/Cryptlib_AES.py	(original)
+++ ./ez/gdata/tlslite/utils/Cryptlib_AES.py	(refactored)
@@ -1,7 +1,7 @@
 """Cryptlib AES implementation."""
 
-from cryptomath import *
-from AES import *
+from .cryptomath import *
+from .AES import *
 
 if cryptlibpyLoaded:
 
--- ./ez/gdata/tlslite/utils/Cryptlib_RC4.py	(original)
+++ ./ez/gdata/tlslite/utils/Cryptlib_RC4.py	(refactored)
@@ -1,7 +1,7 @@
 """Cryptlib RC4 implementation."""
 
-from cryptomath import *
-from RC4 import RC4
+from .cryptomath import *
+from .RC4 import RC4
 
 if cryptlibpyLoaded:
 
--- ./ez/gdata/tlslite/utils/Cryptlib_TripleDES.py	(original)
+++ ./ez/gdata/tlslite/utils/Cryptlib_TripleDES.py	(refactored)
@@ -1,8 +1,8 @@
 """Cryptlib 3DES implementation."""
 
-from cryptomath import *
+from .cryptomath import *
 
-from TripleDES import *
+from .TripleDES import *
 
 if cryptlibpyLoaded:
 
--- ./ez/gdata/tlslite/utils/OpenSSL_AES.py	(original)
+++ ./ez/gdata/tlslite/utils/OpenSSL_AES.py	(refactored)
@@ -1,7 +1,7 @@
 """OpenSSL/M2Crypto AES implementation."""
 
-from cryptomath import *
-from AES import *
+from .cryptomath import *
+from .AES import *
 
 if m2cryptoLoaded:
 
--- ./ez/gdata/tlslite/utils/OpenSSL_RC4.py	(original)
+++ ./ez/gdata/tlslite/utils/OpenSSL_RC4.py	(refactored)
@@ -1,7 +1,7 @@
 """OpenSSL/M2Crypto RC4 implementation."""
 
-from cryptomath import *
-from RC4 import RC4
+from .cryptomath import *
+from .RC4 import RC4
 
 if m2cryptoLoaded:
 
--- ./ez/gdata/tlslite/utils/OpenSSL_RSAKey.py	(original)
+++ ./ez/gdata/tlslite/utils/OpenSSL_RSAKey.py	(refactored)
@@ -1,9 +1,9 @@
 """OpenSSL/M2Crypto RSA implementation."""
 
-from cryptomath import *
+from .cryptomath import *
 
-from RSAKey import *
-from Python_RSAKey import Python_RSAKey
+from .RSAKey import *
+from .Python_RSAKey import Python_RSAKey
 
 #copied from M2Crypto.util.py, so when we load the local copy of m2
 #we can still use it
--- ./ez/gdata/tlslite/utils/OpenSSL_TripleDES.py	(original)
+++ ./ez/gdata/tlslite/utils/OpenSSL_TripleDES.py	(refactored)
@@ -1,7 +1,7 @@
 """OpenSSL/M2Crypto 3DES implementation."""
 
-from cryptomath import *
-from TripleDES import *
+from .cryptomath import *
+from .TripleDES import *
 
 if m2cryptoLoaded:
 
--- ./ez/gdata/tlslite/utils/PyCrypto_AES.py	(original)
+++ ./ez/gdata/tlslite/utils/PyCrypto_AES.py	(refactored)
@@ -1,7 +1,7 @@
 """PyCrypto AES implementation."""
 
-from cryptomath import *
-from AES import *
+from .cryptomath import *
+from .AES import *
 
 if pycryptoLoaded:
     import Crypto.Cipher.AES
--- ./ez/gdata/tlslite/utils/PyCrypto_RC4.py	(original)
+++ ./ez/gdata/tlslite/utils/PyCrypto_RC4.py	(refactored)
@@ -1,7 +1,7 @@
 """PyCrypto RC4 implementation."""
 
-from cryptomath import *
-from RC4 import *
+from .cryptomath import *
+from .RC4 import *
 
 if pycryptoLoaded:
     import Crypto.Cipher.ARC4
--- ./ez/gdata/tlslite/utils/PyCrypto_RSAKey.py	(original)
+++ ./ez/gdata/tlslite/utils/PyCrypto_RSAKey.py	(refactored)
@@ -1,9 +1,9 @@
 """PyCrypto RSA implementation."""
 
-from cryptomath import *
+from .cryptomath import *
 
-from RSAKey import *
-from Python_RSAKey import Python_RSAKey
+from .RSAKey import *
+from .Python_RSAKey import Python_RSAKey
 
 if pycryptoLoaded:
 
--- ./ez/gdata/tlslite/utils/PyCrypto_TripleDES.py	(original)
+++ ./ez/gdata/tlslite/utils/PyCrypto_TripleDES.py	(refactored)
@@ -1,7 +1,7 @@
 """PyCrypto 3DES implementation."""
 
-from cryptomath import *
-from TripleDES import *
+from .cryptomath import *
+from .TripleDES import *
 
 if pycryptoLoaded:
     import Crypto.Cipher.DES3
--- ./ez/gdata/tlslite/utils/Python_AES.py	(original)
+++ ./ez/gdata/tlslite/utils/Python_AES.py	(refactored)
@@ -1,9 +1,9 @@
 """Pure-Python AES implementation."""
 
-from cryptomath import *
+from .cryptomath import *
 
-from AES import *
-from rijndael import rijndael
+from .AES import *
+from .rijndael import rijndael
 
 def new(key, mode, IV):
     return Python_AES(key, mode, IV)
--- ./ez/gdata/tlslite/utils/Python_RC4.py	(original)
+++ ./ez/gdata/tlslite/utils/Python_RC4.py	(refactored)
@@ -1,7 +1,7 @@
 """Pure-Python RC4 implementation."""
 
-from RC4 import RC4
-from cryptomath import *
+from .RC4 import RC4
+from .cryptomath import *
 
 def new(key):
     return Python_RC4(key)
--- ./ez/gdata/tlslite/utils/Python_RSAKey.py	(original)
+++ ./ez/gdata/tlslite/utils/Python_RSAKey.py	(refactored)
@@ -1,9 +1,9 @@
 """Pure-Python RSA implementation."""
 
-from cryptomath import *
-import xmltools
-from ASN1Parser import ASN1Parser
-from RSAKey import *
+from .cryptomath import *
+from . import xmltools
+from .ASN1Parser import ASN1Parser
+from .RSAKey import *
 
 class Python_RSAKey(RSAKey):
     def __init__(self, n=0, e=0, d=0, p=0, q=0, dP=0, dQ=0, qInv=0):
@@ -99,7 +99,7 @@
         q = getRandomPrime(bits/2, False)
         t = lcm(p-1, q-1)
         key.n = p * q
-        key.e = 3L  #Needed to be long, for Java
+        key.e = 3  #Needed to be long, for Java
         key.d = invMod(key.e, t)
         key.p = p
         key.q = q
--- ./ez/gdata/tlslite/utils/RC4.py	(original)
+++ ./ez/gdata/tlslite/utils/RC4.py	(refactored)
@@ -1,6 +1,6 @@
 """Abstract class for RC4."""
 
-from compat import * #For False
+from .compat import * #For False
 
 class RC4:
     def __init__(self, keyBytes, implementation):
--- ./ez/gdata/tlslite/utils/RSAKey.py	(original)
+++ ./ez/gdata/tlslite/utils/RSAKey.py	(refactored)
@@ -1,6 +1,6 @@
 """Abstract class for RSA."""
 
-from cryptomath import *
+from .cryptomath import *
 
 
 class RSAKey:
--- ./ez/gdata/tlslite/utils/TripleDES.py	(original)
+++ ./ez/gdata/tlslite/utils/TripleDES.py	(refactored)
@@ -1,6 +1,6 @@
 """Abstract class for 3DES."""
 
-from compat import * #For True
+from .compat import * #For True
 
 class TripleDES:
     def __init__(self, key, mode, IV, implementation):
--- ./ez/gdata/tlslite/utils/cipherfactory.py	(original)
+++ ./ez/gdata/tlslite/utils/cipherfactory.py	(refactored)
@@ -2,29 +2,29 @@
 
 import os
 
-import Python_AES
-import Python_RC4
+from . import Python_AES
+from . import Python_RC4
 
-import cryptomath
+from . import cryptomath
 
 tripleDESPresent = False
 
 if cryptomath.m2cryptoLoaded:
-    import OpenSSL_AES
-    import OpenSSL_RC4
-    import OpenSSL_TripleDES
+    from . import OpenSSL_AES
+    from . import OpenSSL_RC4
+    from . import OpenSSL_TripleDES
     tripleDESPresent = True
 
 if cryptomath.cryptlibpyLoaded:
-    import Cryptlib_AES
-    import Cryptlib_RC4
-    import Cryptlib_TripleDES
+    from . import Cryptlib_AES
+    from . import Cryptlib_RC4
+    from . import Cryptlib_TripleDES
     tripleDESPresent = True
 
 if cryptomath.pycryptoLoaded:
-    import PyCrypto_AES
-    import PyCrypto_RC4
-    import PyCrypto_TripleDES
+    from . import PyCrypto_AES
+    from . import PyCrypto_RC4
+    from . import PyCrypto_TripleDES
     tripleDESPresent = True
 
 # **************************************************************************
--- ./ez/gdata/tlslite/utils/codec.py	(original)
+++ ./ez/gdata/tlslite/utils/codec.py	(refactored)
@@ -1,6 +1,6 @@
 """Classes for reading/writing binary data (such as TLS records)."""
 
-from compat import *
+from .compat import *
 
 class Writer:
     def __init__(self, length=0):
--- ./ez/gdata/tlslite/utils/compat.py	(original)
+++ ./ez/gdata/tlslite/utils/compat.py	(refactored)
@@ -9,7 +9,7 @@
 if sys.version_info < (2,3):
 
     def enumerate(collection):
-        return zip(range(len(collection)), collection)
+        return list(zip(list(range(len(collection))), collection))
 
     class Set:
         def __init__(self, seq=None):
@@ -22,31 +22,31 @@
             self.values[e] = None
 
         def discard(self, e):
-            if e in self.values.keys():
+            if e in list(self.values.keys()):
                 del(self.values[e])
 
         def union(self, s):
             ret = Set()
-            for e in self.values.keys():
+            for e in list(self.values.keys()):
                 ret.values[e] = None
-            for e in s.values.keys():
+            for e in list(s.values.keys()):
                 ret.values[e] = None
             return ret
 
         def issubset(self, other):
-            for e in self.values.keys():
-                if e not in other.values.keys():
+            for e in list(self.values.keys()):
+                if e not in list(other.values.keys()):
                     return False
             return True
 
-        def __nonzero__( self):
-            return len(self.values.keys())
+        def __bool__( self):
+            return len(list(self.values.keys()))
 
         def __contains__(self, e):
-            return e in self.values.keys()
+            return e in list(self.values.keys())
 
         def __iter__(self):
-            return iter(set.values.keys())
+            return iter(list(set.values.keys()))
 
 
 if os.name != "java":
@@ -83,7 +83,7 @@
     import sys
     import traceback
     def formatExceptionTrace(e):
-        newStr = "".join(traceback.format_exception(sys.exc_type, sys.exc_value, sys.exc_traceback))
+        newStr = "".join(traceback.format_exception(sys.exc_info()[0], sys.exc_info()[1], sys.exc_info()[2]))
         return newStr
 
 else:
@@ -120,7 +120,7 @@
     def numBits(n):
         if n==0:
             return 0
-        n= 1L * n; #convert to long, if it isn't already
+        n= 1 * n; #convert to long, if it isn't already
         return n.__tojava__(java.math.BigInteger).bitLength()
 
     #Adjust the string to an array of bytes
@@ -136,5 +136,5 @@
     import sys
     import traceback
     def formatExceptionTrace(e):
-        newStr = "".join(traceback.format_exception(sys.exc_type, sys.exc_value, sys.exc_traceback))
+        newStr = "".join(traceback.format_exception(sys.exc_info()[0], sys.exc_info()[1], sys.exc_info()[2]))
         return newStr
--- ./ez/gdata/tlslite/utils/cryptomath.py	(original)
+++ ./ez/gdata/tlslite/utils/cryptomath.py	(refactored)
@@ -12,7 +12,7 @@
 else:
   from hashlib import sha1
 
-from compat import *
+from .compat import *
 
 
 # **************************************************************************
@@ -33,7 +33,7 @@
     import cryptlib_py
     try:
         cryptlib_py.cryptInit()
-    except cryptlib_py.CryptException, e:
+    except cryptlib_py.CryptException as e:
         #If tlslite and cryptoIDlib are both present,
         #they might each try to re-initialize this,
         #so we're tolerant of that.
@@ -114,8 +114,8 @@
 # **************************************************************************
 
 def bytesToNumber(bytes):
-    total = 0L
-    multiplier = 1L
+    total = 0
+    multiplier = 1
     for count in range(len(bytes)-1, -1, -1):
         byte = bytes[count]
         total += multiplier * byte
@@ -157,9 +157,9 @@
 def base64ToString(s):
     try:
         return base64.decodestring(s)
-    except binascii.Error, e:
+    except binascii.Error as e:
         raise SyntaxError(e)
-    except binascii.Incomplete, e:
+    except binascii.Incomplete as e:
         raise SyntaxError(e)
 
 def stringToBase64(s):
@@ -258,7 +258,7 @@
         power = gmpy.mpz(power)
         modulus = gmpy.mpz(modulus)
         result = pow(base, power, modulus)
-        return long(result)
+        return int(result)
 
 else:
     #Copied from Bryan G. Olson's post to comp.lang.python
@@ -288,7 +288,7 @@
 
         # Make a table of powers of base up to 2**nBitScan - 1
         lowPowers = [1]
-        for i in xrange(1, exp2):
+        for i in range(1, exp2):
             lowPowers.append((lowPowers[i-1] * base) % modulus)
 
         # To exponentiate by the first nibble, look it up in the table
@@ -299,7 +299,7 @@
         # base^nibble
         while nibbles:
             nib, nibbles = nibbles
-            for i in xrange(nBitScan):
+            for i in range(nBitScan):
                 prod = (prod * prod) % modulus
             if nib: prod = (prod * lowPowers[nib]) % modulus
 
@@ -315,7 +315,7 @@
 
 #Pre-calculate a sieve of the ~100 primes < 1000:
 def makeSieve(n):
-    sieve = range(n)
+    sieve = list(range(n))
     for count in range(2, int(math.sqrt(n))):
         if sieve[count] == 0:
             continue
@@ -336,7 +336,7 @@
     #Passed trial division, proceed to Rabin-Miller
     #Rabin-Miller implemented per Ferguson & Schneier
     #Compute s, t for Rabin-Miller
-    if display: print "*",
+    if display: print("*", end=' ')
     s, t = n-1, 0
     while s % 2 == 0:
         s, t = s/2, t+1
@@ -363,12 +363,12 @@
     #
     #Since 30 is lcm(2,3,5), we'll set our test numbers to
     #29 % 30 and keep them there
-    low = (2L ** (bits-1)) * 3/2
-    high = 2L ** bits - 30
+    low = (2 ** (bits-1)) * 3/2
+    high = 2 ** bits - 30
     p = getRandomNumber(low, high)
     p += 29 - (p % 30)
     while 1:
-        if display: print ".",
+        if display: print(".", end=' ')
         p += 30
         if p >= high:
             p = getRandomNumber(low, high)
@@ -390,7 +390,7 @@
     q = getRandomNumber(low, high)
     q += 29 - (q % 30)
     while 1:
-        if display: print ".",
+        if display: print(".", end=' ')
         q += 30
         if (q >= high):
             q = getRandomNumber(low, high)
--- ./ez/gdata/tlslite/utils/jython_compat.py	(original)
+++ ./ez/gdata/tlslite/utils/jython_compat.py	(refactored)
@@ -49,7 +49,7 @@
     import traceback
 
     def formatExceptionTrace(e):
-        newStr = "".join(traceback.format_exception(sys.exc_type, sys.exc_value, sys.exc_traceback))
+        newStr = "".join(traceback.format_exception(sys.exc_info()[0], sys.exc_info()[1], sys.exc_info()[2]))
         return newStr
 
 else:
@@ -84,7 +84,7 @@
     def numBits(n):
         if n==0:
             return 0
-        n= 1L * n; #convert to long, if it isn't already
+        n= 1 * n; #convert to long, if it isn't already
         return n.__tojava__(java.math.BigInteger).bitLength()
 
     #This properly creates static methods for Jython
@@ -102,7 +102,7 @@
     class StopIteration(Exception): pass
 
     def enumerate(collection):
-        return zip(range(len(collection)), collection)
+        return list(zip(list(range(len(collection))), collection))
 
     class Set:
         def __init__(self, seq=None):
@@ -115,34 +115,34 @@
             self.values[e] = None
 
         def discard(self, e):
-            if e in self.values.keys():
+            if e in list(self.values.keys()):
                 del(self.values[e])
 
         def union(self, s):
             ret = Set()
-            for e in self.values.keys():
+            for e in list(self.values.keys()):
                 ret.values[e] = None
-            for e in s.values.keys():
+            for e in list(s.values.keys()):
                 ret.values[e] = None
             return ret
 
         def issubset(self, other):
-            for e in self.values.keys():
-                if e not in other.values.keys():
+            for e in list(self.values.keys()):
+                if e not in list(other.values.keys()):
                     return False
             return True
 
-        def __nonzero__( self):
-            return len(self.values.keys())
+        def __bool__( self):
+            return len(list(self.values.keys()))
 
         def __contains__(self, e):
-            return e in self.values.keys()
+            return e in list(self.values.keys())
 
     def iterSet(set):
-        return set.values.keys()
+        return list(set.values.keys())
 
     def getListFromSet(set):
-        return set.values.keys()
+        return list(set.values.keys())
 
     """
     class JCE_SHA1:
@@ -191,5 +191,5 @@
     import traceback
 
     def formatExceptionTrace(e):
-        newStr = "".join(traceback.format_exception(sys.exc_type, sys.exc_value, sys.exc_traceback))
+        newStr = "".join(traceback.format_exception(sys.exc_info()[0], sys.exc_info()[1], sys.exc_info()[2]))
         return newStr
--- ./ez/gdata/tlslite/utils/keyfactory.py	(original)
+++ ./ez/gdata/tlslite/utils/keyfactory.py	(refactored)
@@ -3,17 +3,17 @@
 parseAsPrivateKey
 """
 
-from compat import *
-
-from RSAKey import RSAKey
-from Python_RSAKey import Python_RSAKey
-import cryptomath
+from .compat import *
+
+from .RSAKey import RSAKey
+from .Python_RSAKey import Python_RSAKey
+from . import cryptomath
 
 if cryptomath.m2cryptoLoaded:
-    from OpenSSL_RSAKey import OpenSSL_RSAKey
+    from .OpenSSL_RSAKey import OpenSSL_RSAKey
 
 if cryptomath.pycryptoLoaded:
-    from PyCrypto_RSAKey import PyCrypto_RSAKey
+    from .PyCrypto_RSAKey import PyCrypto_RSAKey
 
 # **************************************************************************
 # Factory Functions for RSA Keys
--- ./ez/gdata/tlslite/utils/rijndael.py	(original)
+++ ./ez/gdata/tlslite/utils/rijndael.py	(refactored)
@@ -63,14 +63,14 @@
 # produce log and alog tables, needed for multiplying in the
 # field GF(2^m) (generator = 3)
 alog = [1]
-for i in xrange(255):
+for i in range(255):
     j = (alog[-1] << 1) ^ alog[-1]
     if j & 0x100 != 0:
         j ^= 0x11B
     alog.append(j)
 
 log = [0] * 256
-for i in xrange(1, 255):
+for i in range(1, 255):
     log[alog[i]] = i
 
 # multiply two elements of GF(2^m)
@@ -80,29 +80,29 @@
     return alog[(log[a & 0xFF] + log[b & 0xFF]) % 255]
 
 # substitution box based on F^{-1}(x)
-box = [[0] * 8 for i in xrange(256)]
+box = [[0] * 8 for i in range(256)]
 box[1][7] = 1
-for i in xrange(2, 256):
+for i in range(2, 256):
     j = alog[255 - log[i]]
-    for t in xrange(8):
+    for t in range(8):
         box[i][t] = (j >> (7 - t)) & 0x01
 
 B = [0, 1, 1, 0, 0, 0, 1, 1]
 
 # affine transform:  box[i] <- B + A*box[i]
-cox = [[0] * 8 for i in xrange(256)]
-for i in xrange(256):
-    for t in xrange(8):
+cox = [[0] * 8 for i in range(256)]
+for i in range(256):
+    for t in range(8):
         cox[i][t] = B[t]
-        for j in xrange(8):
+        for j in range(8):
             cox[i][t] ^= A[t][j] * box[i][j]
 
 # S-boxes and inverse S-boxes
 S =  [0] * 256
 Si = [0] * 256
-for i in xrange(256):
+for i in range(256):
     S[i] = cox[i][0] << 7
-    for t in xrange(1, 8):
+    for t in range(1, 8):
         S[i] ^= cox[i][t] << (7-t)
     Si[S[i] & 0xFF] = i
 
@@ -112,36 +112,36 @@
     [1, 3, 2, 1],
     [1, 1, 3, 2]]
 
-AA = [[0] * 8 for i in xrange(4)]
-
-for i in xrange(4):
-    for j in xrange(4):
+AA = [[0] * 8 for i in range(4)]
+
+for i in range(4):
+    for j in range(4):
         AA[i][j] = G[i][j]
         AA[i][i+4] = 1
 
-for i in xrange(4):
+for i in range(4):
     pivot = AA[i][i]
     if pivot == 0:
         t = i + 1
         while AA[t][i] == 0 and t < 4:
             t += 1
             assert t != 4, 'G matrix must be invertible'
-            for j in xrange(8):
+            for j in range(8):
                 AA[i][j], AA[t][j] = AA[t][j], AA[i][j]
             pivot = AA[i][i]
-    for j in xrange(8):
+    for j in range(8):
         if AA[i][j] != 0:
             AA[i][j] = alog[(255 + log[AA[i][j] & 0xFF] - log[pivot & 0xFF]) % 255]
-    for t in xrange(4):
+    for t in range(4):
         if i != t:
-            for j in xrange(i+1, 8):
+            for j in range(i+1, 8):
                 AA[t][j] ^= mul(AA[i][j], AA[t][i])
             AA[t][i] = 0
 
-iG = [[0] * 4 for i in xrange(4)]
-
-for i in xrange(4):
-    for j in xrange(4):
+iG = [[0] * 4 for i in range(4)]
+
+for i in range(4):
+    for j in range(4):
         iG[i][j] = AA[i][j + 4]
 
 def mul4(a, bs):
@@ -167,7 +167,7 @@
 U3 = []
 U4 = []
 
-for t in xrange(256):
+for t in range(256):
     s = S[t]
     T1.append(mul4(s, G[0]))
     T2.append(mul4(s, G[1]))
@@ -188,7 +188,7 @@
 # round constants
 rcon = [1]
 r = 1
-for t in xrange(1, 30):
+for t in range(1, 30):
     r = mul(2, r)
     rcon.append(r)
 
@@ -221,15 +221,15 @@
         ROUNDS = num_rounds[len(key)][block_size]
         BC = block_size / 4
         # encryption round keys
-        Ke = [[0] * BC for i in xrange(ROUNDS + 1)]
+        Ke = [[0] * BC for i in range(ROUNDS + 1)]
         # decryption round keys
-        Kd = [[0] * BC for i in xrange(ROUNDS + 1)]
+        Kd = [[0] * BC for i in range(ROUNDS + 1)]
         ROUND_KEY_COUNT = (ROUNDS + 1) * BC
         KC = len(key) / 4
 
         # copy user material bytes into temporary ints
         tk = []
-        for i in xrange(0, KC):
+        for i in range(0, KC):
             tk.append((ord(key[i * 4]) << 24) | (ord(key[i * 4 + 1]) << 16) |
                 (ord(key[i * 4 + 2]) << 8) | ord(key[i * 4 + 3]))
 
@@ -253,17 +253,17 @@
                      (rcon[rconpointer]    & 0xFF) << 24
             rconpointer += 1
             if KC != 8:
-                for i in xrange(1, KC):
+                for i in range(1, KC):
                     tk[i] ^= tk[i-1]
             else:
-                for i in xrange(1, KC / 2):
+                for i in range(1, KC / 2):
                     tk[i] ^= tk[i-1]
                 tt = tk[KC / 2 - 1]
                 tk[KC / 2] ^= (S[ tt        & 0xFF] & 0xFF)       ^ \
                               (S[(tt >>  8) & 0xFF] & 0xFF) <<  8 ^ \
                               (S[(tt >> 16) & 0xFF] & 0xFF) << 16 ^ \
                               (S[(tt >> 24) & 0xFF] & 0xFF) << 24
-                for i in xrange(KC / 2 + 1, KC):
+                for i in range(KC / 2 + 1, KC):
                     tk[i] ^= tk[i-1]
             # copy values into round key arrays
             j = 0
@@ -273,8 +273,8 @@
                 j += 1
                 t += 1
         # inverse MixColumn where needed
-        for r in xrange(1, ROUNDS):
-            for j in xrange(BC):
+        for r in range(1, ROUNDS):
+            for j in range(BC):
                 tt = Kd[r][j]
                 Kd[r][j] = U1[(tt >> 24) & 0xFF] ^ \
                            U2[(tt >> 16) & 0xFF] ^ \
@@ -303,14 +303,14 @@
         # temporary work array
         t = []
         # plaintext to ints + key
-        for i in xrange(BC):
+        for i in range(BC):
             t.append((ord(plaintext[i * 4    ]) << 24 |
                       ord(plaintext[i * 4 + 1]) << 16 |
                       ord(plaintext[i * 4 + 2]) <<  8 |
                       ord(plaintext[i * 4 + 3])        ) ^ Ke[0][i])
         # apply round transforms
-        for r in xrange(1, ROUNDS):
-            for i in xrange(BC):
+        for r in range(1, ROUNDS):
+            for i in range(BC):
                 a[i] = (T1[(t[ i           ] >> 24) & 0xFF] ^
                         T2[(t[(i + s1) % BC] >> 16) & 0xFF] ^
                         T3[(t[(i + s2) % BC] >>  8) & 0xFF] ^
@@ -318,13 +318,13 @@
             t = copy.copy(a)
         # last round is special
         result = []
-        for i in xrange(BC):
+        for i in range(BC):
             tt = Ke[ROUNDS][i]
             result.append((S[(t[ i           ] >> 24) & 0xFF] ^ (tt >> 24)) & 0xFF)
             result.append((S[(t[(i + s1) % BC] >> 16) & 0xFF] ^ (tt >> 16)) & 0xFF)
             result.append((S[(t[(i + s2) % BC] >>  8) & 0xFF] ^ (tt >>  8)) & 0xFF)
             result.append((S[ t[(i + s3) % BC]        & 0xFF] ^  tt       ) & 0xFF)
-        return string.join(map(chr, result), '')
+        return string.join(list(map(chr, result)), '')
 
     def decrypt(self, ciphertext):
         if len(ciphertext) != self.block_size:
@@ -346,14 +346,14 @@
         # temporary work array
         t = [0] * BC
         # ciphertext to ints + key
-        for i in xrange(BC):
+        for i in range(BC):
             t[i] = (ord(ciphertext[i * 4    ]) << 24 |
                     ord(ciphertext[i * 4 + 1]) << 16 |
                     ord(ciphertext[i * 4 + 2]) <<  8 |
                     ord(ciphertext[i * 4 + 3])        ) ^ Kd[0][i]
         # apply round transforms
-        for r in xrange(1, ROUNDS):
-            for i in xrange(BC):
+        for r in range(1, ROUNDS):
+            for i in range(BC):
                 a[i] = (T5[(t[ i           ] >> 24) & 0xFF] ^
                         T6[(t[(i + s1) % BC] >> 16) & 0xFF] ^
                         T7[(t[(i + s2) % BC] >>  8) & 0xFF] ^
@@ -361,13 +361,13 @@
             t = copy.copy(a)
         # last round is special
         result = []
-        for i in xrange(BC):
+        for i in range(BC):
             tt = Kd[ROUNDS][i]
             result.append((Si[(t[ i           ] >> 24) & 0xFF] ^ (tt >> 24)) & 0xFF)
             result.append((Si[(t[(i + s1) % BC] >> 16) & 0xFF] ^ (tt >> 16)) & 0xFF)
             result.append((Si[(t[(i + s2) % BC] >>  8) & 0xFF] ^ (tt >>  8)) & 0xFF)
             result.append((Si[ t[(i + s3) % BC]        & 0xFF] ^  tt       ) & 0xFF)
-        return string.join(map(chr, result), '')
+        return string.join(list(map(chr, result)), '')
 
 def encrypt(key, block):
     return rijndael(key, len(block)).encrypt(block)
--- ./ez/gdata/tlslite/utils/xmltools.py	(original)
+++ ./ez/gdata/tlslite/utils/xmltools.py	(refactored)
@@ -2,7 +2,7 @@
 
 This module has misc. helper functions for working with XML DOM nodes."""
 
-from compat import *
+from .compat import *
 import os
 import re
 
@@ -26,7 +26,7 @@
 def parseAndStripWhitespace(s):
     try:
         element = parseDocument(s).documentElement
-    except BaseException, e:
+    except BaseException as e:
         raise SyntaxError(str(e))
     stripWhitespace(element)
     return element
@@ -102,7 +102,7 @@
             self.element = element
             self.index = index
 
-        def next(self):
+        def __next__(self):
             if self.index < len(self.element.childNodes):
                 retVal = self.element.childNodes.item(self.index)
                 self.index += 1
--- ./ez/gdata/webmastertools/service.py	(original)
+++ ./ez/gdata/webmastertools/service.py	(refactored)
@@ -23,7 +23,7 @@
 
 __author__ = 'livibetter (Yu-Jie Lin)'
 
-import urllib
+import urllib.request, urllib.parse, urllib.error
 import gdata
 import atom.service
 import gdata.service
@@ -132,7 +132,7 @@
     """
 
     return self.Delete(
-        uri % urllib.quote_plus(site_uri),
+        uri % urllib.parse.quote_plus(site_uri),
         url_params=url_params, escape_params=escape_params)
 
   def VerifySite(self, site_uri, verification_method, uri=SITE_TEMPLATE,
@@ -169,7 +169,7 @@
         )
     response = self.Put(
         site_entry,
-        uri % urllib.quote_plus(site_uri),
+        uri % urllib.parse.quote_plus(site_uri),
         url_params=url_params,
         escape_params=escape_params, converter=converter)
     if not converter and isinstance(response, atom.Entry):
@@ -210,7 +210,7 @@
         )
     response = self.Put(
         site_entry,
-        uri % urllib.quote_plus(site_uri),
+        uri % urllib.parse.quote_plus(site_uri),
         url_params=url_params,
         escape_params=escape_params, converter=converter)
     if not converter and isinstance(response, atom.Entry):
@@ -250,7 +250,7 @@
         )
     response = self.Put(
         site_entry,
-        uri % urllib.quote_plus(site_uri),
+        uri % urllib.parse.quote_plus(site_uri),
         url_params=url_params,
         escape_params=escape_params, converter=converter)
     if not converter and isinstance(response, atom.Entry):
@@ -293,7 +293,7 @@
         )
     response = self.Put(
         site_entry,
-        uri % urllib.quote_plus(site_uri),
+        uri % urllib.parse.quote_plus(site_uri),
         url_params=url_params,
         escape_params=escape_params, converter=converter)
     if not converter and isinstance(response, atom.Entry):
@@ -334,7 +334,7 @@
         )
     response = self.Put(
         site_entry,
-        uri % urllib.quote_plus(site_uri),
+        uri % urllib.parse.quote_plus(site_uri),
         url_params=url_params,
         escape_params=escape_params, converter=converter)
     if not converter and isinstance(response, atom.Entry):
@@ -357,7 +357,7 @@
       If converter is defined, the results of running converter on the server's
       response. Otherwise, it will be a SitemapsFeed object.
     """
-    return self.Get(uri % {'site_id': urllib.quote_plus(site_uri)},
+    return self.Get(uri % {'site_id': urllib.parse.quote_plus(site_uri)},
         converter=converter)
 
   def AddSitemap(self, site_uri, sitemap_uri, sitemap_type='WEB',
@@ -393,7 +393,7 @@
         sitemap_type=webmastertools.SitemapType(text=sitemap_type))
     response = self.Post(
         sitemap_entry,
-        uri % {'site_id': urllib.quote_plus(site_uri)},
+        uri % {'site_id': urllib.parse.quote_plus(site_uri)},
         url_params=url_params,
         escape_params=escape_params, converter=converter)
     if not converter and isinstance(response, atom.Entry):
@@ -434,10 +434,10 @@
         sitemap_mobile_markup_language=\
             webmastertools.SitemapMobileMarkupLanguage(
                 text=sitemap_mobile_markup_language))
-    print sitemap_entry
+    print(sitemap_entry)
     response = self.Post(
         sitemap_entry,
-        uri % {'site_id': urllib.quote_plus(site_uri)},
+        uri % {'site_id': urllib.parse.quote_plus(site_uri)},
         url_params=url_params,
         escape_params=escape_params, converter=converter)
     if not converter and isinstance(response, atom.Entry):
@@ -482,10 +482,10 @@
     for label in sitemap_news_publication_label:
       sitemap_entry.sitemap_news_publication_label.append(
           webmastertools.SitemapNewsPublicationLabel(text=label))
-    print sitemap_entry
+    print(sitemap_entry)
     response = self.Post(
         sitemap_entry,
-        uri % {'site_id': urllib.quote_plus(site_uri)},
+        uri % {'site_id': urllib.parse.quote_plus(site_uri)},
         url_params=url_params,
         escape_params=escape_params, converter=converter)
     if not converter and isinstance(response, atom.Entry):
@@ -511,6 +511,6 @@
     """
 
     return self.Delete(
-        uri % {'site_id': urllib.quote_plus(site_uri),
-            'sitemap_id': urllib.quote_plus(sitemap_uri)},
+        uri % {'site_id': urllib.parse.quote_plus(site_uri),
+            'sitemap_id': urllib.parse.quote_plus(sitemap_uri)},
         url_params=url_params, escape_params=escape_params)
--- ./ez/gdata/youtube/service.py	(original)
+++ ./ez/gdata/youtube/service.py	(refactored)
@@ -629,12 +629,12 @@
     #      'reason':'Accepted content types: %s' %
     #          ['video/%s' % (t) for t in YOUTUBE_SUPPORTED_UPLOAD_TYPES]})
 
-    if (isinstance(filename_or_handle, (str, unicode)) 
+    if (isinstance(filename_or_handle, str) 
         and os.path.exists(filename_or_handle)):
       mediasource = gdata.MediaSource()
       mediasource.setFile(filename_or_handle, content_type)
     elif hasattr(filename_or_handle, 'read'):
-      import StringIO
+      import io
       if hasattr(filename_or_handle, 'seek'):
         filename_or_handle.seek(0)
       file_handle = filename_or_handle
@@ -657,7 +657,7 @@
       try:
         return self.Post(video_entry, uri=upload_uri, media_source=mediasource,
                          converter=gdata.youtube.YouTubeVideoEntryFromString)
-      except gdata.service.RequestError, e:
+      except gdata.service.RequestError as e:
         raise YouTubeError(e.args[0])
     finally:
       del(self.additional_headers['Slug'])
@@ -717,7 +717,7 @@
     """
     try:
       response = self.Post(video_entry, uri)
-    except gdata.service.RequestError, e:
+    except gdata.service.RequestError as e:
       raise YouTubeError(e.args[0])
 
     tree = ElementTree.fromstring(response)
--- ./ez/pipetools/__init__.py	(original)
+++ ./ez/pipetools/__init__.py	(refactored)
@@ -1,13 +1,13 @@
-from utils import foreach
+from .utils import foreach
 
 __version__ = VERSION = 0, 3, 0
 __versionstr__ = VERSION > foreach(str) | '.'.join
 
-from main import pipe, X, maybe, xpartial
-from utils import *
+from .main import pipe, X, maybe, xpartial
+from .utils import *
 
 # prevent namespace pollution
-import compat
+from . import compat
 for symbol in dir(compat):
     if globals().get(symbol) is getattr(compat, symbol):
         globals().pop(symbol)
--- ./ez/pipetools/compat.py	(original)
+++ ./ez/pipetools/compat.py	(refactored)
@@ -1,14 +1,14 @@
 import sys
 
 if sys.version < '3':
-    from itertools import imap as map
-    from itertools import ifilter as filter
+    
+    
     range = xrange
-    text_type = unicode
-    string_types = basestring
-    dict_items = lambda d: d.iteritems()
+    text_type = str
+    string_types = str
+    dict_items = lambda d: iter(d.items())
 else:
     from builtins import map, filter, range
     text_type = str
     string_types = str
-    dict_items = lambda d: d.items()
+    dict_items = lambda d: list(d.items())
--- ./ez/pipetools/debug.py	(original)
+++ ./ez/pipetools/debug.py	(refactored)
@@ -1,6 +1,6 @@
 from itertools import chain
 
-from compat import map, dict_items
+from .compat import map, dict_items
 
 
 def set_name(name, f):
@@ -12,7 +12,7 @@
 
 
 def get_name(f):
-    from main import Pipe
+    from .main import Pipe
     pipetools_name = getattr(f, '__pipetools__name__', None)
     if pipetools_name:
         return pipetools_name() if callable(pipetools_name) else pipetools_name
@@ -25,5 +25,5 @@
 
 def repr_args(*args, **kwargs):
     return ', '.join(chain(
-        map('{0!r}'.format, args),
-        map('{0[0]}={0[1]!r}'.format, dict_items(kwargs))))
+        list(map('{0!r}'.format, args)),
+        list(map('{0[0]}={0[1]!r}'.format, dict_items(kwargs)))))
--- ./ez/pipetools/decorators.py	(original)
+++ ./ez/pipetools/decorators.py	(refactored)
@@ -1,10 +1,10 @@
 import re
 from functools import partial, wraps
 
-from debug import repr_args, set_name, get_name
-from ds_builder import DSBuilder, NoBuilder
-from main import pipe, XObject, StringFormatter, xpartial
-from compat import string_types, dict_items
+from .debug import repr_args, set_name, get_name
+from .ds_builder import DSBuilder, NoBuilder
+from .main import pipe, XObject, StringFormatter, xpartial
+from .compat import string_types, dict_items
 
 
 def pipe_util(func):
@@ -22,7 +22,7 @@
             function = xpartial(function, *args, **kwargs)
 
         name = lambda: '%s(%s)' % (get_name(func), ', '.join(
-            filter(None, (get_name(original_function), repr_args(*args, **kwargs)))))
+            [_f for _f in (get_name(original_function), repr_args(*args, **kwargs)) if _f]))
 
         f = func(function)
 
--- ./ez/pipetools/ds_builder.py	(original)
+++ ./ez/pipetools/ds_builder.py	(refactored)
@@ -1,7 +1,7 @@
 from functools import partial
 
-from main import XObject, StringFormatter
-from compat import string_types, dict_items
+from .main import XObject, StringFormatter
+from .compat import string_types, dict_items
 
 
 class NoBuilder(ValueError):
--- ./ez/pipetools/main.py	(original)
+++ ./ez/pipetools/main.py	(refactored)
@@ -1,8 +1,8 @@
 from collections import Iterable
 from functools import partial, wraps
 
-from debug import get_name, set_name, repr_args
-from compat import text_type, string_types, dict_items
+from .debug import get_name, set_name, repr_args
+from .compat import text_type, string_types, dict_items
 
 
 class Pipe(object):
--- ./ez/pipetools/utils.py	(original)
+++ ./ez/pipetools/utils.py	(refactored)
@@ -1,13 +1,13 @@
-from __future__ import print_function
+
 from functools import partial
 from itertools import islice, takewhile, dropwhile
 import operator
 
-from debug import set_name, repr_args, get_name
-from decorators import data_structure_builder, regex_condition
-from decorators import pipe_util, auto_string_formatter
-from main import pipe, X, _iterable
-from compat import map, filter, range, dict_items
+from .debug import set_name, repr_args, get_name
+from .decorators import data_structure_builder, regex_condition
+from .decorators import pipe_util, auto_string_formatter
+from .main import pipe, X, _iterable
+from .compat import map, filter, range, dict_items
 
 
 KEY, VALUE = X[0], X[1]
@@ -201,7 +201,7 @@
         return _unless
 
     name = lambda: 'unless(%s, %s)' % (exception_class_or_tuple, ', '.join(
-        filter(None, (get_name(func), repr_args(*args, **kwargs)))))
+        [_f for _f in (get_name(func), repr_args(*args, **kwargs)) if _f]))
 
     return set_name(name, construct_unless(func, *args, **kwargs))
 
--- ./ez/timezone/pytz/__init__.py	(original)
+++ ./ez/timezone/pytz/__init__.py	(refactored)
@@ -43,13 +43,13 @@
 
 
 try:
-    unicode
+    str
 
 except NameError: # Python 3.x
 
     # Python 3.x doesn't have unicode(), making writing code
     # for Python 2.3 and Python 3.x a pain.
-    unicode = str
+    str = str
 
     def ascii(s):
         r"""
--- ./ez/timezone/pytz/lazy.py	(original)
+++ ./ez/timezone/pytz/lazy.py	(refactored)
@@ -61,7 +61,7 @@
                     self._fill()
             finally:
                 _fill_lock.release()
-        return self.data.keys()
+        return list(self.data.keys())
 
 
 class LazyList(list):
--- ./ez/timezone/pytz/tzfile.py	(original)
+++ ./ez/timezone/pytz/tzfile.py	(refactored)
@@ -4,7 +4,7 @@
 '''
 
 try:
-    from cStringIO import StringIO
+    from io import StringIO
 except ImportError:
     from io import StringIO
 from datetime import datetime, timedelta
--- ./ez/timezone/pytz/tzinfo.py	(original)
+++ ./ez/timezone/pytz/tzinfo.py	(refactored)
@@ -546,7 +546,7 @@
     # See if we can find an entry differing only by tzname. Abbreviations
     # get changed from the initial guess by the database maintainers to
     # match reality when this information is discovered.
-    for localized_tz in tz._tzinfos.values():
+    for localized_tz in list(tz._tzinfos.values()):
         if (localized_tz._utcoffset == utcoffset
                 and localized_tz._dst == dstoffset):
             return localized_tz
--- ./ez/timezone/pytz/tests/test_lazy.py	(original)
+++ ./ez/timezone/pytz/tests/test_lazy.py	(refactored)
@@ -27,7 +27,7 @@
     def test_unary_ops(self):
         unary_ops = [str, repr, len, bool, not_]
         try:
-            unary_ops.append(unicode)
+            unary_ops.append(str)
         except NameError:
             pass  # unicode no longer exists in Python 3.
 
@@ -169,7 +169,7 @@
         for i in range(-len(self.base), len(self.base)):
             for j in range(-len(self.base), len(self.base)):
                 for step in [-1, 1]:
-                    replacement = range(0, len(self.base[i:j:step]))
+                    replacement = list(range(0, len(self.base[i:j:step])))
                     self.base[i:j:step] = replacement
                     self.lazy[i:j:step] = replacement
                     self.assertEqual(self.lazy, self.base)
@@ -195,7 +195,7 @@
         # These ops just need to work.
         unary_ops = [str, repr]
         try:
-            unary_ops.append(unicode)
+            unary_ops.append(str)
         except NameError:
             pass  # unicode no longer exists in Python 3.
 
--- ./ez/timezone/pytz/tests/test_tzinfo.py	(original)
+++ ./ez/timezone/pytz/tests/test_tzinfo.py	(refactored)
@@ -3,7 +3,7 @@
 import sys, os, os.path
 import unittest, doctest
 try:
-    import cPickle as pickle
+    import pickle as pickle
 except ImportError:
     import pickle
 from datetime import datetime, time, timedelta, tzinfo
@@ -51,11 +51,11 @@
 
 
 try:
-    unicode
+    str
 except NameError:
     # Python 3.x doesn't have unicode(), making writing code
     # for Python 2.3 and Python 3.x a pain.
-    unicode = str
+    str = str
 
 
 class BasicTest(unittest.TestCase):
@@ -107,12 +107,12 @@
         # and traditional strings, and that the desired singleton is
         # returned.
         self.clearCache()
-        eastern = pytz.timezone(unicode('US/Eastern'))
+        eastern = pytz.timezone(str('US/Eastern'))
         self.assertTrue(eastern is pytz.timezone('US/Eastern'))
 
         self.clearCache()
         eastern = pytz.timezone('US/Eastern')
-        self.assertTrue(eastern is pytz.timezone(unicode('US/Eastern')))
+        self.assertTrue(eastern is pytz.timezone(str('US/Eastern')))
 
 
 class PicklingTest(unittest.TestCase):
@@ -136,7 +136,7 @@
         tz = pytz.timezone('Europe/Amsterdam')
         dt = datetime(2004, 2, 1, 0, 0, 0)
 
-        for localized_tz in tz._tzinfos.values():
+        for localized_tz in list(tz._tzinfos.values()):
             self._roundtrip_tzinfo(localized_tz)
             self._roundtrip_datetime(dt.replace(tzinfo=localized_tz))
 
--- ./ez/timezone/tzlocal/darwin.py	(original)
+++ ./ez/timezone/tzlocal/darwin.py	(refactored)
@@ -1,4 +1,4 @@
-from __future__ import with_statement
+
 import os
 import pytz
 
--- ./ez/timezone/tzlocal/unix.py	(original)
+++ ./ez/timezone/tzlocal/unix.py	(refactored)
@@ -1,4 +1,4 @@
-from __future__ import with_statement
+
 import os
 import re
 import pytz
--- ./ez/timezone/tzlocal/win32.py	(original)
+++ ./ez/timezone/tzlocal/win32.py	(refactored)
@@ -1,5 +1,5 @@
 try:
-    import _winreg as winreg
+    import winreg as winreg
 except ImportError:
     import winreg
 
